{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Atari with Deep Reinforcement Learning\n",
    "\n",
    "Paper: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "\n",
    "Walkthorugh: https://becominghuman.ai/lets-build-an-atari-ai-part-0-intro-to-rl-9b2c5336e0ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gym\n",
    "import time\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import History\n",
    "from keras.backend import tf as ktf\n",
    "from keras.callbacks import Callback as KerasCallback, CallbackList as KerasCallbackList\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, CSVLogger\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy, LinearAnnealedPolicy, Policy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import ModelIntervalCheckpoint, FileLogger\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18186548326210526545\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 432144384\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17586047114927762776\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 650, pci bus id: 0000:01:00.0, compute capability: 3.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# check our devices\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "We use Gym's environments for now (specifically, the Atari environments).  Later, we'll be able to define our own environments using Gym's API, but for now we'll just use their out of the box options.\n",
    "\n",
    "In the paper, they use the game `Breakout` with a slightly modified behavior that 'skips' every 4 frames.  It does this because they found that they didn't gain much improvement from having the DQN make an action for every frame, and instead found that having it make an action on every 4th frame (and just repeating that action for the 4 frames) was sufficient in this environment.  Gym offers this same version of the game, which can be made using `BreakoutDeterministic-v4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4') # try out different envs\n",
    "env.reset()\n",
    "\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "In order to implement a DQN, we need to start with an agent.  Instead of writing one from scratch (which is more tedious than actually difficult), we're going to adapt code from the `keras-rl` library (https://github.com/keras-rl/keras-rl).  Their DQN implementation is designed to match the same one demonstrated in the paper.  I've looked through the code (at this point quite extensively), and it's implemented the same way we would, so it's quite suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizer Callback\n",
    "\n",
    "The keras-rl default visualizer is iffy when using a server so, we'll disable the default visualizer, and create a slightly modified version that suits our purposes.  Essentially, we just get the environment to return the image of the game as an RGB numpy array, then use Matplotlib to plot it.\n",
    "\n",
    "Visualization should only be used for debugging/demonstration.  Using visualization during training will slow it down drastically, so use with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer(KerasCallback):\n",
    "    def __init__(self, view_machine_mode=False, show_labels=True):\n",
    "        self.machine_mode = view_machine_mode\n",
    "        self.show_labels = show_labels\n",
    "    \n",
    "    def _set_env(self, env):\n",
    "        self.env = env\n",
    "        self.img = plt.imshow(self.env.render(mode='rgb_array')) # only call this once\n",
    "        self.frame = 0\n",
    "        plt.figure(figsize = (10,10))\n",
    "\n",
    "    def on_action_end(self, action, logs):\n",
    "        \"\"\" Render environment at the end of each action \"\"\"\n",
    "        img = self.env.render(mode='rgb_array')\n",
    "        \n",
    "        if self.machine_mode:\n",
    "            # This lines allow us to see what the NN sees\n",
    "            img = img[::2, ::2] # downscale\n",
    "            img = np.mean(img, axis=2).astype(np.uint8) # grayscale\n",
    "        \n",
    "        self.frame += 1\n",
    "        plt.cla()\n",
    "        plt.imshow(img)\n",
    "        if self.show_labels:\n",
    "            plt.annotate('frame : ' + str(self.frame), xy=(10, 40), color='white')\n",
    "            plt.annotate('action: ' + str(action), xy=(10, 50), color='white')\n",
    "            \n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor\n",
    "\n",
    "Since the environment is pre-built and the agent is pre-built, we create a keras-rl Processor to treat data according to the paper's specifications (downsample and grayscale).\n",
    "\n",
    "Note: we could modify the environment, the agent, or both instead to do this if we needed, but keras-rl provides this API to be able to avoid that.\n",
    "\n",
    "https://github.com/keras-rl/keras-rl/blob/master/rl/core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariProcessor(Processor):      \n",
    "    def process_observation(self, observation):\n",
    "        # Normally, the observation is passed directly to the NN,\n",
    "        # but we override this behavior to follow preprocessing steps\n",
    "        img = observation \n",
    "        img = img[::2, ::2] # downscale\n",
    "        img = np.mean(img, axis=2).astype(np.uint8) # grayscale\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "This is the model used in the paper (or as close to it as I could get).  It's a pretty straight-forward CNN.  It implements the input's normalization as a `Lambda` layer (so that we don't have to preprocess the data in that respect).\n",
    "\n",
    "The input is actually 4 Grayscale frames, hence the input shape of `(4, 105, 80)`.  This is how it was designed in the paper (it uses the 4 most recent frames so that the DQN can figure out things like the ball's trajectory).\n",
    "\n",
    "We also don't directly compile the model.  The keras-rl library takes care of this for us, which is important since it handles 'special' properties of the model, such as using the **Huber Loss** and the output masking.  It should be noted that we could implement these things pretty readily in the model definition (as the walkthrough describes), but we don't since we're relying on keras-rl's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 105, 80)\n",
    "\n",
    "frames_input = keras.layers.Input(input_shape, name='frames')\n",
    "\n",
    "# performs normalization directly in model\n",
    "normalized = keras.layers.Lambda(lambda x: x / 255.0)(frames_input)\n",
    "\n",
    "conv_1 = keras.layers.Conv2D(16, (8,8), strides=(4, 4), activation='relu', data_format='channels_first')(normalized)\n",
    "conv_2 = keras.layers.Conv2D(32, (4,4), strides=(2, 2), activation='relu')(conv_1)\n",
    "\n",
    "conv_flattened = keras.layers.Flatten()(conv_2)\n",
    "hidden = keras.layers.Dense(256, activation='relu')(conv_flattened)\n",
    "output = keras.layers.Dense(nb_actions)(hidden)\n",
    "\n",
    "model = keras.models.Model(inputs=frames_input, outputs=output)\n",
    "optimizer = optimizer=keras.optimizers.RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "#model.compile(optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Creation\n",
    "\n",
    "Finally, we put everything together to create the agent.  We need three things to actually create the agent: it's memory, it's policy, and it's model.  We created the model above, and keras-rl provides us with suitable classes for memory and policy.\n",
    "\n",
    "The memory we'll be using is `Sequential Memory`, which works as described in the paper.  Note that we're using a `window_length` of 4, to reflect the 4 frames of information we need as described before.\n",
    "\n",
    "The policy we'll be using for training is `EpsGreedyQPolicy` setup with `LinearAnnealedPolicy`.  The `EpsGreedyPolicy` is the ε-Greedy policy as described in the paper (it chooses a random action with a proportionate frequency to ε).  The `LinearAnnealedPolicy` is a class wrapper that anneals the ε value in the ε-Greedy policy (as described in the paper).\n",
    "\n",
    "Finally, we put all this together in an instance of the DQNAgent class.  We pass through all of it's components, then compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=100000, window_length=4)\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), 'eps', 1., 0.1, 0.05, 100000)\n",
    "dqn = DQNAgent(model=model, processor=AtariProcessor(), nb_actions=nb_actions, \n",
    "               memory=memory, nb_steps_warmup=50, target_model_update=1e-2, policy=policy, test_policy=policy)\n",
    "dqn.compile(optimizer, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Finally, we can train the thing.  As mentioned above, we can add the `Visualizer` callback to the `fit` method to plot the image and set `visualize` to `False`.  We set `action_repetition` to 4 so that the agent only acts on every 4th frame.  The model's `fit` method returns the training history, so we can look at that later by saving to the `hist` variable.\n",
    "\n",
    "After training has completed, we save the weights of the model (note: this will overwrite previous models.  If you want to save previous models, either move them or save the new one to a different path).  We also save the history to a pickle file for later viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000000 steps ...\n",
      "    111/1000000: episode: 1, duration: 3.667s, episode steps: 111, steps per second: 30, episode reward: 7.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.613 [0.000, 3.000], mean observation: 39.375 [0.000, 142.000], loss: 0.025738, mean_squared_error: 0.703315, mean_q: 0.997127, mean_eps: 0.999275\n",
      "    202/1000000: episode: 2, duration: 5.450s, episode steps: 91, steps per second: 17, episode reward: 5.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.374 [0.000, 3.000], mean observation: 39.490 [0.000, 142.000], loss: 0.021247, mean_squared_error: 0.707965, mean_q: 0.992970, mean_eps: 0.998596\n",
      "    257/1000000: episode: 3, duration: 3.328s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.327 [0.000, 3.000], mean observation: 39.723 [0.000, 142.000], loss: 0.023454, mean_squared_error: 0.729596, mean_q: 1.007391, mean_eps: 0.997939\n",
      "    347/1000000: episode: 4, duration: 5.347s, episode steps: 90, steps per second: 17, episode reward: 5.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.711 [0.000, 3.000], mean observation: 39.601 [0.000, 142.000], loss: 0.022143, mean_squared_error: 0.746531, mean_q: 1.022418, mean_eps: 0.997287\n",
      "    405/1000000: episode: 5, duration: 3.468s, episode steps: 58, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.822 [0.000, 142.000], loss: 0.022687, mean_squared_error: 0.761111, mean_q: 1.034331, mean_eps: 0.996620\n",
      "    490/1000000: episode: 6, duration: 4.978s, episode steps: 85, steps per second: 17, episode reward: 4.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.235 [0.000, 3.000], mean observation: 39.784 [0.000, 142.000], loss: 0.022868, mean_squared_error: 0.770352, mean_q: 1.040883, mean_eps: 0.995977\n",
      "    556/1000000: episode: 7, duration: 3.937s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.591 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.023213, mean_squared_error: 0.780495, mean_q: 1.046380, mean_eps: 0.995298\n",
      "    599/1000000: episode: 8, duration: 2.534s, episode steps: 43, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.651 [0.000, 3.000], mean observation: 40.022 [0.000, 142.000], loss: 0.022764, mean_squared_error: 0.782825, mean_q: 1.047393, mean_eps: 0.994807\n",
      "    673/1000000: episode: 9, duration: 4.242s, episode steps: 74, steps per second: 17, episode reward: 7.000, mean reward: 0.095 [0.000, 4.000], mean action: 1.486 [0.000, 3.000], mean observation: 39.637 [0.000, 142.000], loss: 0.021815, mean_squared_error: 0.804997, mean_q: 1.062494, mean_eps: 0.994280\n",
      "    726/1000000: episode: 10, duration: 3.066s, episode steps: 53, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.283 [0.000, 3.000], mean observation: 39.988 [0.000, 142.000], loss: 0.025490, mean_squared_error: 0.829172, mean_q: 1.075765, mean_eps: 0.993709\n",
      "    772/1000000: episode: 11, duration: 2.760s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.783 [0.000, 3.000], mean observation: 39.718 [0.000, 142.000], loss: 0.025257, mean_squared_error: 0.860190, mean_q: 1.103058, mean_eps: 0.993263\n",
      "    844/1000000: episode: 12, duration: 4.143s, episode steps: 72, steps per second: 17, episode reward: 1.000, mean reward: 0.014 [0.000, 1.000], mean action: 1.653 [0.000, 3.000], mean observation: 39.670 [0.000, 142.000], loss: 0.025088, mean_squared_error: 0.874372, mean_q: 1.110827, mean_eps: 0.992733\n",
      "    925/1000000: episode: 13, duration: 4.720s, episode steps: 81, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.531 [0.000, 3.000], mean observation: 39.653 [0.000, 142.000], loss: 0.028889, mean_squared_error: 0.893528, mean_q: 1.114608, mean_eps: 0.992044\n",
      "    988/1000000: episode: 14, duration: 3.715s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.619 [0.000, 3.000], mean observation: 39.737 [0.000, 142.000], loss: 0.025795, mean_squared_error: 0.912671, mean_q: 1.131753, mean_eps: 0.991396\n",
      "   1089/1000000: episode: 15, duration: 5.870s, episode steps: 101, steps per second: 17, episode reward: 5.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.574 [0.000, 3.000], mean observation: 39.661 [0.000, 142.000], loss: 0.024893, mean_squared_error: 0.932788, mean_q: 1.142148, mean_eps: 0.990658\n",
      "   1144/1000000: episode: 16, duration: 3.246s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.636 [0.000, 3.000], mean observation: 39.831 [0.000, 142.000], loss: 0.027019, mean_squared_error: 0.967002, mean_q: 1.158861, mean_eps: 0.989956\n",
      "   1221/1000000: episode: 17, duration: 4.411s, episode steps: 77, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.377 [0.000, 3.000], mean observation: 39.754 [0.000, 142.000], loss: 0.021751, mean_squared_error: 0.956231, mean_q: 1.158286, mean_eps: 0.989362\n",
      "   1268/1000000: episode: 18, duration: 2.795s, episode steps: 47, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.426 [0.000, 3.000], mean observation: 39.770 [0.000, 142.000], loss: 0.022539, mean_squared_error: 0.958315, mean_q: 1.163168, mean_eps: 0.988804\n",
      "   1323/1000000: episode: 19, duration: 3.177s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.382 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.026513, mean_squared_error: 0.989079, mean_q: 1.170204, mean_eps: 0.988345\n",
      "   1415/1000000: episode: 20, duration: 5.278s, episode steps: 92, steps per second: 17, episode reward: 4.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.023257, mean_squared_error: 1.017155, mean_q: 1.189520, mean_eps: 0.987684\n",
      "   1488/1000000: episode: 21, duration: 4.224s, episode steps: 73, steps per second: 17, episode reward: 1.000, mean reward: 0.014 [0.000, 1.000], mean action: 1.877 [0.000, 3.000], mean observation: 39.963 [0.000, 142.000], loss: 0.025785, mean_squared_error: 1.022265, mean_q: 1.188727, mean_eps: 0.986941\n",
      "   1569/1000000: episode: 22, duration: 4.670s, episode steps: 81, steps per second: 17, episode reward: 1.000, mean reward: 0.012 [0.000, 1.000], mean action: 1.420 [0.000, 3.000], mean observation: 39.984 [0.000, 142.000], loss: 0.022648, mean_squared_error: 1.033175, mean_q: 1.198844, mean_eps: 0.986248\n",
      "   1634/1000000: episode: 23, duration: 3.778s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.292 [0.000, 3.000], mean observation: 39.660 [0.000, 142.000], loss: 0.026664, mean_squared_error: 1.050987, mean_q: 1.206825, mean_eps: 0.985591\n",
      "   1697/1000000: episode: 24, duration: 3.664s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.286 [0.000, 3.000], mean observation: 39.677 [0.000, 142.000], loss: 0.021744, mean_squared_error: 1.069749, mean_q: 1.220823, mean_eps: 0.985015\n",
      "   1773/1000000: episode: 25, duration: 4.399s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.606 [0.000, 142.000], loss: 0.023060, mean_squared_error: 1.082399, mean_q: 1.225817, mean_eps: 0.984390\n",
      "   1835/1000000: episode: 26, duration: 3.595s, episode steps: 62, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.661 [0.000, 3.000], mean observation: 39.796 [0.000, 142.000], loss: 0.029713, mean_squared_error: 1.087521, mean_q: 1.228869, mean_eps: 0.983769\n",
      "   1887/1000000: episode: 27, duration: 3.165s, episode steps: 52, steps per second: 16, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.346 [0.000, 3.000], mean observation: 39.750 [0.000, 142.000], loss: 0.021989, mean_squared_error: 1.092379, mean_q: 1.235363, mean_eps: 0.983256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1948/1000000: episode: 28, duration: 3.541s, episode steps: 61, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.623 [0.000, 3.000], mean observation: 39.792 [0.000, 142.000], loss: 0.024097, mean_squared_error: 1.110860, mean_q: 1.240753, mean_eps: 0.982747\n",
      "   2002/1000000: episode: 29, duration: 3.206s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.444 [0.000, 3.000], mean observation: 39.803 [0.000, 142.000], loss: 0.033732, mean_squared_error: 1.148533, mean_q: 1.260878, mean_eps: 0.982229\n",
      "   2055/1000000: episode: 30, duration: 3.105s, episode steps: 53, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.208 [0.000, 3.000], mean observation: 39.809 [0.000, 142.000], loss: 0.027564, mean_squared_error: 1.154498, mean_q: 1.261945, mean_eps: 0.981748\n",
      "   2118/1000000: episode: 31, duration: 3.754s, episode steps: 63, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.698 [0.000, 3.000], mean observation: 39.829 [0.000, 142.000], loss: 0.028108, mean_squared_error: 1.164640, mean_q: 1.270408, mean_eps: 0.981226\n",
      "   2186/1000000: episode: 32, duration: 3.923s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.853 [0.000, 3.000], mean observation: 39.650 [0.000, 142.000], loss: 0.020799, mean_squared_error: 1.167559, mean_q: 1.275212, mean_eps: 0.980636\n",
      "   2237/1000000: episode: 33, duration: 2.917s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.627 [0.000, 3.000], mean observation: 39.834 [0.000, 142.000], loss: 0.025830, mean_squared_error: 1.183485, mean_q: 1.281655, mean_eps: 0.980101\n",
      "   2303/1000000: episode: 34, duration: 3.834s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.545 [0.000, 3.000], mean observation: 39.806 [0.000, 142.000], loss: 0.027255, mean_squared_error: 1.185222, mean_q: 1.281597, mean_eps: 0.979575\n",
      "   2381/1000000: episode: 35, duration: 4.427s, episode steps: 78, steps per second: 18, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.474 [0.000, 3.000], mean observation: 39.655 [0.000, 142.000], loss: 0.024917, mean_squared_error: 1.195570, mean_q: 1.287810, mean_eps: 0.978926\n",
      "   2435/1000000: episode: 36, duration: 3.124s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.611 [0.000, 3.000], mean observation: 39.780 [0.000, 142.000], loss: 0.025617, mean_squared_error: 1.194486, mean_q: 1.287534, mean_eps: 0.978332\n",
      "   2486/1000000: episode: 37, duration: 2.998s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.471 [0.000, 3.000], mean observation: 39.896 [0.000, 142.000], loss: 0.033042, mean_squared_error: 1.222897, mean_q: 1.303430, mean_eps: 0.977860\n",
      "   2532/1000000: episode: 38, duration: 2.771s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.348 [0.000, 3.000], mean observation: 39.798 [0.000, 142.000], loss: 0.028664, mean_squared_error: 1.229445, mean_q: 1.306172, mean_eps: 0.977424\n",
      "   2594/1000000: episode: 39, duration: 3.596s, episode steps: 62, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.839 [0.000, 3.000], mean observation: 39.811 [0.000, 142.000], loss: 0.025488, mean_squared_error: 1.208649, mean_q: 1.294247, mean_eps: 0.976938\n",
      "   2664/1000000: episode: 40, duration: 4.096s, episode steps: 70, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.457 [0.000, 3.000], mean observation: 39.696 [0.000, 142.000], loss: 0.032036, mean_squared_error: 1.259980, mean_q: 1.325863, mean_eps: 0.976344\n",
      "   2727/1000000: episode: 41, duration: 3.627s, episode steps: 63, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.397 [0.000, 3.000], mean observation: 39.774 [0.000, 142.000], loss: 0.029487, mean_squared_error: 1.259868, mean_q: 1.320312, mean_eps: 0.975745\n",
      "   2802/1000000: episode: 42, duration: 4.334s, episode steps: 75, steps per second: 17, episode reward: 3.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.627 [0.000, 3.000], mean observation: 39.671 [0.000, 142.000], loss: 0.024204, mean_squared_error: 1.263870, mean_q: 1.323584, mean_eps: 0.975124\n",
      "   4969/1000000: episode: 74, duration: 4.187s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.620 [0.000, 3.000], mean observation: 39.756 [0.000, 142.000], loss: 0.021301, mean_squared_error: 1.686183, mean_q: 1.504898, mean_eps: 0.955603\n",
      "   5033/1000000: episode: 75, duration: 3.677s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.578 [0.000, 3.000], mean observation: 39.671 [0.000, 142.000], loss: 0.021249, mean_squared_error: 1.686413, mean_q: 1.503157, mean_eps: 0.954995\n",
      "   5095/1000000: episode: 76, duration: 3.652s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.629 [0.000, 3.000], mean observation: 39.736 [0.000, 142.000], loss: 0.023324, mean_squared_error: 1.677493, mean_q: 1.493915, mean_eps: 0.954429\n",
      "   5176/1000000: episode: 77, duration: 4.696s, episode steps: 81, steps per second: 17, episode reward: 3.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.593 [0.000, 3.000], mean observation: 39.800 [0.000, 142.000], loss: 0.021102, mean_squared_error: 1.668961, mean_q: 1.490233, mean_eps: 0.953785\n",
      "   5253/1000000: episode: 78, duration: 4.452s, episode steps: 77, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.909 [0.000, 142.000], loss: 0.020124, mean_squared_error: 1.692651, mean_q: 1.501468, mean_eps: 0.953074\n",
      "   5319/1000000: episode: 79, duration: 3.839s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.621 [0.000, 3.000], mean observation: 39.694 [0.000, 142.000], loss: 0.021972, mean_squared_error: 1.719835, mean_q: 1.511166, mean_eps: 0.952430\n",
      "   5383/1000000: episode: 80, duration: 3.728s, episode steps: 64, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.844 [0.000, 3.000], mean observation: 39.823 [0.000, 142.000], loss: 0.027842, mean_squared_error: 1.748702, mean_q: 1.523969, mean_eps: 0.951846\n",
      "   5448/1000000: episode: 81, duration: 3.794s, episode steps: 65, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.492 [0.000, 3.000], mean observation: 39.855 [0.000, 142.000], loss: 0.019032, mean_squared_error: 1.725223, mean_q: 1.508091, mean_eps: 0.951265\n",
      "   5505/1000000: episode: 82, duration: 3.353s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.316 [0.000, 3.000], mean observation: 39.886 [0.000, 142.000], loss: 0.023964, mean_squared_error: 1.703584, mean_q: 1.497881, mean_eps: 0.950716\n",
      "   5547/1000000: episode: 83, duration: 2.507s, episode steps: 42, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.595 [0.000, 3.000], mean observation: 40.053 [0.000, 142.000], loss: 0.025990, mean_squared_error: 1.725513, mean_q: 1.510351, mean_eps: 0.950270\n",
      "   5587/1000000: episode: 84, duration: 2.307s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.450 [0.000, 3.000], mean observation: 39.929 [0.000, 142.000], loss: 0.029291, mean_squared_error: 1.744972, mean_q: 1.516319, mean_eps: 0.949901\n",
      "   5654/1000000: episode: 85, duration: 3.876s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.925 [0.000, 3.000], mean observation: 39.677 [0.000, 142.000], loss: 0.019835, mean_squared_error: 1.735583, mean_q: 1.503649, mean_eps: 0.949420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5718/1000000: episode: 86, duration: 3.746s, episode steps: 64, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.281 [0.000, 3.000], mean observation: 40.003 [0.000, 142.000], loss: 0.021747, mean_squared_error: 1.726803, mean_q: 1.500674, mean_eps: 0.948830\n",
      "   5775/1000000: episode: 87, duration: 3.309s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.421 [0.000, 3.000], mean observation: 39.751 [0.000, 142.000], loss: 0.022211, mean_squared_error: 1.747485, mean_q: 1.511239, mean_eps: 0.948286\n",
      "   5836/1000000: episode: 88, duration: 3.534s, episode steps: 61, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.426 [0.000, 3.000], mean observation: 39.808 [0.000, 142.000], loss: 0.029034, mean_squared_error: 1.797203, mean_q: 1.532236, mean_eps: 0.947755\n",
      "   5923/1000000: episode: 89, duration: 4.985s, episode steps: 87, steps per second: 17, episode reward: 2.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.586 [0.000, 3.000], mean observation: 39.764 [0.000, 142.000], loss: 0.020016, mean_squared_error: 1.742197, mean_q: 1.500338, mean_eps: 0.947089\n",
      "   5978/1000000: episode: 90, duration: 3.224s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.200 [0.000, 3.000], mean observation: 39.842 [0.000, 142.000], loss: 0.021567, mean_squared_error: 1.728274, mean_q: 1.495502, mean_eps: 0.946450\n",
      "   6021/1000000: episode: 91, duration: 2.496s, episode steps: 43, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.721 [0.000, 3.000], mean observation: 39.977 [0.000, 142.000], loss: 0.019244, mean_squared_error: 1.753178, mean_q: 1.505681, mean_eps: 0.946009\n",
      "   6078/1000000: episode: 92, duration: 3.397s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.211 [0.000, 3.000], mean observation: 39.790 [0.000, 142.000], loss: 0.021123, mean_squared_error: 1.772356, mean_q: 1.518785, mean_eps: 0.945559\n",
      "   6161/1000000: episode: 93, duration: 4.857s, episode steps: 83, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.590 [0.000, 3.000], mean observation: 39.604 [0.000, 142.000], loss: 0.020612, mean_squared_error: 1.734325, mean_q: 1.489599, mean_eps: 0.944929\n",
      "   6250/1000000: episode: 94, duration: 5.198s, episode steps: 89, steps per second: 17, episode reward: 2.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.685 [0.000, 3.000], mean observation: 39.882 [0.000, 142.000], loss: 0.019874, mean_squared_error: 1.724469, mean_q: 1.483865, mean_eps: 0.944155\n",
      "   6332/1000000: episode: 95, duration: 4.809s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.659 [0.000, 3.000], mean observation: 39.563 [0.000, 142.000], loss: 0.020372, mean_squared_error: 1.775398, mean_q: 1.503342, mean_eps: 0.943386\n",
      "   6398/1000000: episode: 96, duration: 3.846s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.545 [0.000, 3.000], mean observation: 39.666 [0.000, 142.000], loss: 0.020533, mean_squared_error: 1.774838, mean_q: 1.504232, mean_eps: 0.942720\n",
      "   6451/1000000: episode: 97, duration: 3.087s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.377 [0.000, 3.000], mean observation: 39.848 [0.000, 142.000], loss: 0.021047, mean_squared_error: 1.787501, mean_q: 1.505132, mean_eps: 0.942184\n",
      "   6512/1000000: episode: 98, duration: 3.631s, episode steps: 61, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.705 [0.000, 3.000], mean observation: 39.894 [0.000, 142.000], loss: 0.021239, mean_squared_error: 1.771246, mean_q: 1.495885, mean_eps: 0.941671\n",
      "   6565/1000000: episode: 99, duration: 3.070s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.604 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.025543, mean_squared_error: 1.779417, mean_q: 1.500296, mean_eps: 0.941158\n",
      "   6629/1000000: episode: 100, duration: 3.762s, episode steps: 64, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.516 [0.000, 3.000], mean observation: 40.037 [0.000, 142.000], loss: 0.026492, mean_squared_error: 1.810198, mean_q: 1.516170, mean_eps: 0.940632\n",
      "   6695/1000000: episode: 101, duration: 3.917s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.455 [0.000, 3.000], mean observation: 39.739 [0.000, 142.000], loss: 0.020053, mean_squared_error: 1.783649, mean_q: 1.496427, mean_eps: 0.940046\n",
      "   6773/1000000: episode: 102, duration: 4.527s, episode steps: 78, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.397 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.021851, mean_squared_error: 1.798764, mean_q: 1.505270, mean_eps: 0.939399\n",
      "   6816/1000000: episode: 103, duration: 2.582s, episode steps: 43, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.047 [0.000, 3.000], mean observation: 39.987 [0.000, 142.000], loss: 0.020315, mean_squared_error: 1.814846, mean_q: 1.519595, mean_eps: 0.938854\n",
      "   6904/1000000: episode: 104, duration: 5.146s, episode steps: 88, steps per second: 17, episode reward: 5.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.580 [0.000, 142.000], loss: 0.017153, mean_squared_error: 1.808314, mean_q: 1.509671, mean_eps: 0.938264\n",
      "   6954/1000000: episode: 105, duration: 2.983s, episode steps: 50, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.600 [0.000, 3.000], mean observation: 39.987 [0.000, 142.000], loss: 0.019430, mean_squared_error: 1.810178, mean_q: 1.504401, mean_eps: 0.937644\n",
      "   7009/1000000: episode: 106, duration: 3.330s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.109 [0.000, 3.000], mean observation: 39.850 [0.000, 142.000], loss: 0.019843, mean_squared_error: 1.776835, mean_q: 1.488347, mean_eps: 0.937171\n",
      "   7060/1000000: episode: 107, duration: 2.997s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.314 [0.000, 3.000], mean observation: 39.961 [0.000, 142.000], loss: 0.020239, mean_squared_error: 1.763141, mean_q: 1.477877, mean_eps: 0.936694\n",
      "   7126/1000000: episode: 108, duration: 3.867s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.333 [0.000, 3.000], mean observation: 39.791 [0.000, 142.000], loss: 0.021422, mean_squared_error: 1.801720, mean_q: 1.498542, mean_eps: 0.936168\n",
      "   7172/1000000: episode: 109, duration: 2.671s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.413 [0.000, 3.000], mean observation: 39.934 [0.000, 142.000], loss: 0.018766, mean_squared_error: 1.726562, mean_q: 1.451116, mean_eps: 0.935663\n",
      "   7299/1000000: episode: 110, duration: 7.308s, episode steps: 127, steps per second: 17, episode reward: 8.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.654 [0.000, 3.000], mean observation: 39.339 [0.000, 142.000], loss: 0.019033, mean_squared_error: 1.764585, mean_q: 1.473969, mean_eps: 0.934885\n",
      "   7354/1000000: episode: 111, duration: 3.243s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.327 [0.000, 3.000], mean observation: 39.926 [0.000, 142.000], loss: 0.021147, mean_squared_error: 1.796893, mean_q: 1.492202, mean_eps: 0.934066\n",
      "   7411/1000000: episode: 112, duration: 3.360s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.684 [0.000, 3.000], mean observation: 39.779 [0.000, 142.000], loss: 0.019298, mean_squared_error: 1.751090, mean_q: 1.464689, mean_eps: 0.933562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7493/1000000: episode: 113, duration: 4.736s, episode steps: 82, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.732 [0.000, 3.000], mean observation: 39.644 [0.000, 142.000], loss: 0.018470, mean_squared_error: 1.763375, mean_q: 1.475343, mean_eps: 0.932936\n",
      "   7536/1000000: episode: 114, duration: 2.552s, episode steps: 43, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.349 [0.000, 3.000], mean observation: 39.876 [0.000, 142.000], loss: 0.026760, mean_squared_error: 1.744043, mean_q: 1.463005, mean_eps: 0.932374\n",
      "   7602/1000000: episode: 115, duration: 3.847s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.591 [0.000, 3.000], mean observation: 39.681 [0.000, 142.000], loss: 0.018979, mean_squared_error: 1.720434, mean_q: 1.442710, mean_eps: 0.931883\n",
      "   7666/1000000: episode: 116, duration: 3.741s, episode steps: 64, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.578 [0.000, 3.000], mean observation: 39.768 [0.000, 142.000], loss: 0.019218, mean_squared_error: 1.765148, mean_q: 1.466593, mean_eps: 0.931299\n",
      "   7719/1000000: episode: 117, duration: 3.206s, episode steps: 53, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.811 [0.000, 3.000], mean observation: 39.855 [0.000, 142.000], loss: 0.023996, mean_squared_error: 1.786127, mean_q: 1.477143, mean_eps: 0.930772\n",
      "   7768/1000000: episode: 118, duration: 2.874s, episode steps: 49, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.735 [0.000, 3.000], mean observation: 39.754 [0.000, 142.000], loss: 0.017128, mean_squared_error: 1.766299, mean_q: 1.471778, mean_eps: 0.930313\n",
      "   7802/1000000: episode: 119, duration: 2.049s, episode steps: 34, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.824 [0.000, 3.000], mean observation: 40.035 [0.000, 142.000], loss: 0.022018, mean_squared_error: 1.777739, mean_q: 1.474152, mean_eps: 0.929940\n",
      "   7855/1000000: episode: 120, duration: 3.124s, episode steps: 53, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.566 [0.000, 3.000], mean observation: 39.930 [0.000, 142.000], loss: 0.020511, mean_squared_error: 1.749000, mean_q: 1.453130, mean_eps: 0.929548\n",
      "   7936/1000000: episode: 121, duration: 4.722s, episode steps: 81, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.407 [0.000, 3.000], mean observation: 39.624 [0.000, 142.000], loss: 0.022149, mean_squared_error: 1.776688, mean_q: 1.470871, mean_eps: 0.928945\n",
      "   8011/1000000: episode: 122, duration: 4.511s, episode steps: 75, steps per second: 17, episode reward: 1.000, mean reward: 0.013 [0.000, 1.000], mean action: 1.653 [0.000, 3.000], mean observation: 39.767 [0.000, 142.000], loss: 0.021978, mean_squared_error: 1.734758, mean_q: 1.449970, mean_eps: 0.928243\n",
      "   8082/1000000: episode: 123, duration: 4.154s, episode steps: 71, steps per second: 17, episode reward: 2.000, mean reward: 0.028 [0.000, 1.000], mean action: 1.521 [0.000, 3.000], mean observation: 39.717 [0.000, 142.000], loss: 0.023153, mean_squared_error: 1.750173, mean_q: 1.458122, mean_eps: 0.927586\n",
      "   8128/1000000: episode: 124, duration: 2.717s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.739 [0.000, 3.000], mean observation: 39.874 [0.000, 142.000], loss: 0.018957, mean_squared_error: 1.712795, mean_q: 1.432447, mean_eps: 0.927060\n",
      "   8200/1000000: episode: 125, duration: 4.237s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.542 [0.000, 3.000], mean observation: 39.670 [0.000, 142.000], loss: 0.019594, mean_squared_error: 1.712304, mean_q: 1.434656, mean_eps: 0.926529\n",
      "   8276/1000000: episode: 126, duration: 4.447s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.605 [0.000, 3.000], mean observation: 39.662 [0.000, 142.000], loss: 0.021831, mean_squared_error: 1.718508, mean_q: 1.441199, mean_eps: 0.925862\n",
      "   8332/1000000: episode: 127, duration: 3.366s, episode steps: 56, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.482 [0.000, 3.000], mean observation: 39.979 [0.000, 142.000], loss: 0.026961, mean_squared_error: 1.753080, mean_q: 1.463384, mean_eps: 0.925268\n",
      "   8390/1000000: episode: 128, duration: 3.428s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.569 [0.000, 3.000], mean observation: 39.796 [0.000, 142.000], loss: 0.028384, mean_squared_error: 1.715936, mean_q: 1.432474, mean_eps: 0.924755\n",
      "   8471/1000000: episode: 129, duration: 4.609s, episode steps: 81, steps per second: 18, episode reward: 3.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.543 [0.000, 3.000], mean observation: 39.733 [0.000, 142.000], loss: 0.023155, mean_squared_error: 1.747415, mean_q: 1.451113, mean_eps: 0.924130\n",
      "   8574/1000000: episode: 130, duration: 5.986s, episode steps: 103, steps per second: 17, episode reward: 6.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.388 [0.000, 3.000], mean observation: 39.442 [0.000, 142.000], loss: 0.021349, mean_squared_error: 1.739806, mean_q: 1.438536, mean_eps: 0.923302\n",
      "   8650/1000000: episode: 131, duration: 4.415s, episode steps: 76, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.276 [0.000, 3.000], mean observation: 39.737 [0.000, 142.000], loss: 0.026405, mean_squared_error: 1.756719, mean_q: 1.448016, mean_eps: 0.922496\n",
      "   8710/1000000: episode: 132, duration: 3.566s, episode steps: 60, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.633 [0.000, 3.000], mean observation: 39.643 [0.000, 142.000], loss: 0.025355, mean_squared_error: 1.767887, mean_q: 1.453021, mean_eps: 0.921884\n",
      "   8757/1000000: episode: 133, duration: 2.803s, episode steps: 47, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.617 [0.000, 3.000], mean observation: 39.876 [0.000, 142.000], loss: 0.021264, mean_squared_error: 1.751914, mean_q: 1.445113, mean_eps: 0.921403\n",
      "   8808/1000000: episode: 134, duration: 3.025s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.569 [0.000, 3.000], mean observation: 39.926 [0.000, 142.000], loss: 0.023372, mean_squared_error: 1.765410, mean_q: 1.443396, mean_eps: 0.920962\n",
      "   8894/1000000: episode: 135, duration: 5.006s, episode steps: 86, steps per second: 17, episode reward: 4.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.535 [0.000, 3.000], mean observation: 39.690 [0.000, 142.000], loss: 0.021614, mean_squared_error: 1.749455, mean_q: 1.436945, mean_eps: 0.920345\n",
      "   8939/1000000: episode: 136, duration: 2.664s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.622 [0.000, 3.000], mean observation: 39.785 [0.000, 142.000], loss: 0.020943, mean_squared_error: 1.753815, mean_q: 1.443622, mean_eps: 0.919756\n",
      "   8981/1000000: episode: 137, duration: 2.490s, episode steps: 42, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.238 [0.000, 3.000], mean observation: 40.001 [0.000, 142.000], loss: 0.022862, mean_squared_error: 1.764510, mean_q: 1.441522, mean_eps: 0.919365\n",
      "   9047/1000000: episode: 138, duration: 3.955s, episode steps: 66, steps per second: 17, episode reward: 1.000, mean reward: 0.015 [0.000, 1.000], mean action: 1.530 [0.000, 3.000], mean observation: 39.694 [0.000, 142.000], loss: 0.020566, mean_squared_error: 1.738988, mean_q: 1.431646, mean_eps: 0.918879\n",
      "   9116/1000000: episode: 139, duration: 4.038s, episode steps: 69, steps per second: 17, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.638 [0.000, 3.000], mean observation: 39.777 [0.000, 142.000], loss: 0.023915, mean_squared_error: 1.751300, mean_q: 1.437789, mean_eps: 0.918271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9166/1000000: episode: 140, duration: 2.928s, episode steps: 50, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.640 [0.000, 3.000], mean observation: 39.903 [0.000, 142.000], loss: 0.018933, mean_squared_error: 1.731588, mean_q: 1.424895, mean_eps: 0.917736\n",
      "   9220/1000000: episode: 141, duration: 3.133s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.407 [0.000, 3.000], mean observation: 39.781 [0.000, 142.000], loss: 0.021023, mean_squared_error: 1.773704, mean_q: 1.453913, mean_eps: 0.917267\n",
      "   9268/1000000: episode: 142, duration: 2.798s, episode steps: 48, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.521 [0.000, 3.000], mean observation: 40.009 [0.000, 142.000], loss: 0.018493, mean_squared_error: 1.767211, mean_q: 1.437107, mean_eps: 0.916809\n",
      "   9360/1000000: episode: 143, duration: 5.354s, episode steps: 92, steps per second: 17, episode reward: 4.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.522 [0.000, 3.000], mean observation: 39.673 [0.000, 142.000], loss: 0.019515, mean_squared_error: 1.741101, mean_q: 1.431911, mean_eps: 0.916179\n",
      "   9430/1000000: episode: 144, duration: 4.144s, episode steps: 70, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.557 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.023183, mean_squared_error: 1.774102, mean_q: 1.445577, mean_eps: 0.915449\n",
      "   9487/1000000: episode: 145, duration: 3.349s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.456 [0.000, 3.000], mean observation: 39.672 [0.000, 142.000], loss: 0.021118, mean_squared_error: 1.713258, mean_q: 1.403698, mean_eps: 0.914878\n",
      "   9551/1000000: episode: 146, duration: 3.748s, episode steps: 64, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.438 [0.000, 3.000], mean observation: 39.987 [0.000, 142.000], loss: 0.020604, mean_squared_error: 1.735040, mean_q: 1.420997, mean_eps: 0.914333\n",
      "   9606/1000000: episode: 147, duration: 3.258s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.545 [0.000, 3.000], mean observation: 39.791 [0.000, 142.000], loss: 0.020063, mean_squared_error: 1.741931, mean_q: 1.427262, mean_eps: 0.913798\n",
      "   9647/1000000: episode: 148, duration: 2.382s, episode steps: 41, steps per second: 17, episode reward: 1.000, mean reward: 0.024 [0.000, 1.000], mean action: 1.244 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.017124, mean_squared_error: 1.777339, mean_q: 1.437655, mean_eps: 0.913366\n",
      "   9702/1000000: episode: 149, duration: 3.228s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.709 [0.000, 3.000], mean observation: 39.940 [0.000, 142.000], loss: 0.020026, mean_squared_error: 1.710532, mean_q: 1.406215, mean_eps: 0.912934\n",
      "   9772/1000000: episode: 150, duration: 4.122s, episode steps: 70, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.357 [0.000, 3.000], mean observation: 39.663 [0.000, 142.000], loss: 0.020513, mean_squared_error: 1.765691, mean_q: 1.425291, mean_eps: 0.912372\n",
      "   9837/1000000: episode: 151, duration: 3.775s, episode steps: 65, steps per second: 17, episode reward: 1.000, mean reward: 0.015 [0.000, 1.000], mean action: 1.677 [0.000, 3.000], mean observation: 39.878 [0.000, 142.000], loss: 0.023625, mean_squared_error: 1.718277, mean_q: 1.403764, mean_eps: 0.911764\n",
      "   9888/1000000: episode: 152, duration: 2.957s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.490 [0.000, 3.000], mean observation: 39.751 [0.000, 142.000], loss: 0.018104, mean_squared_error: 1.719576, mean_q: 1.403095, mean_eps: 0.911242\n",
      "   9934/1000000: episode: 153, duration: 2.667s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.630 [0.000, 3.000], mean observation: 39.970 [0.000, 142.000], loss: 0.017401, mean_squared_error: 1.767346, mean_q: 1.439515, mean_eps: 0.910806\n",
      "   9979/1000000: episode: 154, duration: 2.616s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.689 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.024491, mean_squared_error: 1.695106, mean_q: 1.395831, mean_eps: 0.910396\n",
      "  10077/1000000: episode: 155, duration: 5.729s, episode steps: 98, steps per second: 17, episode reward: 6.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.439 [0.000, 3.000], mean observation: 39.504 [0.000, 142.000], loss: 0.020138, mean_squared_error: 1.747403, mean_q: 1.419840, mean_eps: 0.909752\n",
      "  10133/1000000: episode: 156, duration: 3.214s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.661 [0.000, 3.000], mean observation: 39.739 [0.000, 142.000], loss: 0.018298, mean_squared_error: 1.671946, mean_q: 1.381568, mean_eps: 0.909059\n",
      "  10192/1000000: episode: 157, duration: 3.396s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.644 [0.000, 3.000], mean observation: 39.748 [0.000, 142.000], loss: 0.016452, mean_squared_error: 1.682852, mean_q: 1.385765, mean_eps: 0.908542\n",
      "  10252/1000000: episode: 158, duration: 3.485s, episode steps: 60, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.018661, mean_squared_error: 1.708732, mean_q: 1.408264, mean_eps: 0.908007\n",
      "  10305/1000000: episode: 159, duration: 3.116s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.358 [0.000, 3.000], mean observation: 39.724 [0.000, 142.000], loss: 0.020419, mean_squared_error: 1.676414, mean_q: 1.382821, mean_eps: 0.907498\n",
      "  10362/1000000: episode: 160, duration: 3.379s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.544 [0.000, 3.000], mean observation: 39.849 [0.000, 142.000], loss: 0.021885, mean_squared_error: 1.642481, mean_q: 1.365212, mean_eps: 0.907003\n",
      "  10416/1000000: episode: 161, duration: 3.142s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.704 [0.000, 3.000], mean observation: 39.823 [0.000, 142.000], loss: 0.019892, mean_squared_error: 1.704216, mean_q: 1.397686, mean_eps: 0.906504\n",
      "  10467/1000000: episode: 162, duration: 2.986s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.235 [0.000, 3.000], mean observation: 39.927 [0.000, 142.000], loss: 0.020083, mean_squared_error: 1.663092, mean_q: 1.377075, mean_eps: 0.906031\n",
      "  10530/1000000: episode: 163, duration: 3.717s, episode steps: 63, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.778 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.021329, mean_squared_error: 1.608369, mean_q: 1.344552, mean_eps: 0.905518\n",
      "  10590/1000000: episode: 164, duration: 3.541s, episode steps: 60, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.400 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.018647, mean_squared_error: 1.671898, mean_q: 1.385013, mean_eps: 0.904964\n",
      "  10648/1000000: episode: 165, duration: 3.406s, episode steps: 58, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.483 [0.000, 3.000], mean observation: 39.778 [0.000, 142.000], loss: 0.016618, mean_squared_error: 1.625330, mean_q: 1.357577, mean_eps: 0.904434\n",
      "  10737/1000000: episode: 166, duration: 5.218s, episode steps: 89, steps per second: 17, episode reward: 5.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.663 [0.000, 3.000], mean observation: 39.562 [0.000, 142.000], loss: 0.019906, mean_squared_error: 1.634667, mean_q: 1.361318, mean_eps: 0.903772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10796/1000000: episode: 167, duration: 3.484s, episode steps: 59, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.706 [0.000, 142.000], loss: 0.025101, mean_squared_error: 1.662686, mean_q: 1.384557, mean_eps: 0.903106\n",
      "  10862/1000000: episode: 168, duration: 3.850s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.561 [0.000, 3.000], mean observation: 39.736 [0.000, 142.000], loss: 0.018231, mean_squared_error: 1.621836, mean_q: 1.351903, mean_eps: 0.902543\n",
      "  10917/1000000: episode: 169, duration: 3.192s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.564 [0.000, 3.000], mean observation: 39.859 [0.000, 142.000], loss: 0.023339, mean_squared_error: 1.645287, mean_q: 1.360811, mean_eps: 0.901999\n",
      "  10983/1000000: episode: 170, duration: 3.880s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.788 [0.000, 3.000], mean observation: 39.769 [0.000, 142.000], loss: 0.016527, mean_squared_error: 1.611701, mean_q: 1.347110, mean_eps: 0.901454\n",
      "  11057/1000000: episode: 171, duration: 4.303s, episode steps: 74, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.608 [0.000, 3.000], mean observation: 39.850 [0.000, 142.000], loss: 0.017876, mean_squared_error: 1.588271, mean_q: 1.324874, mean_eps: 0.900824\n",
      "  11109/1000000: episode: 172, duration: 3.078s, episode steps: 52, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.731 [0.000, 3.000], mean observation: 39.757 [0.000, 142.000], loss: 0.021297, mean_squared_error: 1.558298, mean_q: 1.310226, mean_eps: 0.900258\n",
      "  11169/1000000: episode: 173, duration: 3.458s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.638 [0.000, 142.000], loss: 0.022107, mean_squared_error: 1.599487, mean_q: 1.335017, mean_eps: 0.899753\n",
      "  11205/1000000: episode: 174, duration: 2.182s, episode steps: 36, steps per second: 16, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.278 [0.000, 3.000], mean observation: 39.999 [0.000, 142.000], loss: 0.021853, mean_squared_error: 1.619559, mean_q: 1.351211, mean_eps: 0.899321\n",
      "  11271/1000000: episode: 175, duration: 3.769s, episode steps: 66, steps per second: 18, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.758 [0.000, 3.000], mean observation: 39.873 [0.000, 142.000], loss: 0.019644, mean_squared_error: 1.616650, mean_q: 1.354813, mean_eps: 0.898863\n",
      "  11344/1000000: episode: 176, duration: 4.363s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.575 [0.000, 3.000], mean observation: 39.666 [0.000, 142.000], loss: 0.017870, mean_squared_error: 1.660279, mean_q: 1.366001, mean_eps: 0.898237\n",
      "  11420/1000000: episode: 177, duration: 4.437s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.539 [0.000, 3.000], mean observation: 39.595 [0.000, 142.000], loss: 0.019991, mean_squared_error: 1.625463, mean_q: 1.353338, mean_eps: 0.897566\n",
      "  11473/1000000: episode: 178, duration: 3.172s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.491 [0.000, 3.000], mean observation: 39.726 [0.000, 142.000], loss: 0.020295, mean_squared_error: 1.647218, mean_q: 1.364945, mean_eps: 0.896986\n",
      "  11534/1000000: episode: 179, duration: 3.587s, episode steps: 61, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.705 [0.000, 3.000], mean observation: 39.802 [0.000, 142.000], loss: 0.020323, mean_squared_error: 1.589671, mean_q: 1.336814, mean_eps: 0.896473\n",
      "  11606/1000000: episode: 180, duration: 4.278s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.806 [0.000, 3.000], mean observation: 39.718 [0.000, 142.000], loss: 0.019070, mean_squared_error: 1.578806, mean_q: 1.335185, mean_eps: 0.895874\n",
      "  11663/1000000: episode: 181, duration: 3.351s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.491 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.016473, mean_squared_error: 1.587403, mean_q: 1.332108, mean_eps: 0.895294\n",
      "  11739/1000000: episode: 182, duration: 4.450s, episode steps: 76, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.824 [0.000, 142.000], loss: 0.019962, mean_squared_error: 1.544669, mean_q: 1.314360, mean_eps: 0.894695\n",
      "  11788/1000000: episode: 183, duration: 2.842s, episode steps: 49, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.408 [0.000, 3.000], mean observation: 39.921 [0.000, 142.000], loss: 0.024171, mean_squared_error: 1.572257, mean_q: 1.337953, mean_eps: 0.894133\n",
      "  11847/1000000: episode: 184, duration: 3.452s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.390 [0.000, 3.000], mean observation: 39.932 [0.000, 142.000], loss: 0.019782, mean_squared_error: 1.618985, mean_q: 1.354165, mean_eps: 0.893647\n",
      "  11923/1000000: episode: 185, duration: 4.445s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.697 [0.000, 3.000], mean observation: 39.701 [0.000, 142.000], loss: 0.018394, mean_squared_error: 1.597326, mean_q: 1.344492, mean_eps: 0.893040\n",
      "  12006/1000000: episode: 186, duration: 4.908s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.602 [0.000, 3.000], mean observation: 39.535 [0.000, 142.000], loss: 0.020616, mean_squared_error: 1.598192, mean_q: 1.339916, mean_eps: 0.892324\n",
      "  12080/1000000: episode: 187, duration: 4.264s, episode steps: 74, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.743 [0.000, 3.000], mean observation: 39.762 [0.000, 142.000], loss: 0.019356, mean_squared_error: 1.514066, mean_q: 1.291219, mean_eps: 0.891618\n",
      "  12169/1000000: episode: 188, duration: 5.192s, episode steps: 89, steps per second: 17, episode reward: 3.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.719 [0.000, 3.000], mean observation: 39.733 [0.000, 142.000], loss: 0.017979, mean_squared_error: 1.547457, mean_q: 1.312860, mean_eps: 0.890884\n",
      "  12227/1000000: episode: 189, duration: 3.396s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.914 [0.000, 3.000], mean observation: 39.747 [0.000, 142.000], loss: 0.019609, mean_squared_error: 1.582227, mean_q: 1.336193, mean_eps: 0.890223\n",
      "  12281/1000000: episode: 190, duration: 3.217s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.444 [0.000, 3.000], mean observation: 39.955 [0.000, 142.000], loss: 0.019023, mean_squared_error: 1.559039, mean_q: 1.321914, mean_eps: 0.889718\n",
      "  12332/1000000: episode: 191, duration: 2.980s, episode steps: 51, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.412 [0.000, 3.000], mean observation: 40.017 [0.000, 142.000], loss: 0.020398, mean_squared_error: 1.581854, mean_q: 1.329111, mean_eps: 0.889246\n",
      "  12388/1000000: episode: 192, duration: 3.223s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.018964, mean_squared_error: 1.615428, mean_q: 1.359436, mean_eps: 0.888765\n",
      "  12460/1000000: episode: 193, duration: 4.097s, episode steps: 72, steps per second: 18, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.528 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.015975, mean_squared_error: 1.548588, mean_q: 1.310584, mean_eps: 0.888189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12509/1000000: episode: 194, duration: 2.854s, episode steps: 49, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.367 [0.000, 3.000], mean observation: 39.866 [0.000, 142.000], loss: 0.019528, mean_squared_error: 1.557102, mean_q: 1.317321, mean_eps: 0.887644\n",
      "  12584/1000000: episode: 195, duration: 4.399s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.587 [0.000, 3.000], mean observation: 39.683 [0.000, 142.000], loss: 0.018497, mean_squared_error: 1.560937, mean_q: 1.325230, mean_eps: 0.887086\n",
      "  12658/1000000: episode: 196, duration: 4.246s, episode steps: 74, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.608 [0.000, 3.000], mean observation: 39.659 [0.000, 142.000], loss: 0.020425, mean_squared_error: 1.575842, mean_q: 1.330743, mean_eps: 0.886416\n",
      "  12722/1000000: episode: 197, duration: 3.798s, episode steps: 64, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.344 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.018030, mean_squared_error: 1.586292, mean_q: 1.334827, mean_eps: 0.885795\n",
      "  12778/1000000: episode: 198, duration: 3.261s, episode steps: 56, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.571 [0.000, 3.000], mean observation: 39.699 [0.000, 142.000], loss: 0.017579, mean_squared_error: 1.618122, mean_q: 1.351494, mean_eps: 0.885255\n",
      "  12852/1000000: episode: 199, duration: 4.383s, episode steps: 74, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.514 [0.000, 3.000], mean observation: 39.765 [0.000, 142.000], loss: 0.017442, mean_squared_error: 1.593402, mean_q: 1.336688, mean_eps: 0.884670\n",
      "  12889/1000000: episode: 200, duration: 2.229s, episode steps: 37, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.405 [0.000, 3.000], mean observation: 39.947 [0.000, 142.000], loss: 0.015722, mean_squared_error: 1.580843, mean_q: 1.318049, mean_eps: 0.884170\n",
      "  12934/1000000: episode: 201, duration: 2.665s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.200 [0.000, 3.000], mean observation: 39.903 [0.000, 142.000], loss: 0.016486, mean_squared_error: 1.614945, mean_q: 1.334261, mean_eps: 0.883801\n",
      "  13020/1000000: episode: 202, duration: 5.013s, episode steps: 86, steps per second: 17, episode reward: 4.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.709 [0.000, 3.000], mean observation: 39.659 [0.000, 142.000], loss: 0.017595, mean_squared_error: 1.560451, mean_q: 1.315420, mean_eps: 0.883211\n",
      "  13126/1000000: episode: 203, duration: 6.178s, episode steps: 106, steps per second: 17, episode reward: 6.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.764 [0.000, 3.000], mean observation: 39.463 [0.000, 142.000], loss: 0.016917, mean_squared_error: 1.548303, mean_q: 1.310360, mean_eps: 0.882348\n",
      "  13198/1000000: episode: 204, duration: 4.244s, episode steps: 72, steps per second: 17, episode reward: 2.000, mean reward: 0.028 [0.000, 1.000], mean action: 1.583 [0.000, 3.000], mean observation: 39.765 [0.000, 142.000], loss: 0.020979, mean_squared_error: 1.564778, mean_q: 1.319101, mean_eps: 0.881547\n",
      "  13234/1000000: episode: 205, duration: 2.125s, episode steps: 36, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.583 [0.000, 3.000], mean observation: 40.018 [0.000, 142.000], loss: 0.017437, mean_squared_error: 1.618900, mean_q: 1.351786, mean_eps: 0.881061\n",
      "  13291/1000000: episode: 206, duration: 3.304s, episode steps: 57, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.456 [0.000, 3.000], mean observation: 39.966 [0.000, 142.000], loss: 0.019698, mean_squared_error: 1.549959, mean_q: 1.321271, mean_eps: 0.880642\n",
      "  13336/1000000: episode: 207, duration: 2.637s, episode steps: 45, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.644 [0.000, 3.000], mean observation: 40.016 [0.000, 142.000], loss: 0.016601, mean_squared_error: 1.602006, mean_q: 1.338287, mean_eps: 0.880183\n",
      "  13401/1000000: episode: 208, duration: 3.824s, episode steps: 65, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.769 [0.000, 142.000], loss: 0.017662, mean_squared_error: 1.590414, mean_q: 1.336113, mean_eps: 0.879688\n",
      "  13452/1000000: episode: 209, duration: 2.944s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.549 [0.000, 3.000], mean observation: 39.797 [0.000, 142.000], loss: 0.018412, mean_squared_error: 1.526144, mean_q: 1.299519, mean_eps: 0.879166\n",
      "  13523/1000000: episode: 210, duration: 4.154s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.592 [0.000, 3.000], mean observation: 39.680 [0.000, 142.000], loss: 0.017323, mean_squared_error: 1.572131, mean_q: 1.325526, mean_eps: 0.878617\n",
      "  13586/1000000: episode: 211, duration: 3.715s, episode steps: 63, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.254 [0.000, 3.000], mean observation: 39.765 [0.000, 142.000], loss: 0.018234, mean_squared_error: 1.531742, mean_q: 1.306628, mean_eps: 0.878014\n",
      "  13636/1000000: episode: 212, duration: 2.963s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.520 [0.000, 3.000], mean observation: 39.777 [0.000, 142.000], loss: 0.017083, mean_squared_error: 1.573922, mean_q: 1.332674, mean_eps: 0.877505\n",
      "  13693/1000000: episode: 213, duration: 3.283s, episode steps: 57, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.737 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.018173, mean_squared_error: 1.538550, mean_q: 1.317080, mean_eps: 0.877024\n",
      "  13752/1000000: episode: 214, duration: 3.406s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.763 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.016396, mean_squared_error: 1.560305, mean_q: 1.316278, mean_eps: 0.876502\n",
      "  13807/1000000: episode: 215, duration: 3.249s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.455 [0.000, 3.000], mean observation: 39.872 [0.000, 142.000], loss: 0.023550, mean_squared_error: 1.550075, mean_q: 1.319901, mean_eps: 0.875989\n",
      "  13873/1000000: episode: 216, duration: 3.762s, episode steps: 66, steps per second: 18, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.606 [0.000, 3.000], mean observation: 39.832 [0.000, 142.000], loss: 0.020885, mean_squared_error: 1.574940, mean_q: 1.331772, mean_eps: 0.875444\n",
      "  13944/1000000: episode: 217, duration: 4.184s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.634 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.016708, mean_squared_error: 1.612027, mean_q: 1.350993, mean_eps: 0.874828\n",
      "  13998/1000000: episode: 218, duration: 3.201s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.943 [0.000, 142.000], loss: 0.019184, mean_squared_error: 1.631544, mean_q: 1.364563, mean_eps: 0.874265\n",
      "  14053/1000000: episode: 219, duration: 3.281s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.273 [0.000, 3.000], mean observation: 39.784 [0.000, 142.000], loss: 0.017741, mean_squared_error: 1.575675, mean_q: 1.329370, mean_eps: 0.873775\n",
      "  14123/1000000: episode: 220, duration: 4.026s, episode steps: 70, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.571 [0.000, 3.000], mean observation: 39.753 [0.000, 142.000], loss: 0.018391, mean_squared_error: 1.582647, mean_q: 1.345906, mean_eps: 0.873213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14168/1000000: episode: 221, duration: 2.720s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.689 [0.000, 3.000], mean observation: 39.943 [0.000, 142.000], loss: 0.018698, mean_squared_error: 1.625353, mean_q: 1.354587, mean_eps: 0.872695\n",
      "  14212/1000000: episode: 222, duration: 2.579s, episode steps: 44, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.818 [0.000, 3.000], mean observation: 39.760 [0.000, 142.000], loss: 0.015722, mean_squared_error: 1.603762, mean_q: 1.336316, mean_eps: 0.872294\n",
      "  14288/1000000: episode: 223, duration: 4.405s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.566 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.018333, mean_squared_error: 1.596703, mean_q: 1.331642, mean_eps: 0.871754\n",
      "  14398/1000000: episode: 224, duration: 6.444s, episode steps: 110, steps per second: 17, episode reward: 4.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.555 [0.000, 3.000], mean observation: 39.652 [0.000, 142.000], loss: 0.016018, mean_squared_error: 1.617615, mean_q: 1.345246, mean_eps: 0.870918\n",
      "  14438/1000000: episode: 225, duration: 2.356s, episode steps: 40, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.650 [0.000, 3.000], mean observation: 39.999 [0.000, 142.000], loss: 0.016050, mean_squared_error: 1.551616, mean_q: 1.317676, mean_eps: 0.870242\n",
      "  14491/1000000: episode: 226, duration: 3.169s, episode steps: 53, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.358 [0.000, 3.000], mean observation: 39.801 [0.000, 142.000], loss: 0.019159, mean_squared_error: 1.615882, mean_q: 1.367823, mean_eps: 0.869824\n",
      "  14543/1000000: episode: 227, duration: 3.039s, episode steps: 52, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.538 [0.000, 3.000], mean observation: 39.732 [0.000, 142.000], loss: 0.017348, mean_squared_error: 1.665583, mean_q: 1.378184, mean_eps: 0.869351\n",
      "  14632/1000000: episode: 228, duration: 5.181s, episode steps: 89, steps per second: 17, episode reward: 5.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.565 [0.000, 142.000], loss: 0.013925, mean_squared_error: 1.610851, mean_q: 1.352418, mean_eps: 0.868717\n",
      "  14721/1000000: episode: 229, duration: 5.178s, episode steps: 89, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.472 [0.000, 3.000], mean observation: 39.506 [0.000, 142.000], loss: 0.018237, mean_squared_error: 1.648849, mean_q: 1.376943, mean_eps: 0.867916\n",
      "  14768/1000000: episode: 230, duration: 2.704s, episode steps: 47, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.553 [0.000, 3.000], mean observation: 39.717 [0.000, 142.000], loss: 0.018430, mean_squared_error: 1.677640, mean_q: 1.387236, mean_eps: 0.867304\n",
      "  14830/1000000: episode: 231, duration: 3.632s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.694 [0.000, 3.000], mean observation: 39.706 [0.000, 142.000], loss: 0.016707, mean_squared_error: 1.597773, mean_q: 1.348765, mean_eps: 0.866814\n",
      "  14907/1000000: episode: 232, duration: 4.441s, episode steps: 77, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.662 [0.000, 3.000], mean observation: 39.790 [0.000, 142.000], loss: 0.016857, mean_squared_error: 1.600273, mean_q: 1.353898, mean_eps: 0.866188\n",
      "  14974/1000000: episode: 233, duration: 3.909s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.582 [0.000, 3.000], mean observation: 39.700 [0.000, 142.000], loss: 0.016525, mean_squared_error: 1.668127, mean_q: 1.387371, mean_eps: 0.865540\n",
      "  15020/1000000: episode: 234, duration: 2.684s, episode steps: 46, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.435 [0.000, 3.000], mean observation: 40.004 [0.000, 142.000], loss: 0.016953, mean_squared_error: 1.673854, mean_q: 1.389813, mean_eps: 0.865031\n",
      "  15071/1000000: episode: 235, duration: 2.996s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.294 [0.000, 3.000], mean observation: 39.817 [0.000, 142.000], loss: 0.014992, mean_squared_error: 1.664254, mean_q: 1.390694, mean_eps: 0.864595\n",
      "  15154/1000000: episode: 236, duration: 4.837s, episode steps: 83, steps per second: 17, episode reward: 3.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.482 [0.000, 3.000], mean observation: 39.701 [0.000, 142.000], loss: 0.015597, mean_squared_error: 1.711402, mean_q: 1.402971, mean_eps: 0.863992\n",
      "  15219/1000000: episode: 237, duration: 3.862s, episode steps: 65, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.569 [0.000, 3.000], mean observation: 39.705 [0.000, 142.000], loss: 0.018297, mean_squared_error: 1.747017, mean_q: 1.425270, mean_eps: 0.863326\n",
      "  15291/1000000: episode: 238, duration: 4.218s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.250 [0.000, 3.000], mean observation: 39.732 [0.000, 142.000], loss: 0.020034, mean_squared_error: 1.665331, mean_q: 1.391820, mean_eps: 0.862709\n",
      "  15371/1000000: episode: 239, duration: 4.626s, episode steps: 80, steps per second: 17, episode reward: 2.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.637 [0.000, 3.000], mean observation: 39.767 [0.000, 142.000], loss: 0.018367, mean_squared_error: 1.759713, mean_q: 1.435523, mean_eps: 0.862026\n",
      "  15413/1000000: episode: 240, duration: 2.435s, episode steps: 42, steps per second: 17, episode reward: 1.000, mean reward: 0.024 [0.000, 1.000], mean action: 1.548 [0.000, 3.000], mean observation: 39.965 [0.000, 142.000], loss: 0.017407, mean_squared_error: 1.775221, mean_q: 1.439709, mean_eps: 0.861476\n",
      "  15477/1000000: episode: 241, duration: 3.814s, episode steps: 64, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.484 [0.000, 3.000], mean observation: 39.976 [0.000, 142.000], loss: 0.020188, mean_squared_error: 1.785792, mean_q: 1.451603, mean_eps: 0.860999\n",
      "  15545/1000000: episode: 242, duration: 4.012s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.676 [0.000, 3.000], mean observation: 39.769 [0.000, 142.000], loss: 0.015309, mean_squared_error: 1.872329, mean_q: 1.487553, mean_eps: 0.860405\n",
      "  15609/1000000: episode: 243, duration: 3.719s, episode steps: 64, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.469 [0.000, 3.000], mean observation: 39.902 [0.000, 142.000], loss: 0.019156, mean_squared_error: 1.850143, mean_q: 1.457499, mean_eps: 0.859812\n",
      "  15665/1000000: episode: 244, duration: 3.280s, episode steps: 56, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.952 [0.000, 142.000], loss: 0.020366, mean_squared_error: 1.905523, mean_q: 1.505817, mean_eps: 0.859271\n",
      "  15752/1000000: episode: 245, duration: 5.096s, episode steps: 87, steps per second: 17, episode reward: 8.000, mean reward: 0.092 [0.000, 4.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.592 [0.000, 142.000], loss: 0.016874, mean_squared_error: 1.963607, mean_q: 1.520446, mean_eps: 0.858628\n",
      "  15814/1000000: episode: 246, duration: 3.593s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.613 [0.000, 3.000], mean observation: 39.689 [0.000, 142.000], loss: 0.019790, mean_squared_error: 1.918811, mean_q: 1.502463, mean_eps: 0.857958\n",
      "  15870/1000000: episode: 247, duration: 3.221s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.661 [0.000, 3.000], mean observation: 39.721 [0.000, 142.000], loss: 0.016458, mean_squared_error: 1.942609, mean_q: 1.516361, mean_eps: 0.857426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15932/1000000: episode: 248, duration: 3.640s, episode steps: 62, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.677 [0.000, 3.000], mean observation: 39.711 [0.000, 142.000], loss: 0.017733, mean_squared_error: 1.942444, mean_q: 1.510332, mean_eps: 0.856896\n",
      "  15993/1000000: episode: 249, duration: 3.602s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.426 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.020201, mean_squared_error: 1.991469, mean_q: 1.537875, mean_eps: 0.856342\n",
      "  16067/1000000: episode: 250, duration: 4.311s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.473 [0.000, 3.000], mean observation: 39.607 [0.000, 142.000], loss: 0.018631, mean_squared_error: 1.938443, mean_q: 1.511941, mean_eps: 0.855735\n",
      "  16119/1000000: episode: 251, duration: 2.995s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.808 [0.000, 3.000], mean observation: 39.699 [0.000, 142.000], loss: 0.017375, mean_squared_error: 2.014875, mean_q: 1.534546, mean_eps: 0.855168\n",
      "  16194/1000000: episode: 252, duration: 4.366s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.560 [0.000, 3.000], mean observation: 39.626 [0.000, 142.000], loss: 0.017708, mean_squared_error: 2.081625, mean_q: 1.576446, mean_eps: 0.854596\n",
      "  16262/1000000: episode: 253, duration: 4.024s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.912 [0.000, 3.000], mean observation: 39.737 [0.000, 142.000], loss: 0.016870, mean_squared_error: 2.116249, mean_q: 1.587160, mean_eps: 0.853952\n",
      "  16355/1000000: episode: 254, duration: 5.333s, episode steps: 93, steps per second: 17, episode reward: 5.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.538 [0.000, 3.000], mean observation: 39.681 [0.000, 142.000], loss: 0.021458, mean_squared_error: 2.086486, mean_q: 1.572486, mean_eps: 0.853228\n",
      "  16427/1000000: episode: 255, duration: 4.274s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.764 [0.000, 3.000], mean observation: 39.643 [0.000, 142.000], loss: 0.020506, mean_squared_error: 2.210961, mean_q: 1.617694, mean_eps: 0.852486\n",
      "  16480/1000000: episode: 256, duration: 3.030s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.642 [0.000, 3.000], mean observation: 39.793 [0.000, 142.000], loss: 0.021600, mean_squared_error: 2.208395, mean_q: 1.618975, mean_eps: 0.851923\n",
      "  16571/1000000: episode: 257, duration: 5.151s, episode steps: 91, steps per second: 18, episode reward: 6.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.527 [0.000, 3.000], mean observation: 39.458 [0.000, 142.000], loss: 0.022841, mean_squared_error: 2.233795, mean_q: 1.632145, mean_eps: 0.851275\n",
      "  16642/1000000: episode: 258, duration: 4.166s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.493 [0.000, 3.000], mean observation: 39.639 [0.000, 142.000], loss: 0.016197, mean_squared_error: 2.278608, mean_q: 1.645474, mean_eps: 0.850546\n",
      "  16712/1000000: episode: 259, duration: 3.946s, episode steps: 70, steps per second: 18, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.772 [0.000, 142.000], loss: 0.019125, mean_squared_error: 2.314970, mean_q: 1.671394, mean_eps: 0.849911\n",
      "  16817/1000000: episode: 260, duration: 6.044s, episode steps: 105, steps per second: 17, episode reward: 4.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.657 [0.000, 3.000], mean observation: 39.632 [0.000, 142.000], loss: 0.019059, mean_squared_error: 2.379979, mean_q: 1.689796, mean_eps: 0.849124\n",
      "  16869/1000000: episode: 261, duration: 3.068s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.654 [0.000, 3.000], mean observation: 39.828 [0.000, 142.000], loss: 0.017915, mean_squared_error: 2.387828, mean_q: 1.703002, mean_eps: 0.848418\n",
      "  16928/1000000: episode: 262, duration: 3.512s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.805 [0.000, 142.000], loss: 0.020578, mean_squared_error: 2.445346, mean_q: 1.708408, mean_eps: 0.847918\n",
      "  16993/1000000: episode: 263, duration: 3.830s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.723 [0.000, 3.000], mean observation: 39.724 [0.000, 142.000], loss: 0.020663, mean_squared_error: 2.456726, mean_q: 1.718284, mean_eps: 0.847360\n",
      "  17072/1000000: episode: 264, duration: 4.605s, episode steps: 79, steps per second: 17, episode reward: 2.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.506 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.017872, mean_squared_error: 2.445626, mean_q: 1.727236, mean_eps: 0.846712\n",
      "  17149/1000000: episode: 265, duration: 4.500s, episode steps: 77, steps per second: 17, episode reward: 4.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.610 [0.000, 3.000], mean observation: 39.631 [0.000, 142.000], loss: 0.020349, mean_squared_error: 2.596420, mean_q: 1.770143, mean_eps: 0.846010\n",
      "  17224/1000000: episode: 266, duration: 4.408s, episode steps: 75, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.787 [0.000, 3.000], mean observation: 39.900 [0.000, 142.000], loss: 0.019898, mean_squared_error: 2.601117, mean_q: 1.773897, mean_eps: 0.845326\n",
      "  17272/1000000: episode: 267, duration: 2.824s, episode steps: 48, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.833 [0.000, 3.000], mean observation: 39.782 [0.000, 142.000], loss: 0.016647, mean_squared_error: 2.566399, mean_q: 1.764249, mean_eps: 0.844772\n",
      "  17326/1000000: episode: 268, duration: 3.165s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.889 [0.000, 3.000], mean observation: 39.932 [0.000, 142.000], loss: 0.020907, mean_squared_error: 2.671729, mean_q: 1.805933, mean_eps: 0.844313\n",
      "  17409/1000000: episode: 269, duration: 4.893s, episode steps: 83, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.566 [0.000, 3.000], mean observation: 39.665 [0.000, 142.000], loss: 0.020928, mean_squared_error: 2.760139, mean_q: 1.839738, mean_eps: 0.843697\n",
      "  17486/1000000: episode: 270, duration: 4.497s, episode steps: 77, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.571 [0.000, 3.000], mean observation: 39.860 [0.000, 142.000], loss: 0.016187, mean_squared_error: 2.769617, mean_q: 1.834398, mean_eps: 0.842977\n",
      "  17568/1000000: episode: 271, duration: 4.726s, episode steps: 82, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.854 [0.000, 3.000], mean observation: 39.633 [0.000, 142.000], loss: 0.020653, mean_squared_error: 2.818911, mean_q: 1.853363, mean_eps: 0.842261\n",
      "  17631/1000000: episode: 272, duration: 3.661s, episode steps: 63, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.698 [0.000, 3.000], mean observation: 39.802 [0.000, 142.000], loss: 0.018653, mean_squared_error: 2.928802, mean_q: 1.892641, mean_eps: 0.841609\n",
      "  17686/1000000: episode: 273, duration: 3.217s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.600 [0.000, 3.000], mean observation: 39.758 [0.000, 142.000], loss: 0.021928, mean_squared_error: 2.856508, mean_q: 1.866119, mean_eps: 0.841078\n",
      "  17757/1000000: episode: 274, duration: 4.197s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.803 [0.000, 3.000], mean observation: 39.684 [0.000, 142.000], loss: 0.019290, mean_squared_error: 2.944329, mean_q: 1.911698, mean_eps: 0.840511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17841/1000000: episode: 275, duration: 4.962s, episode steps: 84, steps per second: 17, episode reward: 3.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.738 [0.000, 3.000], mean observation: 39.717 [0.000, 142.000], loss: 0.022000, mean_squared_error: 3.014738, mean_q: 1.915488, mean_eps: 0.839813\n",
      "  17886/1000000: episode: 276, duration: 2.570s, episode steps: 45, steps per second: 18, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.711 [0.000, 3.000], mean observation: 39.927 [0.000, 142.000], loss: 0.022961, mean_squared_error: 3.043151, mean_q: 1.930697, mean_eps: 0.839233\n",
      "  17955/1000000: episode: 277, duration: 4.048s, episode steps: 69, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.652 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.018540, mean_squared_error: 3.059907, mean_q: 1.933670, mean_eps: 0.838720\n",
      "  18000/1000000: episode: 278, duration: 2.658s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.533 [0.000, 3.000], mean observation: 39.784 [0.000, 142.000], loss: 0.017801, mean_squared_error: 3.150009, mean_q: 1.966745, mean_eps: 0.838207\n",
      "  18076/1000000: episode: 279, duration: 4.395s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.763 [0.000, 3.000], mean observation: 39.715 [0.000, 142.000], loss: 0.020929, mean_squared_error: 3.159152, mean_q: 1.973261, mean_eps: 0.837662\n",
      "  18194/1000000: episode: 280, duration: 6.801s, episode steps: 118, steps per second: 17, episode reward: 5.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.559 [0.000, 3.000], mean observation: 39.562 [0.000, 142.000], loss: 0.017443, mean_squared_error: 3.313198, mean_q: 2.016818, mean_eps: 0.836789\n",
      "  18260/1000000: episode: 281, duration: 3.927s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.773 [0.000, 3.000], mean observation: 39.701 [0.000, 142.000], loss: 0.026607, mean_squared_error: 3.453317, mean_q: 2.056932, mean_eps: 0.835962\n",
      "  18333/1000000: episode: 282, duration: 4.339s, episode steps: 73, steps per second: 17, episode reward: 1.000, mean reward: 0.014 [0.000, 1.000], mean action: 1.616 [0.000, 3.000], mean observation: 39.960 [0.000, 142.000], loss: 0.018385, mean_squared_error: 3.426101, mean_q: 2.053378, mean_eps: 0.835336\n",
      "  18413/1000000: episode: 283, duration: 4.668s, episode steps: 80, steps per second: 17, episode reward: 4.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.587 [0.000, 3.000], mean observation: 39.645 [0.000, 142.000], loss: 0.022538, mean_squared_error: 3.469329, mean_q: 2.066416, mean_eps: 0.834647\n",
      "  18506/1000000: episode: 284, duration: 5.459s, episode steps: 93, steps per second: 17, episode reward: 5.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.677 [0.000, 3.000], mean observation: 39.524 [0.000, 142.000], loss: 0.022342, mean_squared_error: 3.513822, mean_q: 2.077704, mean_eps: 0.833869\n",
      "  18553/1000000: episode: 285, duration: 2.695s, episode steps: 47, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.511 [0.000, 3.000], mean observation: 40.045 [0.000, 142.000], loss: 0.019289, mean_squared_error: 3.432114, mean_q: 2.040072, mean_eps: 0.833239\n",
      "  18638/1000000: episode: 286, duration: 4.994s, episode steps: 85, steps per second: 17, episode reward: 7.000, mean reward: 0.082 [0.000, 4.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.679 [0.000, 142.000], loss: 0.019971, mean_squared_error: 3.559217, mean_q: 2.092777, mean_eps: 0.832645\n",
      "  18748/1000000: episode: 287, duration: 6.348s, episode steps: 110, steps per second: 17, episode reward: 11.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.909 [0.000, 3.000], mean observation: 39.275 [0.000, 142.000], loss: 0.019349, mean_squared_error: 3.597133, mean_q: 2.081234, mean_eps: 0.831767\n",
      "  18848/1000000: episode: 288, duration: 5.800s, episode steps: 100, steps per second: 17, episode reward: 6.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.710 [0.000, 3.000], mean observation: 39.533 [0.000, 142.000], loss: 0.019028, mean_squared_error: 3.577342, mean_q: 2.079135, mean_eps: 0.830823\n",
      "  18922/1000000: episode: 289, duration: 4.379s, episode steps: 74, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.703 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.021131, mean_squared_error: 3.685193, mean_q: 2.117312, mean_eps: 0.830040\n",
      "  19045/1000000: episode: 290, duration: 7.124s, episode steps: 123, steps per second: 17, episode reward: 11.000, mean reward: 0.089 [0.000, 4.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.311 [0.000, 142.000], loss: 0.021748, mean_squared_error: 3.752906, mean_q: 2.129310, mean_eps: 0.829153\n",
      "  19120/1000000: episode: 291, duration: 4.367s, episode steps: 75, steps per second: 17, episode reward: 3.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.613 [0.000, 3.000], mean observation: 39.864 [0.000, 142.000], loss: 0.021147, mean_squared_error: 3.756541, mean_q: 2.128785, mean_eps: 0.828262\n",
      "  19181/1000000: episode: 292, duration: 3.573s, episode steps: 61, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.492 [0.000, 3.000], mean observation: 39.823 [0.000, 142.000], loss: 0.022495, mean_squared_error: 3.785550, mean_q: 2.131577, mean_eps: 0.827650\n",
      "  19254/1000000: episode: 293, duration: 4.242s, episode steps: 73, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.644 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.023723, mean_squared_error: 3.907304, mean_q: 2.166802, mean_eps: 0.827047\n",
      "  19323/1000000: episode: 294, duration: 4.057s, episode steps: 69, steps per second: 17, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.377 [0.000, 3.000], mean observation: 39.693 [0.000, 142.000], loss: 0.017534, mean_squared_error: 3.914625, mean_q: 2.181354, mean_eps: 0.826408\n",
      "  19378/1000000: episode: 295, duration: 3.254s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.709 [0.000, 3.000], mean observation: 39.879 [0.000, 142.000], loss: 0.022217, mean_squared_error: 3.866509, mean_q: 2.138150, mean_eps: 0.825850\n",
      "  19436/1000000: episode: 296, duration: 3.415s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.552 [0.000, 3.000], mean observation: 39.824 [0.000, 142.000], loss: 0.024609, mean_squared_error: 3.844481, mean_q: 2.145069, mean_eps: 0.825342\n",
      "  19506/1000000: episode: 297, duration: 4.120s, episode steps: 70, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.786 [0.000, 3.000], mean observation: 39.730 [0.000, 142.000], loss: 0.020493, mean_squared_error: 4.023052, mean_q: 2.202065, mean_eps: 0.824766\n",
      "  19564/1000000: episode: 298, duration: 3.396s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.552 [0.000, 3.000], mean observation: 39.734 [0.000, 142.000], loss: 0.023220, mean_squared_error: 4.072759, mean_q: 2.216487, mean_eps: 0.824190\n",
      "  19618/1000000: episode: 299, duration: 3.237s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.574 [0.000, 3.000], mean observation: 39.824 [0.000, 142.000], loss: 0.025122, mean_squared_error: 4.056591, mean_q: 2.204820, mean_eps: 0.823685\n",
      "  19686/1000000: episode: 300, duration: 4.016s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.694 [0.000, 142.000], loss: 0.028595, mean_squared_error: 3.994285, mean_q: 2.182213, mean_eps: 0.823137\n",
      "  19746/1000000: episode: 301, duration: 3.531s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.450 [0.000, 3.000], mean observation: 39.751 [0.000, 142.000], loss: 0.020536, mean_squared_error: 4.103869, mean_q: 2.222973, mean_eps: 0.822561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19798/1000000: episode: 302, duration: 3.047s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.855 [0.000, 142.000], loss: 0.019943, mean_squared_error: 4.124046, mean_q: 2.230671, mean_eps: 0.822056\n",
      "  19871/1000000: episode: 303, duration: 4.301s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.630 [0.000, 3.000], mean observation: 39.694 [0.000, 142.000], loss: 0.019017, mean_squared_error: 4.146581, mean_q: 2.230917, mean_eps: 0.821494\n",
      "  19948/1000000: episode: 304, duration: 4.533s, episode steps: 77, steps per second: 17, episode reward: 4.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.636 [0.000, 3.000], mean observation: 39.622 [0.000, 142.000], loss: 0.021140, mean_squared_error: 4.173501, mean_q: 2.238537, mean_eps: 0.820819\n",
      "  20031/1000000: episode: 305, duration: 4.895s, episode steps: 83, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.609 [0.000, 142.000], loss: 0.020915, mean_squared_error: 4.191434, mean_q: 2.249277, mean_eps: 0.820099\n",
      "  20087/1000000: episode: 306, duration: 3.240s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.518 [0.000, 3.000], mean observation: 39.714 [0.000, 142.000], loss: 0.026880, mean_squared_error: 4.283912, mean_q: 2.260955, mean_eps: 0.819473\n",
      "  20136/1000000: episode: 307, duration: 2.900s, episode steps: 49, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.673 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.022148, mean_squared_error: 4.006131, mean_q: 2.174273, mean_eps: 0.819001\n",
      "  20187/1000000: episode: 308, duration: 2.969s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.647 [0.000, 3.000], mean observation: 39.844 [0.000, 142.000], loss: 0.022619, mean_squared_error: 4.290774, mean_q: 2.282880, mean_eps: 0.818551\n",
      "  20269/1000000: episode: 309, duration: 4.857s, episode steps: 82, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.537 [0.000, 142.000], loss: 0.019971, mean_squared_error: 4.295076, mean_q: 2.268906, mean_eps: 0.817953\n",
      "  20358/1000000: episode: 310, duration: 5.170s, episode steps: 89, steps per second: 17, episode reward: 4.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.517 [0.000, 3.000], mean observation: 39.655 [0.000, 142.000], loss: 0.024612, mean_squared_error: 4.366780, mean_q: 2.282788, mean_eps: 0.817183\n",
      "  20444/1000000: episode: 311, duration: 5.010s, episode steps: 86, steps per second: 17, episode reward: 4.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.674 [0.000, 3.000], mean observation: 39.585 [0.000, 142.000], loss: 0.020561, mean_squared_error: 4.388812, mean_q: 2.290597, mean_eps: 0.816395\n",
      "  20503/1000000: episode: 312, duration: 3.510s, episode steps: 59, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.678 [0.000, 3.000], mean observation: 39.927 [0.000, 142.000], loss: 0.019652, mean_squared_error: 4.526221, mean_q: 2.334658, mean_eps: 0.815743\n",
      "  20560/1000000: episode: 313, duration: 3.404s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.702 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.020242, mean_squared_error: 4.392107, mean_q: 2.283515, mean_eps: 0.815221\n",
      "  20635/1000000: episode: 314, duration: 4.439s, episode steps: 75, steps per second: 17, episode reward: 7.000, mean reward: 0.093 [0.000, 4.000], mean action: 1.560 [0.000, 3.000], mean observation: 39.648 [0.000, 142.000], loss: 0.024901, mean_squared_error: 4.520751, mean_q: 2.322309, mean_eps: 0.814627\n",
      "  20716/1000000: episode: 315, duration: 4.707s, episode steps: 81, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.852 [0.000, 3.000], mean observation: 39.634 [0.000, 142.000], loss: 0.029713, mean_squared_error: 4.435646, mean_q: 2.300538, mean_eps: 0.813925\n",
      "  20810/1000000: episode: 316, duration: 5.416s, episode steps: 94, steps per second: 17, episode reward: 3.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.798 [0.000, 3.000], mean observation: 39.601 [0.000, 142.000], loss: 0.021374, mean_squared_error: 4.442866, mean_q: 2.309358, mean_eps: 0.813138\n",
      "  20868/1000000: episode: 317, duration: 3.453s, episode steps: 58, steps per second: 17, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.569 [0.000, 3.000], mean observation: 39.980 [0.000, 142.000], loss: 0.027047, mean_squared_error: 4.571299, mean_q: 2.326076, mean_eps: 0.812454\n",
      "  20920/1000000: episode: 318, duration: 3.112s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.615 [0.000, 3.000], mean observation: 39.806 [0.000, 142.000], loss: 0.019379, mean_squared_error: 4.476047, mean_q: 2.312271, mean_eps: 0.811958\n",
      "  20968/1000000: episode: 319, duration: 2.747s, episode steps: 48, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.396 [0.000, 3.000], mean observation: 39.924 [0.000, 142.000], loss: 0.019299, mean_squared_error: 4.643733, mean_q: 2.357387, mean_eps: 0.811508\n",
      "  21062/1000000: episode: 320, duration: 5.486s, episode steps: 94, steps per second: 17, episode reward: 5.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.649 [0.000, 3.000], mean observation: 39.524 [0.000, 142.000], loss: 0.020090, mean_squared_error: 4.670406, mean_q: 2.369737, mean_eps: 0.810870\n",
      "  21122/1000000: episode: 321, duration: 3.456s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.567 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.023055, mean_squared_error: 4.568759, mean_q: 2.333123, mean_eps: 0.810176\n",
      "  21208/1000000: episode: 322, duration: 5.025s, episode steps: 86, steps per second: 17, episode reward: 2.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.663 [0.000, 3.000], mean observation: 39.803 [0.000, 142.000], loss: 0.029101, mean_squared_error: 4.667736, mean_q: 2.366206, mean_eps: 0.809520\n",
      "  21291/1000000: episode: 323, duration: 4.837s, episode steps: 83, steps per second: 17, episode reward: 3.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.639 [0.000, 3.000], mean observation: 39.822 [0.000, 142.000], loss: 0.022594, mean_squared_error: 4.696753, mean_q: 2.370748, mean_eps: 0.808759\n",
      "  21356/1000000: episode: 324, duration: 3.784s, episode steps: 65, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.708 [0.000, 3.000], mean observation: 39.798 [0.000, 142.000], loss: 0.024060, mean_squared_error: 4.693220, mean_q: 2.368261, mean_eps: 0.808093\n",
      "  21414/1000000: episode: 325, duration: 3.422s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.810 [0.000, 3.000], mean observation: 39.761 [0.000, 142.000], loss: 0.020037, mean_squared_error: 4.708961, mean_q: 2.365179, mean_eps: 0.807539\n",
      "  21476/1000000: episode: 326, duration: 3.686s, episode steps: 62, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.742 [0.000, 3.000], mean observation: 39.814 [0.000, 142.000], loss: 0.024079, mean_squared_error: 4.855082, mean_q: 2.418580, mean_eps: 0.806999\n",
      "  21548/1000000: episode: 327, duration: 4.170s, episode steps: 72, steps per second: 17, episode reward: 2.000, mean reward: 0.028 [0.000, 1.000], mean action: 1.875 [0.000, 3.000], mean observation: 39.689 [0.000, 142.000], loss: 0.021713, mean_squared_error: 4.796071, mean_q: 2.398450, mean_eps: 0.806396\n",
      "  21634/1000000: episode: 328, duration: 4.887s, episode steps: 86, steps per second: 18, episode reward: 3.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.849 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.023345, mean_squared_error: 4.819252, mean_q: 2.403049, mean_eps: 0.805685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  21703/1000000: episode: 329, duration: 4.033s, episode steps: 69, steps per second: 17, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.551 [0.000, 3.000], mean observation: 39.902 [0.000, 142.000], loss: 0.021099, mean_squared_error: 4.871096, mean_q: 2.407959, mean_eps: 0.804988\n",
      "  21765/1000000: episode: 330, duration: 3.623s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.613 [0.000, 3.000], mean observation: 39.718 [0.000, 142.000], loss: 0.025352, mean_squared_error: 4.956622, mean_q: 2.425260, mean_eps: 0.804399\n",
      "  21824/1000000: episode: 331, duration: 3.531s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.627 [0.000, 3.000], mean observation: 39.720 [0.000, 142.000], loss: 0.021757, mean_squared_error: 4.802165, mean_q: 2.390705, mean_eps: 0.803854\n",
      "  21890/1000000: episode: 332, duration: 3.825s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.591 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.023084, mean_squared_error: 4.868438, mean_q: 2.393989, mean_eps: 0.803291\n",
      "  21929/1000000: episode: 333, duration: 2.325s, episode steps: 39, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.821 [0.000, 3.000], mean observation: 40.025 [0.000, 142.000], loss: 0.018042, mean_squared_error: 4.998525, mean_q: 2.439736, mean_eps: 0.802819\n",
      "  22018/1000000: episode: 334, duration: 5.112s, episode steps: 89, steps per second: 17, episode reward: 3.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.775 [0.000, 3.000], mean observation: 39.696 [0.000, 142.000], loss: 0.020592, mean_squared_error: 4.777225, mean_q: 2.383373, mean_eps: 0.802243\n",
      "  22101/1000000: episode: 335, duration: 4.876s, episode steps: 83, steps per second: 17, episode reward: 7.000, mean reward: 0.084 [0.000, 4.000], mean action: 1.542 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.020014, mean_squared_error: 4.832795, mean_q: 2.388697, mean_eps: 0.801469\n",
      "  22210/1000000: episode: 336, duration: 6.333s, episode steps: 109, steps per second: 17, episode reward: 6.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.780 [0.000, 3.000], mean observation: 39.437 [0.000, 142.000], loss: 0.021256, mean_squared_error: 4.968624, mean_q: 2.423333, mean_eps: 0.800605\n",
      "  22293/1000000: episode: 337, duration: 4.813s, episode steps: 83, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.819 [0.000, 3.000], mean observation: 39.676 [0.000, 142.000], loss: 0.019984, mean_squared_error: 4.999517, mean_q: 2.425464, mean_eps: 0.799741\n",
      "  22353/1000000: episode: 338, duration: 3.394s, episode steps: 60, steps per second: 18, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.467 [0.000, 3.000], mean observation: 39.741 [0.000, 142.000], loss: 0.018405, mean_squared_error: 4.868726, mean_q: 2.390889, mean_eps: 0.799098\n",
      "  22432/1000000: episode: 339, duration: 4.525s, episode steps: 79, steps per second: 17, episode reward: 3.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.633 [0.000, 3.000], mean observation: 39.684 [0.000, 142.000], loss: 0.023700, mean_squared_error: 4.923286, mean_q: 2.415057, mean_eps: 0.798472\n",
      "  22490/1000000: episode: 340, duration: 3.374s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.414 [0.000, 3.000], mean observation: 39.818 [0.000, 142.000], loss: 0.028071, mean_squared_error: 4.978556, mean_q: 2.435603, mean_eps: 0.797855\n",
      "  22541/1000000: episode: 341, duration: 3.042s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.549 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.022732, mean_squared_error: 4.995172, mean_q: 2.435577, mean_eps: 0.797365\n",
      "  22613/1000000: episode: 342, duration: 4.260s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.833 [0.000, 3.000], mean observation: 39.757 [0.000, 142.000], loss: 0.020619, mean_squared_error: 5.163229, mean_q: 2.474958, mean_eps: 0.796812\n",
      "  22715/1000000: episode: 343, duration: 5.951s, episode steps: 102, steps per second: 17, episode reward: 6.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.706 [0.000, 3.000], mean observation: 39.506 [0.000, 142.000], loss: 0.023909, mean_squared_error: 5.245235, mean_q: 2.493727, mean_eps: 0.796029\n",
      "  22815/1000000: episode: 344, duration: 5.835s, episode steps: 100, steps per second: 17, episode reward: 6.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.360 [0.000, 3.000], mean observation: 39.558 [0.000, 142.000], loss: 0.024653, mean_squared_error: 5.204842, mean_q: 2.480598, mean_eps: 0.795119\n",
      "  22870/1000000: episode: 345, duration: 3.199s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.028922, mean_squared_error: 5.001996, mean_q: 2.434740, mean_eps: 0.794422\n",
      "  22938/1000000: episode: 346, duration: 3.976s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.662 [0.000, 3.000], mean observation: 39.645 [0.000, 142.000], loss: 0.020321, mean_squared_error: 5.117831, mean_q: 2.453526, mean_eps: 0.793868\n",
      "  22990/1000000: episode: 347, duration: 3.046s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.558 [0.000, 3.000], mean observation: 39.822 [0.000, 142.000], loss: 0.024604, mean_squared_error: 5.041110, mean_q: 2.428256, mean_eps: 0.793328\n",
      "  23048/1000000: episode: 348, duration: 3.402s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.414 [0.000, 3.000], mean observation: 39.763 [0.000, 142.000], loss: 0.027859, mean_squared_error: 5.069566, mean_q: 2.436195, mean_eps: 0.792834\n",
      "  23102/1000000: episode: 349, duration: 3.153s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.407 [0.000, 3.000], mean observation: 39.851 [0.000, 142.000], loss: 0.039290, mean_squared_error: 5.098053, mean_q: 2.452210, mean_eps: 0.792329\n",
      "  23158/1000000: episode: 350, duration: 3.230s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.536 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.021343, mean_squared_error: 5.138605, mean_q: 2.471618, mean_eps: 0.791834\n",
      "  23250/1000000: episode: 351, duration: 5.373s, episode steps: 92, steps per second: 17, episode reward: 2.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.685 [0.000, 3.000], mean observation: 39.712 [0.000, 142.000], loss: 0.021756, mean_squared_error: 5.089111, mean_q: 2.451174, mean_eps: 0.791169\n",
      "  23295/1000000: episode: 352, duration: 2.630s, episode steps: 45, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.711 [0.000, 3.000], mean observation: 40.018 [0.000, 142.000], loss: 0.030299, mean_squared_error: 5.121392, mean_q: 2.468005, mean_eps: 0.790552\n",
      "  23368/1000000: episode: 353, duration: 4.143s, episode steps: 73, steps per second: 18, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.370 [0.000, 3.000], mean observation: 39.681 [0.000, 142.000], loss: 0.023839, mean_squared_error: 5.073079, mean_q: 2.453695, mean_eps: 0.790021\n",
      "  23435/1000000: episode: 354, duration: 3.919s, episode steps: 67, steps per second: 17, episode reward: 1.000, mean reward: 0.015 [0.000, 1.000], mean action: 1.493 [0.000, 3.000], mean observation: 39.875 [0.000, 142.000], loss: 0.024213, mean_squared_error: 5.105289, mean_q: 2.459696, mean_eps: 0.789391\n",
      "  23515/1000000: episode: 355, duration: 4.712s, episode steps: 80, steps per second: 17, episode reward: 4.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.662 [0.000, 142.000], loss: 0.026436, mean_squared_error: 5.158861, mean_q: 2.478312, mean_eps: 0.788729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  23579/1000000: episode: 356, duration: 3.810s, episode steps: 64, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.641 [0.000, 3.000], mean observation: 39.714 [0.000, 142.000], loss: 0.020077, mean_squared_error: 5.327573, mean_q: 2.526491, mean_eps: 0.788081\n",
      "  23646/1000000: episode: 357, duration: 3.924s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.507 [0.000, 3.000], mean observation: 39.767 [0.000, 142.000], loss: 0.023345, mean_squared_error: 5.060687, mean_q: 2.444200, mean_eps: 0.787492\n",
      "  23717/1000000: episode: 358, duration: 4.117s, episode steps: 71, steps per second: 17, episode reward: 2.000, mean reward: 0.028 [0.000, 1.000], mean action: 1.676 [0.000, 3.000], mean observation: 39.737 [0.000, 142.000], loss: 0.020438, mean_squared_error: 5.338773, mean_q: 2.528362, mean_eps: 0.786871\n",
      "  23773/1000000: episode: 359, duration: 3.263s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.250 [0.000, 3.000], mean observation: 39.833 [0.000, 142.000], loss: 0.022630, mean_squared_error: 5.254639, mean_q: 2.501383, mean_eps: 0.786300\n",
      "  23854/1000000: episode: 360, duration: 4.652s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.556 [0.000, 3.000], mean observation: 39.536 [0.000, 142.000], loss: 0.022638, mean_squared_error: 5.215173, mean_q: 2.493144, mean_eps: 0.785683\n",
      "  23929/1000000: episode: 361, duration: 4.398s, episode steps: 75, steps per second: 17, episode reward: 3.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.680 [0.000, 3.000], mean observation: 39.778 [0.000, 142.000], loss: 0.021006, mean_squared_error: 5.204195, mean_q: 2.485653, mean_eps: 0.784981\n",
      "  24005/1000000: episode: 362, duration: 4.405s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.763 [0.000, 3.000], mean observation: 39.699 [0.000, 142.000], loss: 0.022188, mean_squared_error: 5.270516, mean_q: 2.495725, mean_eps: 0.784302\n",
      "  24073/1000000: episode: 363, duration: 4.046s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.574 [0.000, 3.000], mean observation: 39.705 [0.000, 142.000], loss: 0.022293, mean_squared_error: 5.228841, mean_q: 2.483521, mean_eps: 0.783654\n",
      "  24128/1000000: episode: 364, duration: 3.276s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.691 [0.000, 3.000], mean observation: 39.791 [0.000, 142.000], loss: 0.024428, mean_squared_error: 5.387666, mean_q: 2.532592, mean_eps: 0.783100\n",
      "  24213/1000000: episode: 365, duration: 4.958s, episode steps: 85, steps per second: 17, episode reward: 7.000, mean reward: 0.082 [0.000, 4.000], mean action: 1.529 [0.000, 3.000], mean observation: 39.666 [0.000, 142.000], loss: 0.025711, mean_squared_error: 5.248945, mean_q: 2.488256, mean_eps: 0.782470\n",
      "  24300/1000000: episode: 366, duration: 5.118s, episode steps: 87, steps per second: 17, episode reward: 8.000, mean reward: 0.092 [0.000, 4.000], mean action: 1.713 [0.000, 3.000], mean observation: 39.567 [0.000, 142.000], loss: 0.027036, mean_squared_error: 5.412108, mean_q: 2.530824, mean_eps: 0.781696\n",
      "  24368/1000000: episode: 367, duration: 3.984s, episode steps: 68, steps per second: 17, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.838 [0.000, 3.000], mean observation: 39.673 [0.000, 142.000], loss: 0.026670, mean_squared_error: 5.307721, mean_q: 2.506174, mean_eps: 0.780999\n",
      "  24419/1000000: episode: 368, duration: 2.964s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.647 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.032405, mean_squared_error: 5.330645, mean_q: 2.517221, mean_eps: 0.780463\n",
      "  24503/1000000: episode: 369, duration: 4.913s, episode steps: 84, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.655 [0.000, 3.000], mean observation: 39.622 [0.000, 142.000], loss: 0.022189, mean_squared_error: 5.412628, mean_q: 2.534746, mean_eps: 0.779856\n",
      "  24606/1000000: episode: 370, duration: 5.977s, episode steps: 103, steps per second: 17, episode reward: 9.000, mean reward: 0.087 [0.000, 4.000], mean action: 1.670 [0.000, 3.000], mean observation: 39.560 [0.000, 142.000], loss: 0.021180, mean_squared_error: 5.380728, mean_q: 2.526948, mean_eps: 0.779014\n",
      "  24670/1000000: episode: 371, duration: 3.690s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.641 [0.000, 3.000], mean observation: 39.730 [0.000, 142.000], loss: 0.021765, mean_squared_error: 5.341166, mean_q: 2.500477, mean_eps: 0.778263\n",
      "  24749/1000000: episode: 372, duration: 4.619s, episode steps: 79, steps per second: 17, episode reward: 2.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.818 [0.000, 142.000], loss: 0.020456, mean_squared_error: 5.198220, mean_q: 2.475900, mean_eps: 0.777619\n",
      "  24815/1000000: episode: 373, duration: 3.928s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.348 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.029364, mean_squared_error: 5.517846, mean_q: 2.573518, mean_eps: 0.776966\n",
      "  24888/1000000: episode: 374, duration: 4.251s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.863 [0.000, 3.000], mean observation: 39.684 [0.000, 142.000], loss: 0.019065, mean_squared_error: 5.482167, mean_q: 2.539883, mean_eps: 0.776341\n",
      "  25000/1000000: episode: 375, duration: 6.559s, episode steps: 112, steps per second: 17, episode reward: 5.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.732 [0.000, 3.000], mean observation: 39.525 [0.000, 142.000], loss: 0.020733, mean_squared_error: 5.521923, mean_q: 2.569939, mean_eps: 0.775509\n",
      "  25092/1000000: episode: 376, duration: 5.378s, episode steps: 92, steps per second: 17, episode reward: 4.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.815 [0.000, 3.000], mean observation: 39.670 [0.000, 142.000], loss: 0.023963, mean_squared_error: 5.564430, mean_q: 2.578055, mean_eps: 0.774591\n",
      "  25184/1000000: episode: 377, duration: 5.363s, episode steps: 92, steps per second: 17, episode reward: 11.000, mean reward: 0.120 [0.000, 4.000], mean action: 1.576 [0.000, 3.000], mean observation: 39.540 [0.000, 142.000], loss: 0.018947, mean_squared_error: 5.536373, mean_q: 2.567759, mean_eps: 0.773763\n",
      "  25245/1000000: episode: 378, duration: 3.623s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.689 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.018784, mean_squared_error: 5.531607, mean_q: 2.567294, mean_eps: 0.773074\n",
      "  25301/1000000: episode: 379, duration: 3.291s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.739 [0.000, 142.000], loss: 0.026651, mean_squared_error: 5.465122, mean_q: 2.537204, mean_eps: 0.772547\n",
      "  25372/1000000: episode: 380, duration: 4.139s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.648 [0.000, 3.000], mean observation: 39.723 [0.000, 142.000], loss: 0.026054, mean_squared_error: 5.518911, mean_q: 2.555556, mean_eps: 0.771976\n",
      "  25446/1000000: episode: 381, duration: 4.304s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.716 [0.000, 3.000], mean observation: 39.627 [0.000, 142.000], loss: 0.018370, mean_squared_error: 5.615015, mean_q: 2.591165, mean_eps: 0.771323\n",
      "  25500/1000000: episode: 382, duration: 3.186s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.611 [0.000, 3.000], mean observation: 39.793 [0.000, 142.000], loss: 0.020715, mean_squared_error: 5.662319, mean_q: 2.592932, mean_eps: 0.770748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25545/1000000: episode: 383, duration: 2.664s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.578 [0.000, 3.000], mean observation: 39.867 [0.000, 142.000], loss: 0.021618, mean_squared_error: 5.682519, mean_q: 2.590624, mean_eps: 0.770302\n",
      "  25608/1000000: episode: 384, duration: 3.718s, episode steps: 63, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.508 [0.000, 3.000], mean observation: 39.748 [0.000, 142.000], loss: 0.025587, mean_squared_error: 5.622363, mean_q: 2.574962, mean_eps: 0.769816\n",
      "  25661/1000000: episode: 385, duration: 3.055s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.547 [0.000, 3.000], mean observation: 39.775 [0.000, 142.000], loss: 0.025161, mean_squared_error: 5.739607, mean_q: 2.605937, mean_eps: 0.769294\n",
      "  25707/1000000: episode: 386, duration: 2.645s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.391 [0.000, 3.000], mean observation: 39.952 [0.000, 142.000], loss: 0.023770, mean_squared_error: 5.573751, mean_q: 2.567195, mean_eps: 0.768848\n",
      "  25783/1000000: episode: 387, duration: 4.557s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.632 [0.000, 3.000], mean observation: 39.618 [0.000, 142.000], loss: 0.020885, mean_squared_error: 5.559328, mean_q: 2.553857, mean_eps: 0.768300\n",
      "  25855/1000000: episode: 388, duration: 4.241s, episode steps: 72, steps per second: 17, episode reward: 1.000, mean reward: 0.014 [0.000, 1.000], mean action: 1.597 [0.000, 3.000], mean observation: 39.796 [0.000, 142.000], loss: 0.024107, mean_squared_error: 5.726098, mean_q: 2.597135, mean_eps: 0.767634\n",
      "  25943/1000000: episode: 389, duration: 5.067s, episode steps: 88, steps per second: 17, episode reward: 5.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.580 [0.000, 3.000], mean observation: 39.728 [0.000, 142.000], loss: 0.026571, mean_squared_error: 5.719710, mean_q: 2.609236, mean_eps: 0.766914\n",
      "  26044/1000000: episode: 390, duration: 5.918s, episode steps: 101, steps per second: 17, episode reward: 5.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.574 [0.000, 3.000], mean observation: 39.587 [0.000, 142.000], loss: 0.028482, mean_squared_error: 5.606435, mean_q: 2.571815, mean_eps: 0.766063\n",
      "  26148/1000000: episode: 391, duration: 6.035s, episode steps: 104, steps per second: 17, episode reward: 6.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.606 [0.000, 3.000], mean observation: 39.605 [0.000, 142.000], loss: 0.022425, mean_squared_error: 5.655850, mean_q: 2.587554, mean_eps: 0.765141\n",
      "  26227/1000000: episode: 392, duration: 4.547s, episode steps: 79, steps per second: 17, episode reward: 3.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.911 [0.000, 3.000], mean observation: 39.736 [0.000, 142.000], loss: 0.017697, mean_squared_error: 5.777189, mean_q: 2.628802, mean_eps: 0.764317\n",
      "  26300/1000000: episode: 393, duration: 4.228s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.740 [0.000, 3.000], mean observation: 39.784 [0.000, 142.000], loss: 0.027930, mean_squared_error: 5.746669, mean_q: 2.619860, mean_eps: 0.763633\n",
      "  26374/1000000: episode: 394, duration: 4.262s, episode steps: 74, steps per second: 17, episode reward: 7.000, mean reward: 0.095 [0.000, 4.000], mean action: 1.635 [0.000, 3.000], mean observation: 39.675 [0.000, 142.000], loss: 0.020377, mean_squared_error: 5.749807, mean_q: 2.613327, mean_eps: 0.762972\n",
      "  26472/1000000: episode: 395, duration: 5.714s, episode steps: 98, steps per second: 17, episode reward: 6.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.806 [0.000, 3.000], mean observation: 39.507 [0.000, 142.000], loss: 0.025488, mean_squared_error: 5.773313, mean_q: 2.627452, mean_eps: 0.762198\n",
      "  26547/1000000: episode: 396, duration: 4.324s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.467 [0.000, 3.000], mean observation: 39.624 [0.000, 142.000], loss: 0.030473, mean_squared_error: 5.807151, mean_q: 2.637268, mean_eps: 0.761419\n",
      "  26606/1000000: episode: 397, duration: 3.497s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.729 [0.000, 3.000], mean observation: 39.704 [0.000, 142.000], loss: 0.032967, mean_squared_error: 5.935070, mean_q: 2.676022, mean_eps: 0.760816\n",
      "  26667/1000000: episode: 398, duration: 3.502s, episode steps: 61, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.656 [0.000, 3.000], mean observation: 39.944 [0.000, 142.000], loss: 0.024595, mean_squared_error: 5.739478, mean_q: 2.627173, mean_eps: 0.760276\n",
      "  26755/1000000: episode: 399, duration: 5.110s, episode steps: 88, steps per second: 17, episode reward: 3.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.580 [0.000, 3.000], mean observation: 39.710 [0.000, 142.000], loss: 0.025685, mean_squared_error: 5.790856, mean_q: 2.624588, mean_eps: 0.759605\n",
      "  26822/1000000: episode: 400, duration: 3.876s, episode steps: 67, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.716 [0.000, 3.000], mean observation: 39.760 [0.000, 142.000], loss: 0.019636, mean_squared_error: 5.729507, mean_q: 2.624526, mean_eps: 0.758908\n",
      "  26891/1000000: episode: 401, duration: 4.085s, episode steps: 69, steps per second: 17, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.522 [0.000, 3.000], mean observation: 39.779 [0.000, 142.000], loss: 0.026662, mean_squared_error: 5.907873, mean_q: 2.667305, mean_eps: 0.758296\n",
      "  26941/1000000: episode: 402, duration: 2.926s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.740 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.029841, mean_squared_error: 5.878222, mean_q: 2.649335, mean_eps: 0.757760\n",
      "  27013/1000000: episode: 403, duration: 4.263s, episode steps: 72, steps per second: 17, episode reward: 2.000, mean reward: 0.028 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.026302, mean_squared_error: 6.084071, mean_q: 2.708999, mean_eps: 0.757211\n",
      "  27062/1000000: episode: 404, duration: 2.873s, episode steps: 49, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.935 [0.000, 142.000], loss: 0.020751, mean_squared_error: 5.877597, mean_q: 2.652106, mean_eps: 0.756667\n",
      "  27109/1000000: episode: 405, duration: 2.747s, episode steps: 47, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.532 [0.000, 3.000], mean observation: 39.733 [0.000, 142.000], loss: 0.018643, mean_squared_error: 5.875904, mean_q: 2.652325, mean_eps: 0.756235\n",
      "  27175/1000000: episode: 406, duration: 3.762s, episode steps: 66, steps per second: 18, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.515 [0.000, 3.000], mean observation: 39.676 [0.000, 142.000], loss: 0.020745, mean_squared_error: 6.107845, mean_q: 2.712399, mean_eps: 0.755726\n",
      "  27231/1000000: episode: 407, duration: 3.270s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.732 [0.000, 3.000], mean observation: 39.764 [0.000, 142.000], loss: 0.024557, mean_squared_error: 5.990465, mean_q: 2.702766, mean_eps: 0.755178\n",
      "  27298/1000000: episode: 408, duration: 3.948s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.343 [0.000, 3.000], mean observation: 39.827 [0.000, 142.000], loss: 0.023743, mean_squared_error: 6.149416, mean_q: 2.732631, mean_eps: 0.754624\n",
      "  27366/1000000: episode: 409, duration: 3.991s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.559 [0.000, 3.000], mean observation: 39.771 [0.000, 142.000], loss: 0.018604, mean_squared_error: 6.033150, mean_q: 2.700063, mean_eps: 0.754016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  27428/1000000: episode: 410, duration: 3.633s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.790 [0.000, 3.000], mean observation: 39.690 [0.000, 142.000], loss: 0.028638, mean_squared_error: 6.027587, mean_q: 2.690462, mean_eps: 0.753432\n",
      "  27494/1000000: episode: 411, duration: 3.846s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.803 [0.000, 3.000], mean observation: 39.729 [0.000, 142.000], loss: 0.019670, mean_squared_error: 5.988749, mean_q: 2.681106, mean_eps: 0.752856\n",
      "  27568/1000000: episode: 412, duration: 4.362s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.649 [0.000, 3.000], mean observation: 39.620 [0.000, 142.000], loss: 0.022032, mean_squared_error: 5.997611, mean_q: 2.678503, mean_eps: 0.752225\n",
      "  27615/1000000: episode: 413, duration: 2.773s, episode steps: 47, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.489 [0.000, 3.000], mean observation: 39.941 [0.000, 142.000], loss: 0.026073, mean_squared_error: 6.205136, mean_q: 2.730112, mean_eps: 0.751681\n",
      "  27683/1000000: episode: 414, duration: 3.985s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.794 [0.000, 3.000], mean observation: 39.739 [0.000, 142.000], loss: 0.022249, mean_squared_error: 6.160141, mean_q: 2.714138, mean_eps: 0.751163\n",
      "  27754/1000000: episode: 415, duration: 4.178s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.634 [0.000, 3.000], mean observation: 39.770 [0.000, 142.000], loss: 0.020558, mean_squared_error: 6.206317, mean_q: 2.733708, mean_eps: 0.750538\n",
      "  27838/1000000: episode: 416, duration: 4.914s, episode steps: 84, steps per second: 17, episode reward: 3.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.738 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.021418, mean_squared_error: 6.206921, mean_q: 2.741473, mean_eps: 0.749841\n",
      "  27886/1000000: episode: 417, duration: 2.803s, episode steps: 48, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.933 [0.000, 142.000], loss: 0.028676, mean_squared_error: 6.242767, mean_q: 2.741912, mean_eps: 0.749247\n",
      "  27999/1000000: episode: 418, duration: 6.506s, episode steps: 113, steps per second: 17, episode reward: 8.000, mean reward: 0.071 [0.000, 4.000], mean action: 1.664 [0.000, 3.000], mean observation: 39.596 [0.000, 142.000], loss: 0.021905, mean_squared_error: 6.194722, mean_q: 2.736690, mean_eps: 0.748522\n",
      "  28055/1000000: episode: 419, duration: 3.267s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.589 [0.000, 3.000], mean observation: 39.717 [0.000, 142.000], loss: 0.025832, mean_squared_error: 6.418804, mean_q: 2.784914, mean_eps: 0.747762\n",
      "  28126/1000000: episode: 420, duration: 4.180s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.465 [0.000, 3.000], mean observation: 39.702 [0.000, 142.000], loss: 0.020847, mean_squared_error: 6.115594, mean_q: 2.710929, mean_eps: 0.747190\n",
      "  28199/1000000: episode: 421, duration: 4.311s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.658 [0.000, 3.000], mean observation: 39.766 [0.000, 142.000], loss: 0.029632, mean_squared_error: 6.448477, mean_q: 2.789802, mean_eps: 0.746542\n",
      "  28282/1000000: episode: 422, duration: 4.750s, episode steps: 83, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.554 [0.000, 3.000], mean observation: 39.679 [0.000, 142.000], loss: 0.020133, mean_squared_error: 6.414004, mean_q: 2.776432, mean_eps: 0.745840\n",
      "  28355/1000000: episode: 423, duration: 4.204s, episode steps: 73, steps per second: 17, episode reward: 7.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.671 [0.000, 3.000], mean observation: 39.659 [0.000, 142.000], loss: 0.026984, mean_squared_error: 6.257541, mean_q: 2.733960, mean_eps: 0.745138\n",
      "  28424/1000000: episode: 424, duration: 3.991s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.580 [0.000, 3.000], mean observation: 39.644 [0.000, 142.000], loss: 0.022469, mean_squared_error: 6.350372, mean_q: 2.766163, mean_eps: 0.744499\n",
      "  28500/1000000: episode: 425, duration: 4.460s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.684 [0.000, 3.000], mean observation: 39.683 [0.000, 142.000], loss: 0.023075, mean_squared_error: 6.395361, mean_q: 2.773554, mean_eps: 0.743847\n",
      "  28570/1000000: episode: 426, duration: 4.118s, episode steps: 70, steps per second: 17, episode reward: 7.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.557 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.027818, mean_squared_error: 6.481888, mean_q: 2.802182, mean_eps: 0.743189\n",
      "  28621/1000000: episode: 427, duration: 2.924s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.824 [0.000, 3.000], mean observation: 39.741 [0.000, 142.000], loss: 0.021699, mean_squared_error: 6.284072, mean_q: 2.738502, mean_eps: 0.742645\n",
      "  28689/1000000: episode: 428, duration: 4.071s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.794 [0.000, 3.000], mean observation: 39.705 [0.000, 142.000], loss: 0.021320, mean_squared_error: 6.701243, mean_q: 2.845091, mean_eps: 0.742109\n",
      "  28763/1000000: episode: 429, duration: 4.379s, episode steps: 74, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.689 [0.000, 3.000], mean observation: 39.704 [0.000, 142.000], loss: 0.021143, mean_squared_error: 6.423706, mean_q: 2.768668, mean_eps: 0.741471\n",
      "  28858/1000000: episode: 430, duration: 5.522s, episode steps: 95, steps per second: 17, episode reward: 9.000, mean reward: 0.095 [0.000, 4.000], mean action: 1.547 [0.000, 3.000], mean observation: 39.523 [0.000, 142.000], loss: 0.026682, mean_squared_error: 6.548991, mean_q: 2.796249, mean_eps: 0.740710\n",
      "  28949/1000000: episode: 431, duration: 5.348s, episode steps: 91, steps per second: 17, episode reward: 4.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.715 [0.000, 142.000], loss: 0.026205, mean_squared_error: 6.555078, mean_q: 2.807099, mean_eps: 0.739873\n",
      "  28996/1000000: episode: 432, duration: 2.682s, episode steps: 47, steps per second: 18, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.745 [0.000, 3.000], mean observation: 39.834 [0.000, 142.000], loss: 0.021134, mean_squared_error: 6.530359, mean_q: 2.790814, mean_eps: 0.739252\n",
      "  29040/1000000: episode: 433, duration: 2.598s, episode steps: 44, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.773 [0.000, 3.000], mean observation: 39.940 [0.000, 142.000], loss: 0.025377, mean_squared_error: 6.348688, mean_q: 2.753705, mean_eps: 0.738843\n",
      "  29111/1000000: episode: 434, duration: 4.125s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.789 [0.000, 3.000], mean observation: 39.745 [0.000, 142.000], loss: 0.025902, mean_squared_error: 6.667668, mean_q: 2.826055, mean_eps: 0.738325\n",
      "  29182/1000000: episode: 435, duration: 4.145s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.606 [0.000, 3.000], mean observation: 39.684 [0.000, 142.000], loss: 0.029366, mean_squared_error: 6.590200, mean_q: 2.826714, mean_eps: 0.737686\n",
      "  29268/1000000: episode: 436, duration: 5.054s, episode steps: 86, steps per second: 17, episode reward: 7.000, mean reward: 0.081 [0.000, 4.000], mean action: 1.558 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.021782, mean_squared_error: 6.519033, mean_q: 2.787525, mean_eps: 0.736980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  29341/1000000: episode: 437, duration: 4.211s, episode steps: 73, steps per second: 17, episode reward: 8.000, mean reward: 0.110 [0.000, 4.000], mean action: 1.658 [0.000, 3.000], mean observation: 39.576 [0.000, 142.000], loss: 0.027940, mean_squared_error: 6.545693, mean_q: 2.787181, mean_eps: 0.736264\n",
      "  29430/1000000: episode: 438, duration: 5.136s, episode steps: 89, steps per second: 17, episode reward: 7.000, mean reward: 0.079 [0.000, 4.000], mean action: 1.573 [0.000, 3.000], mean observation: 39.633 [0.000, 142.000], loss: 0.026267, mean_squared_error: 6.598003, mean_q: 2.797011, mean_eps: 0.735535\n",
      "  29532/1000000: episode: 439, duration: 5.998s, episode steps: 102, steps per second: 17, episode reward: 5.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.696 [0.000, 3.000], mean observation: 39.680 [0.000, 142.000], loss: 0.022002, mean_squared_error: 6.827913, mean_q: 2.862181, mean_eps: 0.734676\n",
      "  29589/1000000: episode: 440, duration: 3.349s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.018 [0.000, 3.000], mean observation: 39.734 [0.000, 142.000], loss: 0.028867, mean_squared_error: 6.647053, mean_q: 2.814179, mean_eps: 0.733960\n",
      "  29655/1000000: episode: 441, duration: 3.908s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.894 [0.000, 3.000], mean observation: 39.676 [0.000, 142.000], loss: 0.024767, mean_squared_error: 6.595601, mean_q: 2.802895, mean_eps: 0.733406\n",
      "  29716/1000000: episode: 442, duration: 3.538s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.754 [0.000, 3.000], mean observation: 39.731 [0.000, 142.000], loss: 0.025691, mean_squared_error: 6.757932, mean_q: 2.842098, mean_eps: 0.732835\n",
      "  29755/1000000: episode: 443, duration: 2.294s, episode steps: 39, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.462 [0.000, 3.000], mean observation: 40.005 [0.000, 142.000], loss: 0.029575, mean_squared_error: 6.546654, mean_q: 2.794419, mean_eps: 0.732385\n",
      "  29830/1000000: episode: 444, duration: 4.452s, episode steps: 75, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.733 [0.000, 3.000], mean observation: 39.828 [0.000, 142.000], loss: 0.030464, mean_squared_error: 6.579600, mean_q: 2.807313, mean_eps: 0.731872\n",
      "  29924/1000000: episode: 445, duration: 5.494s, episode steps: 94, steps per second: 17, episode reward: 12.000, mean reward: 0.128 [0.000, 4.000], mean action: 1.787 [0.000, 3.000], mean observation: 39.545 [0.000, 142.000], loss: 0.021787, mean_squared_error: 6.670710, mean_q: 2.823525, mean_eps: 0.731112\n",
      "  30021/1000000: episode: 446, duration: 5.602s, episode steps: 97, steps per second: 17, episode reward: 5.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.711 [0.000, 3.000], mean observation: 39.544 [0.000, 142.000], loss: 0.022900, mean_squared_error: 6.640981, mean_q: 2.818480, mean_eps: 0.730252\n",
      "  30090/1000000: episode: 447, duration: 4.079s, episode steps: 69, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.478 [0.000, 3.000], mean observation: 39.725 [0.000, 142.000], loss: 0.026495, mean_squared_error: 6.708708, mean_q: 2.821638, mean_eps: 0.729505\n",
      "  30169/1000000: episode: 448, duration: 4.565s, episode steps: 79, steps per second: 17, episode reward: 4.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.722 [0.000, 3.000], mean observation: 39.660 [0.000, 142.000], loss: 0.023969, mean_squared_error: 6.772437, mean_q: 2.842010, mean_eps: 0.728839\n",
      "  30223/1000000: episode: 449, duration: 3.105s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.519 [0.000, 3.000], mean observation: 39.846 [0.000, 142.000], loss: 0.026400, mean_squared_error: 6.560541, mean_q: 2.789341, mean_eps: 0.728240\n",
      "  30288/1000000: episode: 450, duration: 3.836s, episode steps: 65, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.615 [0.000, 3.000], mean observation: 39.837 [0.000, 142.000], loss: 0.027963, mean_squared_error: 6.737137, mean_q: 2.817226, mean_eps: 0.727705\n",
      "  30397/1000000: episode: 451, duration: 6.404s, episode steps: 109, steps per second: 17, episode reward: 7.000, mean reward: 0.064 [0.000, 1.000], mean action: 1.642 [0.000, 3.000], mean observation: 39.433 [0.000, 142.000], loss: 0.026279, mean_squared_error: 6.862617, mean_q: 2.844396, mean_eps: 0.726922\n",
      "  30465/1000000: episode: 452, duration: 3.987s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.441 [0.000, 3.000], mean observation: 39.712 [0.000, 142.000], loss: 0.023786, mean_squared_error: 6.612361, mean_q: 2.798842, mean_eps: 0.726126\n",
      "  30517/1000000: episode: 453, duration: 3.134s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.538 [0.000, 3.000], mean observation: 39.851 [0.000, 142.000], loss: 0.023810, mean_squared_error: 6.683322, mean_q: 2.807598, mean_eps: 0.725585\n",
      "  30586/1000000: episode: 454, duration: 3.972s, episode steps: 69, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.710 [0.000, 3.000], mean observation: 39.730 [0.000, 142.000], loss: 0.027796, mean_squared_error: 6.810537, mean_q: 2.838475, mean_eps: 0.725041\n",
      "  30641/1000000: episode: 455, duration: 3.225s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.364 [0.000, 3.000], mean observation: 39.723 [0.000, 142.000], loss: 0.024026, mean_squared_error: 6.953469, mean_q: 2.871227, mean_eps: 0.724483\n",
      "  30707/1000000: episode: 456, duration: 3.809s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.803 [0.000, 3.000], mean observation: 39.760 [0.000, 142.000], loss: 0.023306, mean_squared_error: 6.910629, mean_q: 2.880418, mean_eps: 0.723939\n",
      "  30784/1000000: episode: 457, duration: 4.431s, episode steps: 77, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.597 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.026157, mean_squared_error: 6.880829, mean_q: 2.867037, mean_eps: 0.723295\n",
      "  30861/1000000: episode: 458, duration: 4.597s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.558 [0.000, 3.000], mean observation: 39.605 [0.000, 142.000], loss: 0.027651, mean_squared_error: 6.918020, mean_q: 2.854997, mean_eps: 0.722602\n",
      "  30970/1000000: episode: 459, duration: 6.312s, episode steps: 109, steps per second: 17, episode reward: 4.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.706 [0.000, 3.000], mean observation: 39.580 [0.000, 142.000], loss: 0.036364, mean_squared_error: 6.779213, mean_q: 2.838744, mean_eps: 0.721765\n",
      "  31042/1000000: episode: 460, duration: 4.223s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.708 [0.000, 3.000], mean observation: 39.722 [0.000, 142.000], loss: 0.021759, mean_squared_error: 7.037691, mean_q: 2.901649, mean_eps: 0.720950\n",
      "  31096/1000000: episode: 461, duration: 3.123s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.296 [0.000, 3.000], mean observation: 39.819 [0.000, 142.000], loss: 0.021013, mean_squared_error: 6.969541, mean_q: 2.888876, mean_eps: 0.720383\n",
      "  31174/1000000: episode: 462, duration: 4.543s, episode steps: 78, steps per second: 17, episode reward: 7.000, mean reward: 0.090 [0.000, 4.000], mean action: 1.654 [0.000, 3.000], mean observation: 39.635 [0.000, 142.000], loss: 0.030176, mean_squared_error: 6.817545, mean_q: 2.858337, mean_eps: 0.719790\n",
      "  31255/1000000: episode: 463, duration: 4.710s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.753 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.023909, mean_squared_error: 6.954763, mean_q: 2.884184, mean_eps: 0.719074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  31314/1000000: episode: 464, duration: 3.486s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.932 [0.000, 3.000], mean observation: 39.763 [0.000, 142.000], loss: 0.021986, mean_squared_error: 6.853311, mean_q: 2.858088, mean_eps: 0.718444\n",
      "  31392/1000000: episode: 465, duration: 4.481s, episode steps: 78, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.654 [0.000, 3.000], mean observation: 39.846 [0.000, 142.000], loss: 0.027126, mean_squared_error: 6.954181, mean_q: 2.878358, mean_eps: 0.717827\n",
      "  31465/1000000: episode: 466, duration: 4.242s, episode steps: 73, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.671 [0.000, 3.000], mean observation: 39.888 [0.000, 142.000], loss: 0.027777, mean_squared_error: 7.125254, mean_q: 2.919529, mean_eps: 0.717148\n",
      "  31511/1000000: episode: 467, duration: 2.727s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.565 [0.000, 3.000], mean observation: 39.750 [0.000, 142.000], loss: 0.030428, mean_squared_error: 7.044725, mean_q: 2.898256, mean_eps: 0.716613\n",
      "  31566/1000000: episode: 468, duration: 3.250s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.745 [0.000, 3.000], mean observation: 39.947 [0.000, 142.000], loss: 0.027436, mean_squared_error: 6.984155, mean_q: 2.882759, mean_eps: 0.716158\n",
      "  31652/1000000: episode: 469, duration: 4.932s, episode steps: 86, steps per second: 17, episode reward: 7.000, mean reward: 0.081 [0.000, 4.000], mean action: 1.663 [0.000, 3.000], mean observation: 39.669 [0.000, 142.000], loss: 0.022289, mean_squared_error: 6.956556, mean_q: 2.875176, mean_eps: 0.715523\n",
      "  31725/1000000: episode: 470, duration: 4.205s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.493 [0.000, 3.000], mean observation: 39.676 [0.000, 142.000], loss: 0.024960, mean_squared_error: 7.119967, mean_q: 2.927579, mean_eps: 0.714808\n",
      "  31821/1000000: episode: 471, duration: 5.687s, episode steps: 96, steps per second: 17, episode reward: 5.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.615 [0.000, 3.000], mean observation: 39.534 [0.000, 142.000], loss: 0.031687, mean_squared_error: 7.039107, mean_q: 2.894959, mean_eps: 0.714047\n",
      "  31888/1000000: episode: 472, duration: 3.912s, episode steps: 67, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.836 [0.000, 3.000], mean observation: 39.756 [0.000, 142.000], loss: 0.032735, mean_squared_error: 7.033924, mean_q: 2.885977, mean_eps: 0.713314\n",
      "  31971/1000000: episode: 473, duration: 4.775s, episode steps: 83, steps per second: 17, episode reward: 3.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.542 [0.000, 3.000], mean observation: 39.726 [0.000, 142.000], loss: 0.025706, mean_squared_error: 6.981709, mean_q: 2.891510, mean_eps: 0.712639\n",
      "  32051/1000000: episode: 474, duration: 4.592s, episode steps: 80, steps per second: 17, episode reward: 4.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.575 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.030441, mean_squared_error: 6.941386, mean_q: 2.880062, mean_eps: 0.711906\n",
      "  32129/1000000: episode: 475, duration: 4.462s, episode steps: 78, steps per second: 17, episode reward: 2.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.814 [0.000, 142.000], loss: 0.025967, mean_squared_error: 7.218531, mean_q: 2.935519, mean_eps: 0.711195\n",
      "  32224/1000000: episode: 476, duration: 5.561s, episode steps: 95, steps per second: 17, episode reward: 7.000, mean reward: 0.074 [0.000, 4.000], mean action: 1.842 [0.000, 3.000], mean observation: 39.627 [0.000, 142.000], loss: 0.022907, mean_squared_error: 7.389437, mean_q: 2.988823, mean_eps: 0.710416\n",
      "  32284/1000000: episode: 477, duration: 3.553s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.600 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.024824, mean_squared_error: 7.508197, mean_q: 3.009960, mean_eps: 0.709719\n",
      "  32346/1000000: episode: 478, duration: 3.616s, episode steps: 62, steps per second: 17, episode reward: 1.000, mean reward: 0.016 [0.000, 1.000], mean action: 1.694 [0.000, 3.000], mean observation: 39.807 [0.000, 142.000], loss: 0.028308, mean_squared_error: 7.297102, mean_q: 2.952655, mean_eps: 0.709170\n",
      "  32412/1000000: episode: 479, duration: 3.874s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.727 [0.000, 3.000], mean observation: 39.721 [0.000, 142.000], loss: 0.023670, mean_squared_error: 7.096364, mean_q: 2.917960, mean_eps: 0.708593\n",
      "  32471/1000000: episode: 480, duration: 3.495s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.661 [0.000, 3.000], mean observation: 39.755 [0.000, 142.000], loss: 0.034117, mean_squared_error: 7.255178, mean_q: 2.965960, mean_eps: 0.708031\n",
      "  32533/1000000: episode: 481, duration: 3.641s, episode steps: 62, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.694 [0.000, 3.000], mean observation: 39.878 [0.000, 142.000], loss: 0.024839, mean_squared_error: 7.470211, mean_q: 2.998673, mean_eps: 0.707487\n",
      "  32622/1000000: episode: 482, duration: 5.201s, episode steps: 89, steps per second: 17, episode reward: 3.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.640 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.024214, mean_squared_error: 7.315741, mean_q: 2.954406, mean_eps: 0.706807\n",
      "  32676/1000000: episode: 483, duration: 3.150s, episode steps: 54, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.944 [0.000, 3.000], mean observation: 39.988 [0.000, 142.000], loss: 0.024578, mean_squared_error: 7.323383, mean_q: 2.971414, mean_eps: 0.706164\n",
      "  32735/1000000: episode: 484, duration: 3.369s, episode steps: 59, steps per second: 18, episode reward: 1.000, mean reward: 0.017 [0.000, 1.000], mean action: 1.458 [0.000, 3.000], mean observation: 39.848 [0.000, 142.000], loss: 0.027603, mean_squared_error: 7.357714, mean_q: 2.963697, mean_eps: 0.705655\n",
      "  32809/1000000: episode: 485, duration: 4.279s, episode steps: 74, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.595 [0.000, 3.000], mean observation: 39.723 [0.000, 142.000], loss: 0.026337, mean_squared_error: 7.249888, mean_q: 2.940918, mean_eps: 0.705057\n",
      "  32861/1000000: episode: 486, duration: 2.994s, episode steps: 52, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.596 [0.000, 3.000], mean observation: 39.953 [0.000, 142.000], loss: 0.027303, mean_squared_error: 7.389299, mean_q: 2.970045, mean_eps: 0.704489\n",
      "  32937/1000000: episode: 487, duration: 4.361s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.882 [0.000, 3.000], mean observation: 39.614 [0.000, 142.000], loss: 0.033001, mean_squared_error: 7.432193, mean_q: 2.987490, mean_eps: 0.703914\n",
      "  33014/1000000: episode: 488, duration: 4.589s, episode steps: 77, steps per second: 17, episode reward: 11.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.805 [0.000, 3.000], mean observation: 39.561 [0.000, 142.000], loss: 0.032575, mean_squared_error: 7.326180, mean_q: 2.958939, mean_eps: 0.703225\n",
      "  33067/1000000: episode: 489, duration: 3.058s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.472 [0.000, 3.000], mean observation: 39.856 [0.000, 142.000], loss: 0.025601, mean_squared_error: 7.435056, mean_q: 2.972984, mean_eps: 0.702640\n",
      "  33173/1000000: episode: 490, duration: 6.110s, episode steps: 106, steps per second: 17, episode reward: 5.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.755 [0.000, 3.000], mean observation: 39.648 [0.000, 142.000], loss: 0.027029, mean_squared_error: 7.459083, mean_q: 2.984452, mean_eps: 0.701925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  33226/1000000: episode: 491, duration: 3.133s, episode steps: 53, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.377 [0.000, 3.000], mean observation: 39.784 [0.000, 142.000], loss: 0.020824, mean_squared_error: 7.573546, mean_q: 3.011580, mean_eps: 0.701209\n",
      "  33311/1000000: episode: 492, duration: 5.022s, episode steps: 85, steps per second: 17, episode reward: 8.000, mean reward: 0.094 [0.000, 4.000], mean action: 1.659 [0.000, 3.000], mean observation: 39.606 [0.000, 142.000], loss: 0.031208, mean_squared_error: 7.521084, mean_q: 2.985803, mean_eps: 0.700588\n",
      "  33375/1000000: episode: 493, duration: 3.734s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.734 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.025034, mean_squared_error: 7.472137, mean_q: 2.985579, mean_eps: 0.699917\n",
      "  33427/1000000: episode: 494, duration: 3.006s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.654 [0.000, 3.000], mean observation: 39.751 [0.000, 142.000], loss: 0.028788, mean_squared_error: 7.359248, mean_q: 2.958772, mean_eps: 0.699395\n",
      "  33511/1000000: episode: 495, duration: 4.872s, episode steps: 84, steps per second: 17, episode reward: 7.000, mean reward: 0.083 [0.000, 4.000], mean action: 1.690 [0.000, 3.000], mean observation: 39.703 [0.000, 142.000], loss: 0.033387, mean_squared_error: 7.617210, mean_q: 3.026376, mean_eps: 0.698784\n",
      "  33581/1000000: episode: 496, duration: 4.075s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.671 [0.000, 3.000], mean observation: 39.673 [0.000, 142.000], loss: 0.029087, mean_squared_error: 7.510058, mean_q: 2.994818, mean_eps: 0.698090\n",
      "  33648/1000000: episode: 497, duration: 3.882s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.478 [0.000, 3.000], mean observation: 39.812 [0.000, 142.000], loss: 0.031759, mean_squared_error: 7.772463, mean_q: 3.042467, mean_eps: 0.697474\n",
      "  33703/1000000: episode: 498, duration: 3.246s, episode steps: 55, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.709 [0.000, 3.000], mean observation: 39.910 [0.000, 142.000], loss: 0.028440, mean_squared_error: 7.830672, mean_q: 3.059976, mean_eps: 0.696925\n",
      "  33763/1000000: episode: 499, duration: 3.502s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.383 [0.000, 3.000], mean observation: 39.744 [0.000, 142.000], loss: 0.028839, mean_squared_error: 7.802792, mean_q: 3.061095, mean_eps: 0.696407\n",
      "  33847/1000000: episode: 500, duration: 4.892s, episode steps: 84, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.611 [0.000, 142.000], loss: 0.023423, mean_squared_error: 7.735298, mean_q: 3.049197, mean_eps: 0.695759\n",
      "  33923/1000000: episode: 501, duration: 4.507s, episode steps: 76, steps per second: 17, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.738 [0.000, 142.000], loss: 0.028773, mean_squared_error: 7.575632, mean_q: 3.017751, mean_eps: 0.695039\n",
      "  34015/1000000: episode: 502, duration: 5.230s, episode steps: 92, steps per second: 18, episode reward: 8.000, mean reward: 0.087 [0.000, 4.000], mean action: 1.783 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.026932, mean_squared_error: 7.642800, mean_q: 3.010076, mean_eps: 0.694283\n",
      "  34068/1000000: episode: 503, duration: 3.082s, episode steps: 53, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.642 [0.000, 3.000], mean observation: 39.766 [0.000, 142.000], loss: 0.025431, mean_squared_error: 7.735034, mean_q: 3.037901, mean_eps: 0.693631\n",
      "  34111/1000000: episode: 504, duration: 2.542s, episode steps: 43, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.884 [0.000, 3.000], mean observation: 40.006 [0.000, 142.000], loss: 0.025892, mean_squared_error: 7.935160, mean_q: 3.066202, mean_eps: 0.693199\n",
      "  34202/1000000: episode: 505, duration: 5.329s, episode steps: 91, steps per second: 17, episode reward: 7.000, mean reward: 0.077 [0.000, 4.000], mean action: 1.549 [0.000, 3.000], mean observation: 39.714 [0.000, 142.000], loss: 0.031663, mean_squared_error: 7.810045, mean_q: 3.045221, mean_eps: 0.692596\n",
      "  34266/1000000: episode: 506, duration: 3.688s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.531 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.034299, mean_squared_error: 7.454911, mean_q: 2.978758, mean_eps: 0.691898\n",
      "  34325/1000000: episode: 507, duration: 3.460s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.458 [0.000, 3.000], mean observation: 39.761 [0.000, 142.000], loss: 0.027635, mean_squared_error: 7.579725, mean_q: 3.009785, mean_eps: 0.691345\n",
      "  34403/1000000: episode: 508, duration: 4.616s, episode steps: 78, steps per second: 17, episode reward: 3.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.679 [0.000, 3.000], mean observation: 39.700 [0.000, 142.000], loss: 0.030221, mean_squared_error: 7.780348, mean_q: 3.055511, mean_eps: 0.690728\n",
      "  34467/1000000: episode: 509, duration: 3.834s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.234 [0.000, 3.000], mean observation: 39.771 [0.000, 142.000], loss: 0.025332, mean_squared_error: 7.607704, mean_q: 3.019041, mean_eps: 0.690090\n",
      "  34521/1000000: episode: 510, duration: 3.128s, episode steps: 54, steps per second: 17, episode reward: 1.000, mean reward: 0.019 [0.000, 1.000], mean action: 1.556 [0.000, 3.000], mean observation: 39.954 [0.000, 142.000], loss: 0.029849, mean_squared_error: 7.804124, mean_q: 3.050646, mean_eps: 0.689558\n",
      "  34615/1000000: episode: 511, duration: 5.512s, episode steps: 94, steps per second: 17, episode reward: 4.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.596 [0.000, 3.000], mean observation: 39.595 [0.000, 142.000], loss: 0.031480, mean_squared_error: 7.693186, mean_q: 3.033761, mean_eps: 0.688892\n",
      "  34673/1000000: episode: 512, duration: 3.375s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.810 [0.000, 3.000], mean observation: 39.732 [0.000, 142.000], loss: 0.023756, mean_squared_error: 7.793707, mean_q: 3.052935, mean_eps: 0.688209\n",
      "  34735/1000000: episode: 513, duration: 3.621s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.742 [0.000, 3.000], mean observation: 39.722 [0.000, 142.000], loss: 0.025368, mean_squared_error: 7.956125, mean_q: 3.102942, mean_eps: 0.687669\n",
      "  34797/1000000: episode: 514, duration: 3.516s, episode steps: 62, steps per second: 18, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.887 [0.000, 3.000], mean observation: 39.711 [0.000, 142.000], loss: 0.029676, mean_squared_error: 7.664043, mean_q: 3.038310, mean_eps: 0.687110\n",
      "  34863/1000000: episode: 515, duration: 3.874s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.652 [0.000, 3.000], mean observation: 39.712 [0.000, 142.000], loss: 0.027280, mean_squared_error: 7.773003, mean_q: 3.064161, mean_eps: 0.686534\n",
      "  34956/1000000: episode: 516, duration: 5.375s, episode steps: 93, steps per second: 17, episode reward: 4.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.796 [0.000, 3.000], mean observation: 39.670 [0.000, 142.000], loss: 0.029946, mean_squared_error: 7.872031, mean_q: 3.077012, mean_eps: 0.685819\n",
      "  35053/1000000: episode: 517, duration: 5.662s, episode steps: 97, steps per second: 17, episode reward: 6.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.515 [0.000, 3.000], mean observation: 39.486 [0.000, 142.000], loss: 0.032858, mean_squared_error: 7.945979, mean_q: 3.092517, mean_eps: 0.684964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  35149/1000000: episode: 518, duration: 5.635s, episode steps: 96, steps per second: 17, episode reward: 6.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.625 [0.000, 3.000], mean observation: 39.517 [0.000, 142.000], loss: 0.034106, mean_squared_error: 7.961876, mean_q: 3.086145, mean_eps: 0.684095\n",
      "  35205/1000000: episode: 519, duration: 3.336s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.161 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.024194, mean_squared_error: 7.907967, mean_q: 3.074132, mean_eps: 0.683412\n",
      "  35308/1000000: episode: 520, duration: 6.065s, episode steps: 103, steps per second: 17, episode reward: 6.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.515 [0.000, 3.000], mean observation: 39.481 [0.000, 142.000], loss: 0.029672, mean_squared_error: 7.928703, mean_q: 3.071667, mean_eps: 0.682696\n",
      "  35378/1000000: episode: 521, duration: 4.078s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.543 [0.000, 3.000], mean observation: 39.650 [0.000, 142.000], loss: 0.022513, mean_squared_error: 8.120106, mean_q: 3.122243, mean_eps: 0.681917\n",
      "  35459/1000000: episode: 522, duration: 4.703s, episode steps: 81, steps per second: 17, episode reward: 11.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.605 [0.000, 3.000], mean observation: 39.587 [0.000, 142.000], loss: 0.027750, mean_squared_error: 7.918475, mean_q: 3.077802, mean_eps: 0.681238\n",
      "  35507/1000000: episode: 523, duration: 2.894s, episode steps: 48, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.875 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.035808, mean_squared_error: 7.974674, mean_q: 3.107390, mean_eps: 0.680658\n",
      "  35582/1000000: episode: 524, duration: 4.286s, episode steps: 75, steps per second: 17, episode reward: 3.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.640 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.031932, mean_squared_error: 7.784451, mean_q: 3.068166, mean_eps: 0.680104\n",
      "  35677/1000000: episode: 525, duration: 5.462s, episode steps: 95, steps per second: 17, episode reward: 9.000, mean reward: 0.095 [0.000, 4.000], mean action: 1.463 [0.000, 3.000], mean observation: 39.527 [0.000, 142.000], loss: 0.025022, mean_squared_error: 7.797523, mean_q: 3.051132, mean_eps: 0.679339\n",
      "  35748/1000000: episode: 526, duration: 4.176s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.521 [0.000, 3.000], mean observation: 39.670 [0.000, 142.000], loss: 0.021731, mean_squared_error: 7.858584, mean_q: 3.068627, mean_eps: 0.678592\n",
      "  35795/1000000: episode: 527, duration: 2.817s, episode steps: 47, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.553 [0.000, 3.000], mean observation: 39.724 [0.000, 142.000], loss: 0.034388, mean_squared_error: 8.034648, mean_q: 3.110182, mean_eps: 0.678061\n",
      "  35863/1000000: episode: 528, duration: 3.938s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.324 [0.000, 3.000], mean observation: 39.644 [0.000, 142.000], loss: 0.026156, mean_squared_error: 8.128382, mean_q: 3.124934, mean_eps: 0.677543\n",
      "  35917/1000000: episode: 529, duration: 3.077s, episode steps: 54, steps per second: 18, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.648 [0.000, 3.000], mean observation: 39.774 [0.000, 142.000], loss: 0.035648, mean_squared_error: 7.707273, mean_q: 3.032487, mean_eps: 0.676994\n",
      "  36000/1000000: episode: 530, duration: 4.812s, episode steps: 83, steps per second: 17, episode reward: 3.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.843 [0.000, 3.000], mean observation: 39.802 [0.000, 142.000], loss: 0.028886, mean_squared_error: 8.192173, mean_q: 3.144694, mean_eps: 0.676378\n",
      "  36068/1000000: episode: 531, duration: 3.900s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.691 [0.000, 3.000], mean observation: 39.802 [0.000, 142.000], loss: 0.029878, mean_squared_error: 8.113130, mean_q: 3.143397, mean_eps: 0.675698\n",
      "  36142/1000000: episode: 532, duration: 4.345s, episode steps: 74, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.446 [0.000, 3.000], mean observation: 39.794 [0.000, 142.000], loss: 0.030981, mean_squared_error: 7.866101, mean_q: 3.064733, mean_eps: 0.675060\n",
      "  36237/1000000: episode: 533, duration: 5.560s, episode steps: 95, steps per second: 17, episode reward: 5.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.516 [0.000, 3.000], mean observation: 39.486 [0.000, 142.000], loss: 0.025195, mean_squared_error: 7.994998, mean_q: 3.094319, mean_eps: 0.674299\n",
      "  36299/1000000: episode: 534, duration: 3.618s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.677 [0.000, 3.000], mean observation: 39.705 [0.000, 142.000], loss: 0.030697, mean_squared_error: 7.924129, mean_q: 3.086178, mean_eps: 0.673593\n",
      "  36366/1000000: episode: 535, duration: 3.979s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.522 [0.000, 3.000], mean observation: 39.644 [0.000, 142.000], loss: 0.030982, mean_squared_error: 8.098647, mean_q: 3.117913, mean_eps: 0.673012\n",
      "  36449/1000000: episode: 536, duration: 4.879s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.578 [0.000, 3.000], mean observation: 39.650 [0.000, 142.000], loss: 0.027890, mean_squared_error: 8.076538, mean_q: 3.118585, mean_eps: 0.672337\n",
      "  36530/1000000: episode: 537, duration: 4.680s, episode steps: 81, steps per second: 17, episode reward: 7.000, mean reward: 0.086 [0.000, 4.000], mean action: 1.679 [0.000, 3.000], mean observation: 39.606 [0.000, 142.000], loss: 0.026569, mean_squared_error: 8.008104, mean_q: 3.113047, mean_eps: 0.671599\n",
      "  36602/1000000: episode: 538, duration: 4.208s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.681 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.024859, mean_squared_error: 8.082613, mean_q: 3.113751, mean_eps: 0.670910\n",
      "  36670/1000000: episode: 539, duration: 3.972s, episode steps: 68, steps per second: 17, episode reward: 3.000, mean reward: 0.044 [0.000, 1.000], mean action: 1.647 [0.000, 3.000], mean observation: 39.809 [0.000, 142.000], loss: 0.028803, mean_squared_error: 8.088148, mean_q: 3.107729, mean_eps: 0.670281\n",
      "  36728/1000000: episode: 540, duration: 3.422s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.603 [0.000, 3.000], mean observation: 39.701 [0.000, 142.000], loss: 0.031394, mean_squared_error: 7.851706, mean_q: 3.058927, mean_eps: 0.669714\n",
      "  36800/1000000: episode: 541, duration: 4.127s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.653 [0.000, 3.000], mean observation: 39.763 [0.000, 142.000], loss: 0.035213, mean_squared_error: 8.160860, mean_q: 3.136625, mean_eps: 0.669128\n",
      "  36862/1000000: episode: 542, duration: 3.586s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.919 [0.000, 3.000], mean observation: 39.680 [0.000, 142.000], loss: 0.024606, mean_squared_error: 8.052858, mean_q: 3.118295, mean_eps: 0.668525\n",
      "  36939/1000000: episode: 543, duration: 4.380s, episode steps: 77, steps per second: 18, episode reward: 3.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.792 [0.000, 3.000], mean observation: 39.718 [0.000, 142.000], loss: 0.026803, mean_squared_error: 8.072455, mean_q: 3.123989, mean_eps: 0.667900\n",
      "  37008/1000000: episode: 544, duration: 4.060s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.652 [0.000, 142.000], loss: 0.025643, mean_squared_error: 8.000401, mean_q: 3.089820, mean_eps: 0.667243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  37056/1000000: episode: 545, duration: 2.815s, episode steps: 48, steps per second: 17, episode reward: 1.000, mean reward: 0.021 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.672 [0.000, 142.000], loss: 0.028707, mean_squared_error: 8.035435, mean_q: 3.111827, mean_eps: 0.666717\n",
      "  37092/1000000: episode: 546, duration: 2.119s, episode steps: 36, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.528 [0.000, 3.000], mean observation: 40.001 [0.000, 142.000], loss: 0.028389, mean_squared_error: 8.215436, mean_q: 3.149593, mean_eps: 0.666338\n",
      "  37148/1000000: episode: 547, duration: 3.307s, episode steps: 56, steps per second: 17, episode reward: 1.000, mean reward: 0.018 [0.000, 1.000], mean action: 1.875 [0.000, 3.000], mean observation: 39.731 [0.000, 142.000], loss: 0.031533, mean_squared_error: 8.103960, mean_q: 3.121374, mean_eps: 0.665925\n",
      "  37212/1000000: episode: 548, duration: 3.684s, episode steps: 64, steps per second: 17, episode reward: 7.000, mean reward: 0.109 [0.000, 4.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.645 [0.000, 142.000], loss: 0.030635, mean_squared_error: 8.041395, mean_q: 3.096620, mean_eps: 0.665385\n",
      "  37262/1000000: episode: 549, duration: 2.976s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.880 [0.000, 3.000], mean observation: 39.747 [0.000, 142.000], loss: 0.026167, mean_squared_error: 8.213033, mean_q: 3.145779, mean_eps: 0.664871\n",
      "  37353/1000000: episode: 550, duration: 5.271s, episode steps: 91, steps per second: 17, episode reward: 7.000, mean reward: 0.077 [0.000, 4.000], mean action: 1.791 [0.000, 3.000], mean observation: 39.695 [0.000, 142.000], loss: 0.029683, mean_squared_error: 8.269921, mean_q: 3.149902, mean_eps: 0.664237\n",
      "  37411/1000000: episode: 551, duration: 3.395s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.414 [0.000, 3.000], mean observation: 39.682 [0.000, 142.000], loss: 0.029495, mean_squared_error: 8.222228, mean_q: 3.133850, mean_eps: 0.663567\n",
      "  37477/1000000: episode: 552, duration: 3.923s, episode steps: 66, steps per second: 17, episode reward: 2.000, mean reward: 0.030 [0.000, 1.000], mean action: 1.924 [0.000, 3.000], mean observation: 39.887 [0.000, 142.000], loss: 0.026224, mean_squared_error: 8.109159, mean_q: 3.098159, mean_eps: 0.663009\n",
      "  37550/1000000: episode: 553, duration: 4.226s, episode steps: 73, steps per second: 17, episode reward: 7.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.726 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.031266, mean_squared_error: 8.053132, mean_q: 3.117963, mean_eps: 0.662383\n",
      "  37614/1000000: episode: 554, duration: 3.662s, episode steps: 64, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.812 [0.000, 3.000], mean observation: 39.635 [0.000, 142.000], loss: 0.027369, mean_squared_error: 8.387084, mean_q: 3.175363, mean_eps: 0.661767\n",
      "  37695/1000000: episode: 555, duration: 4.754s, episode steps: 81, steps per second: 17, episode reward: 7.000, mean reward: 0.086 [0.000, 4.000], mean action: 1.753 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.032183, mean_squared_error: 8.218627, mean_q: 3.141215, mean_eps: 0.661114\n",
      "  37766/1000000: episode: 556, duration: 4.125s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.761 [0.000, 3.000], mean observation: 39.685 [0.000, 142.000], loss: 0.025720, mean_squared_error: 8.219250, mean_q: 3.144578, mean_eps: 0.660430\n",
      "  37823/1000000: episode: 557, duration: 3.257s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.632 [0.000, 3.000], mean observation: 39.735 [0.000, 142.000], loss: 0.027864, mean_squared_error: 8.226308, mean_q: 3.142523, mean_eps: 0.659854\n",
      "  37902/1000000: episode: 558, duration: 4.617s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.696 [0.000, 3.000], mean observation: 39.622 [0.000, 142.000], loss: 0.032841, mean_squared_error: 8.469429, mean_q: 3.181010, mean_eps: 0.659242\n",
      "  37993/1000000: episode: 559, duration: 5.248s, episode steps: 91, steps per second: 17, episode reward: 6.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.813 [0.000, 3.000], mean observation: 39.494 [0.000, 142.000], loss: 0.030417, mean_squared_error: 8.540403, mean_q: 3.203326, mean_eps: 0.658477\n",
      "  38055/1000000: episode: 560, duration: 3.587s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.742 [0.000, 3.000], mean observation: 39.714 [0.000, 142.000], loss: 0.033924, mean_squared_error: 8.296395, mean_q: 3.160128, mean_eps: 0.657788\n",
      "  38114/1000000: episode: 561, duration: 3.511s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.661 [0.000, 3.000], mean observation: 39.747 [0.000, 142.000], loss: 0.029032, mean_squared_error: 8.436038, mean_q: 3.182041, mean_eps: 0.657244\n",
      "  38182/1000000: episode: 562, duration: 3.991s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.471 [0.000, 3.000], mean observation: 39.649 [0.000, 142.000], loss: 0.032282, mean_squared_error: 8.346039, mean_q: 3.174102, mean_eps: 0.656672\n",
      "  38237/1000000: episode: 563, duration: 3.219s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.745 [0.000, 3.000], mean observation: 39.745 [0.000, 142.000], loss: 0.033631, mean_squared_error: 8.276785, mean_q: 3.156463, mean_eps: 0.656119\n",
      "  38278/1000000: episode: 564, duration: 2.430s, episode steps: 41, steps per second: 17, episode reward: 1.000, mean reward: 0.024 [0.000, 1.000], mean action: 1.293 [0.000, 3.000], mean observation: 39.762 [0.000, 142.000], loss: 0.029667, mean_squared_error: 8.457734, mean_q: 3.190295, mean_eps: 0.655687\n",
      "  38352/1000000: episode: 565, duration: 4.245s, episode steps: 74, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.703 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.031710, mean_squared_error: 8.297303, mean_q: 3.151708, mean_eps: 0.655169\n",
      "  38409/1000000: episode: 566, duration: 3.297s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.386 [0.000, 3.000], mean observation: 39.706 [0.000, 142.000], loss: 0.030315, mean_squared_error: 8.223852, mean_q: 3.151387, mean_eps: 0.654580\n",
      "  38469/1000000: episode: 567, duration: 3.512s, episode steps: 60, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.775 [0.000, 142.000], loss: 0.028769, mean_squared_error: 8.472199, mean_q: 3.205476, mean_eps: 0.654053\n",
      "  38535/1000000: episode: 568, duration: 3.930s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.894 [0.000, 3.000], mean observation: 39.672 [0.000, 142.000], loss: 0.035534, mean_squared_error: 8.696673, mean_q: 3.239172, mean_eps: 0.653486\n",
      "  38592/1000000: episode: 569, duration: 3.306s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.860 [0.000, 3.000], mean observation: 39.729 [0.000, 142.000], loss: 0.022425, mean_squared_error: 8.233046, mean_q: 3.137575, mean_eps: 0.652933\n",
      "  38657/1000000: episode: 570, duration: 3.826s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.523 [0.000, 3.000], mean observation: 39.745 [0.000, 142.000], loss: 0.029382, mean_squared_error: 8.517235, mean_q: 3.204798, mean_eps: 0.652384\n",
      "  38712/1000000: episode: 571, duration: 3.228s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.691 [0.000, 3.000], mean observation: 39.749 [0.000, 142.000], loss: 0.029457, mean_squared_error: 8.494449, mean_q: 3.194905, mean_eps: 0.651844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  38770/1000000: episode: 572, duration: 3.393s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.534 [0.000, 3.000], mean observation: 39.744 [0.000, 142.000], loss: 0.035971, mean_squared_error: 8.648330, mean_q: 3.232991, mean_eps: 0.651335\n",
      "  38854/1000000: episode: 573, duration: 4.850s, episode steps: 84, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.488 [0.000, 3.000], mean observation: 39.714 [0.000, 142.000], loss: 0.031174, mean_squared_error: 8.542341, mean_q: 3.211730, mean_eps: 0.650696\n",
      "  38936/1000000: episode: 574, duration: 4.829s, episode steps: 82, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.634 [0.000, 3.000], mean observation: 39.627 [0.000, 142.000], loss: 0.031649, mean_squared_error: 8.663517, mean_q: 3.220312, mean_eps: 0.649949\n",
      "  39021/1000000: episode: 575, duration: 4.883s, episode steps: 85, steps per second: 17, episode reward: 5.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.471 [0.000, 3.000], mean observation: 39.576 [0.000, 142.000], loss: 0.038015, mean_squared_error: 8.695283, mean_q: 3.234593, mean_eps: 0.649198\n",
      "  39082/1000000: episode: 576, duration: 3.585s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.803 [0.000, 3.000], mean observation: 39.701 [0.000, 142.000], loss: 0.029859, mean_squared_error: 8.473445, mean_q: 3.192965, mean_eps: 0.648541\n",
      "  39140/1000000: episode: 577, duration: 3.378s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.586 [0.000, 3.000], mean observation: 39.799 [0.000, 142.000], loss: 0.029731, mean_squared_error: 8.267838, mean_q: 3.135374, mean_eps: 0.648006\n",
      "  39202/1000000: episode: 578, duration: 3.693s, episode steps: 62, steps per second: 17, episode reward: 2.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.839 [0.000, 3.000], mean observation: 39.881 [0.000, 142.000], loss: 0.032785, mean_squared_error: 8.829791, mean_q: 3.277145, mean_eps: 0.647465\n",
      "  39238/1000000: episode: 579, duration: 2.132s, episode steps: 36, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.528 [0.000, 3.000], mean observation: 40.022 [0.000, 142.000], loss: 0.026725, mean_squared_error: 8.634755, mean_q: 3.233616, mean_eps: 0.647025\n",
      "  39311/1000000: episode: 580, duration: 4.208s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.685 [0.000, 3.000], mean observation: 39.802 [0.000, 142.000], loss: 0.033986, mean_squared_error: 8.788503, mean_q: 3.245017, mean_eps: 0.646534\n",
      "  39378/1000000: episode: 581, duration: 3.854s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.821 [0.000, 3.000], mean observation: 39.737 [0.000, 142.000], loss: 0.027866, mean_squared_error: 8.596930, mean_q: 3.220652, mean_eps: 0.645904\n",
      "  39447/1000000: episode: 582, duration: 3.968s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.783 [0.000, 3.000], mean observation: 39.687 [0.000, 142.000], loss: 0.036592, mean_squared_error: 8.639189, mean_q: 3.230826, mean_eps: 0.645292\n",
      "  39521/1000000: episode: 583, duration: 4.361s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.811 [0.000, 3.000], mean observation: 39.698 [0.000, 142.000], loss: 0.025582, mean_squared_error: 8.832514, mean_q: 3.259891, mean_eps: 0.644648\n",
      "  39588/1000000: episode: 584, duration: 3.916s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.806 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.030191, mean_squared_error: 8.589364, mean_q: 3.204075, mean_eps: 0.644014\n",
      "  39661/1000000: episode: 585, duration: 4.277s, episode steps: 73, steps per second: 17, episode reward: 3.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.425 [0.000, 3.000], mean observation: 39.707 [0.000, 142.000], loss: 0.030269, mean_squared_error: 8.692369, mean_q: 3.227209, mean_eps: 0.643384\n",
      "  39733/1000000: episode: 586, duration: 4.271s, episode steps: 72, steps per second: 17, episode reward: 7.000, mean reward: 0.097 [0.000, 4.000], mean action: 1.847 [0.000, 3.000], mean observation: 39.646 [0.000, 142.000], loss: 0.025355, mean_squared_error: 8.874690, mean_q: 3.265531, mean_eps: 0.642732\n",
      "  39826/1000000: episode: 587, duration: 5.429s, episode steps: 93, steps per second: 17, episode reward: 3.000, mean reward: 0.032 [0.000, 1.000], mean action: 1.742 [0.000, 3.000], mean observation: 39.808 [0.000, 142.000], loss: 0.029009, mean_squared_error: 8.487356, mean_q: 3.187424, mean_eps: 0.641989\n",
      "  39880/1000000: episode: 588, duration: 3.169s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.833 [0.000, 3.000], mean observation: 39.761 [0.000, 142.000], loss: 0.035063, mean_squared_error: 8.718443, mean_q: 3.242799, mean_eps: 0.641327\n",
      "  40001/1000000: episode: 589, duration: 6.930s, episode steps: 121, steps per second: 17, episode reward: 10.000, mean reward: 0.083 [0.000, 4.000], mean action: 1.826 [0.000, 3.000], mean observation: 39.334 [0.000, 142.000], loss: 0.026999, mean_squared_error: 8.620249, mean_q: 3.217882, mean_eps: 0.640540\n",
      "  40066/1000000: episode: 590, duration: 3.699s, episode steps: 65, steps per second: 18, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.646 [0.000, 3.000], mean observation: 39.738 [0.000, 142.000], loss: 0.028717, mean_squared_error: 8.473707, mean_q: 3.192282, mean_eps: 0.639703\n",
      "  40114/1000000: episode: 591, duration: 2.845s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.333 [0.000, 3.000], mean observation: 39.756 [0.000, 142.000], loss: 0.034082, mean_squared_error: 8.626914, mean_q: 3.203023, mean_eps: 0.639194\n",
      "  40170/1000000: episode: 592, duration: 3.248s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.643 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.032078, mean_squared_error: 8.756852, mean_q: 3.256329, mean_eps: 0.638726\n",
      "  40248/1000000: episode: 593, duration: 4.551s, episode steps: 78, steps per second: 17, episode reward: 4.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.756 [0.000, 3.000], mean observation: 39.652 [0.000, 142.000], loss: 0.036062, mean_squared_error: 8.735369, mean_q: 3.229093, mean_eps: 0.638124\n",
      "  40306/1000000: episode: 594, duration: 3.407s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.828 [0.000, 3.000], mean observation: 39.712 [0.000, 142.000], loss: 0.034305, mean_squared_error: 8.641672, mean_q: 3.206253, mean_eps: 0.637512\n",
      "  40349/1000000: episode: 595, duration: 2.583s, episode steps: 43, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.442 [0.000, 3.000], mean observation: 39.966 [0.000, 142.000], loss: 0.029816, mean_squared_error: 8.464319, mean_q: 3.187804, mean_eps: 0.637057\n",
      "  40431/1000000: episode: 596, duration: 4.733s, episode steps: 82, steps per second: 17, episode reward: 7.000, mean reward: 0.085 [0.000, 4.000], mean action: 1.280 [0.000, 3.000], mean observation: 39.663 [0.000, 142.000], loss: 0.032723, mean_squared_error: 8.606927, mean_q: 3.213035, mean_eps: 0.636494\n",
      "  40506/1000000: episode: 597, duration: 4.446s, episode steps: 75, steps per second: 17, episode reward: 3.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.773 [0.000, 3.000], mean observation: 39.718 [0.000, 142.000], loss: 0.024432, mean_squared_error: 8.619160, mean_q: 3.216261, mean_eps: 0.635788\n",
      "  40584/1000000: episode: 598, duration: 4.546s, episode steps: 78, steps per second: 17, episode reward: 5.000, mean reward: 0.064 [0.000, 1.000], mean action: 1.385 [0.000, 3.000], mean observation: 39.622 [0.000, 142.000], loss: 0.028651, mean_squared_error: 8.455137, mean_q: 3.175589, mean_eps: 0.635100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  40652/1000000: episode: 599, duration: 4.017s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.662 [0.000, 3.000], mean observation: 39.622 [0.000, 142.000], loss: 0.034888, mean_squared_error: 8.527643, mean_q: 3.195626, mean_eps: 0.634442\n",
      "  40794/1000000: episode: 600, duration: 8.120s, episode steps: 142, steps per second: 17, episode reward: 8.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.641 [0.000, 3.000], mean observation: 39.399 [0.000, 142.000], loss: 0.024383, mean_squared_error: 8.747908, mean_q: 3.235961, mean_eps: 0.633498\n",
      "  40866/1000000: episode: 601, duration: 4.175s, episode steps: 72, steps per second: 17, episode reward: 7.000, mean reward: 0.097 [0.000, 4.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.677 [0.000, 142.000], loss: 0.025354, mean_squared_error: 8.942364, mean_q: 3.287360, mean_eps: 0.632534\n",
      "  40938/1000000: episode: 602, duration: 4.215s, episode steps: 72, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.611 [0.000, 3.000], mean observation: 39.773 [0.000, 142.000], loss: 0.026106, mean_squared_error: 8.745990, mean_q: 3.224578, mean_eps: 0.631887\n",
      "  41001/1000000: episode: 603, duration: 3.657s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.905 [0.000, 3.000], mean observation: 39.687 [0.000, 142.000], loss: 0.027733, mean_squared_error: 8.598130, mean_q: 3.202526, mean_eps: 0.631279\n",
      "  41053/1000000: episode: 604, duration: 3.051s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.846 [0.000, 3.000], mean observation: 39.793 [0.000, 142.000], loss: 0.036475, mean_squared_error: 8.747379, mean_q: 3.238623, mean_eps: 0.630762\n",
      "  41111/1000000: episode: 605, duration: 3.431s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.707 [0.000, 3.000], mean observation: 39.729 [0.000, 142.000], loss: 0.027028, mean_squared_error: 8.736082, mean_q: 3.249757, mean_eps: 0.630266\n",
      "  41187/1000000: episode: 606, duration: 4.446s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.763 [0.000, 3.000], mean observation: 39.632 [0.000, 142.000], loss: 0.033384, mean_squared_error: 8.602538, mean_q: 3.187167, mean_eps: 0.629664\n",
      "  41245/1000000: episode: 607, duration: 3.398s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.638 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.029153, mean_squared_error: 8.896152, mean_q: 3.259816, mean_eps: 0.629061\n",
      "  41296/1000000: episode: 608, duration: 2.994s, episode steps: 51, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.529 [0.000, 3.000], mean observation: 39.753 [0.000, 142.000], loss: 0.046105, mean_squared_error: 8.868158, mean_q: 3.254452, mean_eps: 0.628570\n",
      "  41355/1000000: episode: 609, duration: 3.500s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.508 [0.000, 3.000], mean observation: 39.745 [0.000, 142.000], loss: 0.021140, mean_squared_error: 8.884237, mean_q: 3.256608, mean_eps: 0.628075\n",
      "  41430/1000000: episode: 610, duration: 4.387s, episode steps: 75, steps per second: 17, episode reward: 7.000, mean reward: 0.093 [0.000, 4.000], mean action: 1.707 [0.000, 3.000], mean observation: 39.673 [0.000, 142.000], loss: 0.023880, mean_squared_error: 8.892029, mean_q: 3.249154, mean_eps: 0.627472\n",
      "  41499/1000000: episode: 611, duration: 4.099s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.666 [0.000, 142.000], loss: 0.029140, mean_squared_error: 8.648392, mean_q: 3.217152, mean_eps: 0.626824\n",
      "  41557/1000000: episode: 612, duration: 3.428s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.397 [0.000, 3.000], mean observation: 39.746 [0.000, 142.000], loss: 0.034564, mean_squared_error: 8.792431, mean_q: 3.229437, mean_eps: 0.626252\n",
      "  41619/1000000: episode: 613, duration: 3.616s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.452 [0.000, 3.000], mean observation: 39.706 [0.000, 142.000], loss: 0.027204, mean_squared_error: 8.846931, mean_q: 3.259663, mean_eps: 0.625713\n",
      "  41688/1000000: episode: 614, duration: 4.033s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.609 [0.000, 3.000], mean observation: 39.640 [0.000, 142.000], loss: 0.026907, mean_squared_error: 8.900701, mean_q: 3.258934, mean_eps: 0.625123\n",
      "  41748/1000000: episode: 615, duration: 3.520s, episode steps: 60, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.533 [0.000, 3.000], mean observation: 39.801 [0.000, 142.000], loss: 0.026723, mean_squared_error: 8.759680, mean_q: 3.247375, mean_eps: 0.624543\n",
      "  41822/1000000: episode: 616, duration: 4.308s, episode steps: 74, steps per second: 17, episode reward: 2.000, mean reward: 0.027 [0.000, 1.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.027678, mean_squared_error: 8.760499, mean_q: 3.218837, mean_eps: 0.623939\n",
      "  41898/1000000: episode: 617, duration: 4.456s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.579 [0.000, 3.000], mean observation: 39.673 [0.000, 142.000], loss: 0.021935, mean_squared_error: 8.816877, mean_q: 3.240951, mean_eps: 0.623264\n",
      "  41957/1000000: episode: 618, duration: 3.472s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.644 [0.000, 3.000], mean observation: 39.727 [0.000, 142.000], loss: 0.029880, mean_squared_error: 8.771882, mean_q: 3.237501, mean_eps: 0.622657\n",
      "  42022/1000000: episode: 619, duration: 3.780s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 2.015 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.031690, mean_squared_error: 9.010020, mean_q: 3.305657, mean_eps: 0.622099\n",
      "  42095/1000000: episode: 620, duration: 4.148s, episode steps: 73, steps per second: 18, episode reward: 7.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.575 [0.000, 3.000], mean observation: 39.614 [0.000, 142.000], loss: 0.026689, mean_squared_error: 8.884206, mean_q: 3.281065, mean_eps: 0.621478\n",
      "  42159/1000000: episode: 621, duration: 3.741s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.438 [0.000, 3.000], mean observation: 39.771 [0.000, 142.000], loss: 0.027014, mean_squared_error: 8.748000, mean_q: 3.242565, mean_eps: 0.620861\n",
      "  42200/1000000: episode: 622, duration: 2.402s, episode steps: 41, steps per second: 17, episode reward: 1.000, mean reward: 0.024 [0.000, 1.000], mean action: 1.512 [0.000, 3.000], mean observation: 39.749 [0.000, 142.000], loss: 0.025538, mean_squared_error: 9.086057, mean_q: 3.331599, mean_eps: 0.620389\n",
      "  42280/1000000: episode: 623, duration: 4.622s, episode steps: 80, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.525 [0.000, 3.000], mean observation: 39.551 [0.000, 142.000], loss: 0.027844, mean_squared_error: 8.892588, mean_q: 3.277005, mean_eps: 0.619844\n",
      "  42347/1000000: episode: 624, duration: 3.886s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.851 [0.000, 3.000], mean observation: 39.745 [0.000, 142.000], loss: 0.025654, mean_squared_error: 8.841092, mean_q: 3.254743, mean_eps: 0.619183\n",
      "  42403/1000000: episode: 625, duration: 3.254s, episode steps: 56, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.589 [0.000, 3.000], mean observation: 39.738 [0.000, 142.000], loss: 0.027510, mean_squared_error: 9.042993, mean_q: 3.313081, mean_eps: 0.618629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  42443/1000000: episode: 626, duration: 2.367s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.525 [0.000, 3.000], mean observation: 39.942 [0.000, 142.000], loss: 0.024424, mean_squared_error: 9.150969, mean_q: 3.324606, mean_eps: 0.618197\n",
      "  42495/1000000: episode: 627, duration: 3.082s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.744 [0.000, 142.000], loss: 0.032914, mean_squared_error: 9.201892, mean_q: 3.338452, mean_eps: 0.617783\n",
      "  42567/1000000: episode: 628, duration: 4.212s, episode steps: 72, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.556 [0.000, 3.000], mean observation: 39.651 [0.000, 142.000], loss: 0.025739, mean_squared_error: 9.060872, mean_q: 3.307341, mean_eps: 0.617225\n",
      "  42633/1000000: episode: 629, duration: 3.795s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.630 [0.000, 142.000], loss: 0.039637, mean_squared_error: 8.928834, mean_q: 3.293932, mean_eps: 0.616604\n",
      "  42723/1000000: episode: 630, duration: 5.283s, episode steps: 90, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.611 [0.000, 3.000], mean observation: 39.454 [0.000, 142.000], loss: 0.025296, mean_squared_error: 9.018251, mean_q: 3.316558, mean_eps: 0.615903\n",
      "  42775/1000000: episode: 631, duration: 2.972s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.808 [0.000, 3.000], mean observation: 39.727 [0.000, 142.000], loss: 0.023255, mean_squared_error: 8.990351, mean_q: 3.309951, mean_eps: 0.615263\n",
      "  42858/1000000: episode: 632, duration: 4.790s, episode steps: 83, steps per second: 17, episode reward: 11.000, mean reward: 0.133 [0.000, 4.000], mean action: 1.578 [0.000, 3.000], mean observation: 39.602 [0.000, 142.000], loss: 0.031805, mean_squared_error: 9.154327, mean_q: 3.327431, mean_eps: 0.614656\n",
      "  42912/1000000: episode: 633, duration: 3.097s, episode steps: 54, steps per second: 17, episode reward: 3.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.759 [0.000, 3.000], mean observation: 39.711 [0.000, 142.000], loss: 0.027035, mean_squared_error: 8.990260, mean_q: 3.302447, mean_eps: 0.614039\n",
      "  42976/1000000: episode: 634, duration: 3.716s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.656 [0.000, 3.000], mean observation: 39.779 [0.000, 142.000], loss: 0.031783, mean_squared_error: 8.982445, mean_q: 3.283832, mean_eps: 0.613509\n",
      "  43036/1000000: episode: 635, duration: 3.654s, episode steps: 60, steps per second: 16, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.517 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.030146, mean_squared_error: 9.061709, mean_q: 3.300338, mean_eps: 0.612951\n",
      "  43096/1000000: episode: 636, duration: 3.480s, episode steps: 60, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.733 [0.000, 3.000], mean observation: 39.829 [0.000, 142.000], loss: 0.024838, mean_squared_error: 8.977754, mean_q: 3.291325, mean_eps: 0.612410\n",
      "  43153/1000000: episode: 637, duration: 3.289s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.333 [0.000, 3.000], mean observation: 39.727 [0.000, 142.000], loss: 0.033939, mean_squared_error: 8.961208, mean_q: 3.318859, mean_eps: 0.611884\n",
      "  43233/1000000: episode: 638, duration: 4.669s, episode steps: 80, steps per second: 17, episode reward: 3.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.663 [0.000, 3.000], mean observation: 39.698 [0.000, 142.000], loss: 0.029955, mean_squared_error: 9.032351, mean_q: 3.314287, mean_eps: 0.611267\n",
      "  43310/1000000: episode: 639, duration: 4.561s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.481 [0.000, 3.000], mean observation: 39.576 [0.000, 142.000], loss: 0.030491, mean_squared_error: 8.990512, mean_q: 3.292550, mean_eps: 0.610561\n",
      "  43369/1000000: episode: 640, duration: 3.582s, episode steps: 59, steps per second: 16, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.576 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.031177, mean_squared_error: 9.173097, mean_q: 3.337631, mean_eps: 0.609949\n",
      "  43438/1000000: episode: 641, duration: 4.062s, episode steps: 69, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.638 [0.000, 3.000], mean observation: 39.778 [0.000, 142.000], loss: 0.025174, mean_squared_error: 9.234986, mean_q: 3.337097, mean_eps: 0.609373\n",
      "  43510/1000000: episode: 642, duration: 4.179s, episode steps: 72, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.417 [0.000, 3.000], mean observation: 39.661 [0.000, 142.000], loss: 0.030098, mean_squared_error: 9.170676, mean_q: 3.327913, mean_eps: 0.608738\n",
      "  43564/1000000: episode: 643, duration: 3.126s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.722 [0.000, 3.000], mean observation: 39.733 [0.000, 142.000], loss: 0.036309, mean_squared_error: 9.242865, mean_q: 3.347240, mean_eps: 0.608172\n",
      "  43631/1000000: episode: 644, duration: 3.918s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.776 [0.000, 3.000], mean observation: 39.640 [0.000, 142.000], loss: 0.028908, mean_squared_error: 8.953607, mean_q: 3.287465, mean_eps: 0.607627\n",
      "  43706/1000000: episode: 645, duration: 4.311s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.653 [0.000, 3.000], mean observation: 39.655 [0.000, 142.000], loss: 0.027517, mean_squared_error: 9.163437, mean_q: 3.325884, mean_eps: 0.606988\n",
      "  43777/1000000: episode: 646, duration: 4.150s, episode steps: 71, steps per second: 17, episode reward: 3.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.465 [0.000, 3.000], mean observation: 39.735 [0.000, 142.000], loss: 0.025068, mean_squared_error: 8.968223, mean_q: 3.283583, mean_eps: 0.606331\n",
      "  43842/1000000: episode: 647, duration: 3.883s, episode steps: 65, steps per second: 17, episode reward: 2.000, mean reward: 0.031 [0.000, 1.000], mean action: 1.785 [0.000, 3.000], mean observation: 39.797 [0.000, 142.000], loss: 0.024304, mean_squared_error: 9.419920, mean_q: 3.370376, mean_eps: 0.605719\n",
      "  43921/1000000: episode: 648, duration: 4.618s, episode steps: 79, steps per second: 17, episode reward: 7.000, mean reward: 0.089 [0.000, 4.000], mean action: 1.620 [0.000, 3.000], mean observation: 39.622 [0.000, 142.000], loss: 0.029379, mean_squared_error: 9.295030, mean_q: 3.342061, mean_eps: 0.605071\n",
      "  43974/1000000: episode: 649, duration: 3.144s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.604 [0.000, 3.000], mean observation: 39.845 [0.000, 142.000], loss: 0.024177, mean_squared_error: 9.439848, mean_q: 3.393778, mean_eps: 0.604477\n",
      "  44029/1000000: episode: 650, duration: 3.305s, episode steps: 55, steps per second: 17, episode reward: 3.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.636 [0.000, 3.000], mean observation: 39.730 [0.000, 142.000], loss: 0.025061, mean_squared_error: 9.552772, mean_q: 3.402764, mean_eps: 0.603991\n",
      "  44083/1000000: episode: 651, duration: 3.188s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.944 [0.000, 3.000], mean observation: 39.763 [0.000, 142.000], loss: 0.036548, mean_squared_error: 9.030563, mean_q: 3.295403, mean_eps: 0.603500\n",
      "  44147/1000000: episode: 652, duration: 3.742s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.025980, mean_squared_error: 9.215331, mean_q: 3.340172, mean_eps: 0.602969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  44246/1000000: episode: 653, duration: 5.555s, episode steps: 99, steps per second: 18, episode reward: 7.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.485 [0.000, 3.000], mean observation: 39.458 [0.000, 142.000], loss: 0.023846, mean_squared_error: 9.449336, mean_q: 3.391929, mean_eps: 0.602236\n",
      "  44319/1000000: episode: 654, duration: 4.265s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.726 [0.000, 3.000], mean observation: 39.632 [0.000, 142.000], loss: 0.026482, mean_squared_error: 9.321061, mean_q: 3.347380, mean_eps: 0.601462\n",
      "  44370/1000000: episode: 655, duration: 2.997s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.471 [0.000, 3.000], mean observation: 39.807 [0.000, 142.000], loss: 0.026952, mean_squared_error: 9.411739, mean_q: 3.369028, mean_eps: 0.600904\n",
      "  44431/1000000: episode: 656, duration: 3.460s, episode steps: 61, steps per second: 18, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.672 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.027068, mean_squared_error: 9.099841, mean_q: 3.289445, mean_eps: 0.600400\n",
      "  44488/1000000: episode: 657, duration: 3.397s, episode steps: 57, steps per second: 17, episode reward: 2.000, mean reward: 0.035 [0.000, 1.000], mean action: 1.596 [0.000, 3.000], mean observation: 39.799 [0.000, 142.000], loss: 0.023255, mean_squared_error: 9.423414, mean_q: 3.378308, mean_eps: 0.599869\n",
      "  44566/1000000: episode: 658, duration: 4.542s, episode steps: 78, steps per second: 17, episode reward: 4.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.603 [0.000, 3.000], mean observation: 39.633 [0.000, 142.000], loss: 0.030380, mean_squared_error: 9.343878, mean_q: 3.338878, mean_eps: 0.599262\n",
      "  44643/1000000: episode: 659, duration: 4.427s, episode steps: 77, steps per second: 17, episode reward: 4.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.857 [0.000, 3.000], mean observation: 39.726 [0.000, 142.000], loss: 0.025026, mean_squared_error: 9.123063, mean_q: 3.293390, mean_eps: 0.598564\n",
      "  44702/1000000: episode: 660, duration: 3.491s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.424 [0.000, 3.000], mean observation: 39.731 [0.000, 142.000], loss: 0.028379, mean_squared_error: 9.345557, mean_q: 3.352436, mean_eps: 0.597952\n",
      "  44763/1000000: episode: 661, duration: 3.477s, episode steps: 61, steps per second: 18, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.656 [0.000, 3.000], mean observation: 39.770 [0.000, 142.000], loss: 0.030886, mean_squared_error: 9.260112, mean_q: 3.332024, mean_eps: 0.597412\n",
      "  44859/1000000: episode: 662, duration: 5.581s, episode steps: 96, steps per second: 17, episode reward: 8.000, mean reward: 0.083 [0.000, 4.000], mean action: 1.490 [0.000, 3.000], mean observation: 39.626 [0.000, 142.000], loss: 0.034354, mean_squared_error: 9.335056, mean_q: 3.334271, mean_eps: 0.596705\n",
      "  44922/1000000: episode: 663, duration: 3.705s, episode steps: 63, steps per second: 17, episode reward: 4.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.603 [0.000, 3.000], mean observation: 39.647 [0.000, 142.000], loss: 0.028086, mean_squared_error: 9.403068, mean_q: 3.369890, mean_eps: 0.595990\n",
      "  44992/1000000: episode: 664, duration: 4.213s, episode steps: 70, steps per second: 17, episode reward: 7.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.800 [0.000, 3.000], mean observation: 39.627 [0.000, 142.000], loss: 0.027294, mean_squared_error: 9.371440, mean_q: 3.365037, mean_eps: 0.595392\n",
      "  45048/1000000: episode: 665, duration: 3.307s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.713 [0.000, 142.000], loss: 0.023417, mean_squared_error: 9.322180, mean_q: 3.354186, mean_eps: 0.594824\n",
      "  45117/1000000: episode: 666, duration: 4.066s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.464 [0.000, 3.000], mean observation: 39.660 [0.000, 142.000], loss: 0.029276, mean_squared_error: 9.349801, mean_q: 3.347693, mean_eps: 0.594262\n",
      "  45169/1000000: episode: 667, duration: 3.048s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.692 [0.000, 3.000], mean observation: 39.868 [0.000, 142.000], loss: 0.024497, mean_squared_error: 9.377317, mean_q: 3.369602, mean_eps: 0.593718\n",
      "  45219/1000000: episode: 668, duration: 2.946s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.440 [0.000, 3.000], mean observation: 39.870 [0.000, 142.000], loss: 0.027066, mean_squared_error: 9.490141, mean_q: 3.372849, mean_eps: 0.593258\n",
      "  45301/1000000: episode: 669, duration: 4.844s, episode steps: 82, steps per second: 17, episode reward: 8.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.707 [0.000, 3.000], mean observation: 39.583 [0.000, 142.000], loss: 0.027718, mean_squared_error: 9.558279, mean_q: 3.385608, mean_eps: 0.592665\n",
      "  45362/1000000: episode: 670, duration: 3.563s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.574 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.026536, mean_squared_error: 9.268040, mean_q: 3.325840, mean_eps: 0.592021\n",
      "  45412/1000000: episode: 671, duration: 2.908s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.520 [0.000, 3.000], mean observation: 39.806 [0.000, 142.000], loss: 0.034962, mean_squared_error: 9.352934, mean_q: 3.356086, mean_eps: 0.591522\n",
      "  45468/1000000: episode: 672, duration: 3.129s, episode steps: 56, steps per second: 18, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.679 [0.000, 3.000], mean observation: 39.714 [0.000, 142.000], loss: 0.031344, mean_squared_error: 9.461493, mean_q: 3.371710, mean_eps: 0.591044\n",
      "  45534/1000000: episode: 673, duration: 3.899s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.333 [0.000, 3.000], mean observation: 39.690 [0.000, 142.000], loss: 0.026742, mean_squared_error: 9.455979, mean_q: 3.374574, mean_eps: 0.590496\n",
      "  45608/1000000: episode: 674, duration: 4.299s, episode steps: 74, steps per second: 17, episode reward: 5.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.554 [0.000, 3.000], mean observation: 39.621 [0.000, 142.000], loss: 0.024956, mean_squared_error: 9.299055, mean_q: 3.341712, mean_eps: 0.589866\n",
      "  45685/1000000: episode: 675, duration: 4.515s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.519 [0.000, 3.000], mean observation: 39.597 [0.000, 142.000], loss: 0.027610, mean_squared_error: 9.388089, mean_q: 3.346115, mean_eps: 0.589186\n",
      "  45748/1000000: episode: 676, duration: 3.675s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.746 [0.000, 3.000], mean observation: 39.738 [0.000, 142.000], loss: 0.027464, mean_squared_error: 9.438313, mean_q: 3.377500, mean_eps: 0.588556\n",
      "  45797/1000000: episode: 677, duration: 2.954s, episode steps: 49, steps per second: 17, episode reward: 2.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.592 [0.000, 3.000], mean observation: 39.756 [0.000, 142.000], loss: 0.027052, mean_squared_error: 9.334965, mean_q: 3.341391, mean_eps: 0.588052\n",
      "  45862/1000000: episode: 678, duration: 3.855s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.754 [0.000, 3.000], mean observation: 39.670 [0.000, 142.000], loss: 0.023716, mean_squared_error: 9.421206, mean_q: 3.354990, mean_eps: 0.587539\n",
      "  45944/1000000: episode: 679, duration: 4.825s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.582 [0.000, 142.000], loss: 0.023744, mean_squared_error: 9.208302, mean_q: 3.304455, mean_eps: 0.586877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  46009/1000000: episode: 680, duration: 3.585s, episode steps: 65, steps per second: 18, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.846 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.024296, mean_squared_error: 9.225285, mean_q: 3.321355, mean_eps: 0.586216\n",
      "  46048/1000000: episode: 681, duration: 2.246s, episode steps: 39, steps per second: 17, episode reward: 1.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.359 [0.000, 3.000], mean observation: 39.868 [0.000, 142.000], loss: 0.031120, mean_squared_error: 9.613758, mean_q: 3.397930, mean_eps: 0.585748\n",
      "  46108/1000000: episode: 682, duration: 3.446s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.810 [0.000, 142.000], loss: 0.022417, mean_squared_error: 9.317414, mean_q: 3.363034, mean_eps: 0.585302\n",
      "  46148/1000000: episode: 683, duration: 2.398s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.550 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.022669, mean_squared_error: 9.321814, mean_q: 3.347546, mean_eps: 0.584852\n",
      "  46211/1000000: episode: 684, duration: 3.566s, episode steps: 63, steps per second: 18, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.492 [0.000, 3.000], mean observation: 39.721 [0.000, 142.000], loss: 0.022693, mean_squared_error: 9.309440, mean_q: 3.325880, mean_eps: 0.584389\n",
      "  46254/1000000: episode: 685, duration: 2.543s, episode steps: 43, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.977 [0.000, 3.000], mean observation: 39.760 [0.000, 142.000], loss: 0.028071, mean_squared_error: 9.312338, mean_q: 3.340640, mean_eps: 0.583912\n",
      "  46328/1000000: episode: 686, duration: 4.367s, episode steps: 74, steps per second: 17, episode reward: 5.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.676 [0.000, 3.000], mean observation: 39.702 [0.000, 142.000], loss: 0.026693, mean_squared_error: 9.486373, mean_q: 3.366435, mean_eps: 0.583386\n",
      "  46383/1000000: episode: 687, duration: 3.231s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.691 [0.000, 3.000], mean observation: 39.874 [0.000, 142.000], loss: 0.025656, mean_squared_error: 9.373535, mean_q: 3.357203, mean_eps: 0.582805\n",
      "  46475/1000000: episode: 688, duration: 5.435s, episode steps: 92, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.620 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.027882, mean_squared_error: 9.572368, mean_q: 3.398708, mean_eps: 0.582143\n",
      "  46525/1000000: episode: 689, duration: 2.824s, episode steps: 50, steps per second: 18, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.886 [0.000, 142.000], loss: 0.024079, mean_squared_error: 9.283151, mean_q: 3.344076, mean_eps: 0.581504\n",
      "  46577/1000000: episode: 690, duration: 2.999s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.308 [0.000, 3.000], mean observation: 39.803 [0.000, 142.000], loss: 0.024619, mean_squared_error: 9.024078, mean_q: 3.293652, mean_eps: 0.581045\n",
      "  46634/1000000: episode: 691, duration: 3.314s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.789 [0.000, 3.000], mean observation: 39.736 [0.000, 142.000], loss: 0.027195, mean_squared_error: 9.232059, mean_q: 3.320983, mean_eps: 0.580555\n",
      "  46717/1000000: episode: 692, duration: 4.832s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.349 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.022436, mean_squared_error: 9.654636, mean_q: 3.404466, mean_eps: 0.579925\n",
      "  46773/1000000: episode: 693, duration: 3.273s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.589 [0.000, 3.000], mean observation: 39.718 [0.000, 142.000], loss: 0.027279, mean_squared_error: 9.555856, mean_q: 3.389204, mean_eps: 0.579300\n",
      "  46838/1000000: episode: 694, duration: 3.763s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.523 [0.000, 3.000], mean observation: 39.627 [0.000, 142.000], loss: 0.029513, mean_squared_error: 9.630979, mean_q: 3.418389, mean_eps: 0.578755\n",
      "  46905/1000000: episode: 695, duration: 3.874s, episode steps: 67, steps per second: 17, episode reward: 7.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.746 [0.000, 3.000], mean observation: 39.640 [0.000, 142.000], loss: 0.024661, mean_squared_error: 9.497930, mean_q: 3.381531, mean_eps: 0.578161\n",
      "  46975/1000000: episode: 696, duration: 4.124s, episode steps: 70, steps per second: 17, episode reward: 7.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.025697, mean_squared_error: 9.577413, mean_q: 3.405782, mean_eps: 0.577544\n",
      "  47027/1000000: episode: 697, duration: 3.051s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.519 [0.000, 3.000], mean observation: 39.753 [0.000, 142.000], loss: 0.029725, mean_squared_error: 9.317000, mean_q: 3.328502, mean_eps: 0.576995\n",
      "  47095/1000000: episode: 698, duration: 3.960s, episode steps: 68, steps per second: 17, episode reward: 2.000, mean reward: 0.029 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.841 [0.000, 142.000], loss: 0.029264, mean_squared_error: 9.459313, mean_q: 3.371424, mean_eps: 0.576456\n",
      "  47162/1000000: episode: 699, duration: 3.999s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.493 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.027343, mean_squared_error: 9.525814, mean_q: 3.389871, mean_eps: 0.575848\n",
      "  47261/1000000: episode: 700, duration: 5.811s, episode steps: 99, steps per second: 17, episode reward: 9.000, mean reward: 0.091 [0.000, 1.000], mean action: 1.556 [0.000, 3.000], mean observation: 39.229 [0.000, 142.000], loss: 0.028101, mean_squared_error: 9.447387, mean_q: 3.375298, mean_eps: 0.575101\n",
      "  47325/1000000: episode: 701, duration: 3.707s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.688 [0.000, 3.000], mean observation: 39.710 [0.000, 142.000], loss: 0.023379, mean_squared_error: 9.727592, mean_q: 3.419470, mean_eps: 0.574368\n",
      "  47412/1000000: episode: 702, duration: 5.147s, episode steps: 87, steps per second: 17, episode reward: 6.000, mean reward: 0.069 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.477 [0.000, 142.000], loss: 0.025912, mean_squared_error: 9.566107, mean_q: 3.389313, mean_eps: 0.573688\n",
      "  47507/1000000: episode: 703, duration: 5.512s, episode steps: 95, steps per second: 17, episode reward: 6.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.674 [0.000, 3.000], mean observation: 39.477 [0.000, 142.000], loss: 0.025914, mean_squared_error: 9.505849, mean_q: 3.385480, mean_eps: 0.572869\n",
      "  47607/1000000: episode: 704, duration: 5.829s, episode steps: 100, steps per second: 17, episode reward: 7.000, mean reward: 0.070 [0.000, 1.000], mean action: 1.730 [0.000, 3.000], mean observation: 39.434 [0.000, 142.000], loss: 0.024001, mean_squared_error: 9.779757, mean_q: 3.431724, mean_eps: 0.571991\n",
      "  47662/1000000: episode: 705, duration: 3.235s, episode steps: 55, steps per second: 17, episode reward: 3.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.582 [0.000, 3.000], mean observation: 39.696 [0.000, 142.000], loss: 0.024587, mean_squared_error: 9.411779, mean_q: 3.345280, mean_eps: 0.571294\n",
      "  47719/1000000: episode: 706, duration: 3.411s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.404 [0.000, 3.000], mean observation: 39.808 [0.000, 142.000], loss: 0.031201, mean_squared_error: 9.550779, mean_q: 3.369787, mean_eps: 0.570790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  47796/1000000: episode: 707, duration: 4.514s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.649 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.024637, mean_squared_error: 9.384633, mean_q: 3.347305, mean_eps: 0.570187\n",
      "  47867/1000000: episode: 708, duration: 4.160s, episode steps: 71, steps per second: 17, episode reward: 7.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.423 [0.000, 3.000], mean observation: 39.636 [0.000, 142.000], loss: 0.022883, mean_squared_error: 9.809231, mean_q: 3.434125, mean_eps: 0.569521\n",
      "  47903/1000000: episode: 709, duration: 2.186s, episode steps: 36, steps per second: 16, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.556 [0.000, 3.000], mean observation: 39.989 [0.000, 142.000], loss: 0.023497, mean_squared_error: 9.722389, mean_q: 3.416792, mean_eps: 0.569040\n",
      "  47965/1000000: episode: 710, duration: 3.559s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.613 [0.000, 3.000], mean observation: 39.792 [0.000, 142.000], loss: 0.025129, mean_squared_error: 9.555251, mean_q: 3.391269, mean_eps: 0.568599\n",
      "  48014/1000000: episode: 711, duration: 2.871s, episode steps: 49, steps per second: 17, episode reward: 1.000, mean reward: 0.020 [0.000, 1.000], mean action: 1.837 [0.000, 3.000], mean observation: 39.891 [0.000, 142.000], loss: 0.025337, mean_squared_error: 9.466495, mean_q: 3.365669, mean_eps: 0.568099\n",
      "  48084/1000000: episode: 712, duration: 4.058s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.814 [0.000, 3.000], mean observation: 39.639 [0.000, 142.000], loss: 0.020743, mean_squared_error: 9.653325, mean_q: 3.408266, mean_eps: 0.567563\n",
      "  48148/1000000: episode: 713, duration: 3.672s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.531 [0.000, 3.000], mean observation: 39.727 [0.000, 142.000], loss: 0.022125, mean_squared_error: 9.414406, mean_q: 3.349213, mean_eps: 0.566960\n",
      "  48247/1000000: episode: 714, duration: 5.845s, episode steps: 99, steps per second: 17, episode reward: 6.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.657 [0.000, 3.000], mean observation: 39.520 [0.000, 142.000], loss: 0.029007, mean_squared_error: 9.483513, mean_q: 3.366341, mean_eps: 0.566227\n",
      "  48305/1000000: episode: 715, duration: 3.404s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.862 [0.000, 3.000], mean observation: 39.843 [0.000, 142.000], loss: 0.023816, mean_squared_error: 9.225922, mean_q: 3.308960, mean_eps: 0.565520\n",
      "  48354/1000000: episode: 716, duration: 2.842s, episode steps: 49, steps per second: 17, episode reward: 2.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.673 [0.000, 3.000], mean observation: 39.761 [0.000, 142.000], loss: 0.030592, mean_squared_error: 9.063685, mean_q: 3.292700, mean_eps: 0.565039\n",
      "  48395/1000000: episode: 717, duration: 2.418s, episode steps: 41, steps per second: 17, episode reward: 1.000, mean reward: 0.024 [0.000, 1.000], mean action: 1.634 [0.000, 3.000], mean observation: 39.942 [0.000, 142.000], loss: 0.027792, mean_squared_error: 9.289524, mean_q: 3.330240, mean_eps: 0.564634\n",
      "  48452/1000000: episode: 718, duration: 3.336s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.716 [0.000, 142.000], loss: 0.026580, mean_squared_error: 9.504609, mean_q: 3.369539, mean_eps: 0.564193\n",
      "  48515/1000000: episode: 719, duration: 3.641s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.651 [0.000, 3.000], mean observation: 39.709 [0.000, 142.000], loss: 0.026031, mean_squared_error: 9.280524, mean_q: 3.338616, mean_eps: 0.563653\n",
      "  48598/1000000: episode: 720, duration: 4.830s, episode steps: 83, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.663 [0.000, 3.000], mean observation: 39.625 [0.000, 142.000], loss: 0.026736, mean_squared_error: 9.332741, mean_q: 3.324621, mean_eps: 0.562996\n",
      "  48698/1000000: episode: 721, duration: 5.897s, episode steps: 100, steps per second: 17, episode reward: 7.000, mean reward: 0.070 [0.000, 1.000], mean action: 1.420 [0.000, 3.000], mean observation: 39.406 [0.000, 142.000], loss: 0.020253, mean_squared_error: 9.388517, mean_q: 3.345659, mean_eps: 0.562172\n",
      "  48753/1000000: episode: 722, duration: 3.152s, episode steps: 55, steps per second: 17, episode reward: 3.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.782 [0.000, 3.000], mean observation: 39.710 [0.000, 142.000], loss: 0.026394, mean_squared_error: 9.212803, mean_q: 3.323973, mean_eps: 0.561475\n",
      "  48806/1000000: episode: 723, duration: 3.052s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.679 [0.000, 3.000], mean observation: 39.717 [0.000, 142.000], loss: 0.027738, mean_squared_error: 9.536294, mean_q: 3.372681, mean_eps: 0.560989\n",
      "  48899/1000000: episode: 724, duration: 5.364s, episode steps: 93, steps per second: 17, episode reward: 8.000, mean reward: 0.086 [0.000, 4.000], mean action: 1.699 [0.000, 3.000], mean observation: 39.529 [0.000, 142.000], loss: 0.023409, mean_squared_error: 9.443812, mean_q: 3.354996, mean_eps: 0.560332\n",
      "  48957/1000000: episode: 725, duration: 3.380s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.672 [0.000, 3.000], mean observation: 39.796 [0.000, 142.000], loss: 0.028674, mean_squared_error: 9.548974, mean_q: 3.385342, mean_eps: 0.559652\n",
      "  49004/1000000: episode: 726, duration: 2.832s, episode steps: 47, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.745 [0.000, 3.000], mean observation: 39.711 [0.000, 142.000], loss: 0.029882, mean_squared_error: 9.280113, mean_q: 3.325960, mean_eps: 0.559180\n",
      "  49088/1000000: episode: 727, duration: 4.958s, episode steps: 84, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.726 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.024820, mean_squared_error: 9.233475, mean_q: 3.319289, mean_eps: 0.558590\n",
      "  49161/1000000: episode: 728, duration: 4.325s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.904 [0.000, 3.000], mean observation: 39.616 [0.000, 142.000], loss: 0.024451, mean_squared_error: 9.349111, mean_q: 3.341479, mean_eps: 0.557884\n",
      "  49202/1000000: episode: 729, duration: 2.447s, episode steps: 41, steps per second: 17, episode reward: 1.000, mean reward: 0.024 [0.000, 1.000], mean action: 1.585 [0.000, 3.000], mean observation: 39.948 [0.000, 142.000], loss: 0.032573, mean_squared_error: 9.396849, mean_q: 3.356936, mean_eps: 0.557371\n",
      "  49267/1000000: episode: 730, duration: 3.738s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.385 [0.000, 3.000], mean observation: 39.636 [0.000, 142.000], loss: 0.023468, mean_squared_error: 9.470690, mean_q: 3.343372, mean_eps: 0.556894\n",
      "  49392/1000000: episode: 731, duration: 7.186s, episode steps: 125, steps per second: 17, episode reward: 10.000, mean reward: 0.080 [0.000, 1.000], mean action: 1.512 [0.000, 3.000], mean observation: 39.260 [0.000, 142.000], loss: 0.023265, mean_squared_error: 9.225150, mean_q: 3.303770, mean_eps: 0.556039\n",
      "  49440/1000000: episode: 732, duration: 2.806s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.871 [0.000, 142.000], loss: 0.023269, mean_squared_error: 9.163449, mean_q: 3.314676, mean_eps: 0.555261\n",
      "  49486/1000000: episode: 733, duration: 2.660s, episode steps: 46, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.304 [0.000, 3.000], mean observation: 39.757 [0.000, 142.000], loss: 0.021132, mean_squared_error: 9.242952, mean_q: 3.325117, mean_eps: 0.554837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  49545/1000000: episode: 734, duration: 3.510s, episode steps: 59, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.712 [0.000, 142.000], loss: 0.027665, mean_squared_error: 9.533026, mean_q: 3.378120, mean_eps: 0.554365\n",
      "  49601/1000000: episode: 735, duration: 3.245s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.839 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.022333, mean_squared_error: 9.491480, mean_q: 3.365537, mean_eps: 0.553847\n",
      "  49654/1000000: episode: 736, duration: 3.067s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.736 [0.000, 3.000], mean observation: 39.815 [0.000, 142.000], loss: 0.028341, mean_squared_error: 9.448461, mean_q: 3.374371, mean_eps: 0.553357\n",
      "  49705/1000000: episode: 737, duration: 3.021s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.608 [0.000, 3.000], mean observation: 39.750 [0.000, 142.000], loss: 0.023372, mean_squared_error: 9.260579, mean_q: 3.339651, mean_eps: 0.552889\n",
      "  49801/1000000: episode: 738, duration: 5.566s, episode steps: 96, steps per second: 17, episode reward: 8.000, mean reward: 0.083 [0.000, 4.000], mean action: 1.594 [0.000, 3.000], mean observation: 39.564 [0.000, 142.000], loss: 0.024269, mean_squared_error: 9.560691, mean_q: 3.398344, mean_eps: 0.552227\n",
      "  49855/1000000: episode: 739, duration: 3.141s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.481 [0.000, 3.000], mean observation: 39.740 [0.000, 142.000], loss: 0.026411, mean_squared_error: 9.339658, mean_q: 3.338529, mean_eps: 0.551553\n",
      "  49926/1000000: episode: 740, duration: 4.062s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.646 [0.000, 142.000], loss: 0.021928, mean_squared_error: 9.320774, mean_q: 3.337322, mean_eps: 0.550990\n",
      "  50013/1000000: episode: 741, duration: 5.158s, episode steps: 87, steps per second: 17, episode reward: 6.000, mean reward: 0.069 [0.000, 1.000], mean action: 1.448 [0.000, 3.000], mean observation: 39.459 [0.000, 142.000], loss: 0.022998, mean_squared_error: 9.369271, mean_q: 3.345687, mean_eps: 0.550279\n",
      "  50082/1000000: episode: 742, duration: 4.024s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.594 [0.000, 3.000], mean observation: 39.664 [0.000, 142.000], loss: 0.022754, mean_squared_error: 9.385272, mean_q: 3.334260, mean_eps: 0.549577\n",
      "  50175/1000000: episode: 743, duration: 5.472s, episode steps: 93, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.688 [0.000, 3.000], mean observation: 39.516 [0.000, 142.000], loss: 0.030903, mean_squared_error: 9.185875, mean_q: 3.297258, mean_eps: 0.548848\n",
      "  50238/1000000: episode: 744, duration: 3.700s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.397 [0.000, 3.000], mean observation: 39.722 [0.000, 142.000], loss: 0.025449, mean_squared_error: 9.281542, mean_q: 3.337328, mean_eps: 0.548146\n",
      "  50299/1000000: episode: 745, duration: 3.561s, episode steps: 61, steps per second: 17, episode reward: 2.000, mean reward: 0.033 [0.000, 1.000], mean action: 1.803 [0.000, 3.000], mean observation: 39.747 [0.000, 142.000], loss: 0.024379, mean_squared_error: 9.203838, mean_q: 3.312758, mean_eps: 0.547588\n",
      "  50375/1000000: episode: 746, duration: 4.455s, episode steps: 76, steps per second: 17, episode reward: 11.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.697 [0.000, 3.000], mean observation: 39.554 [0.000, 142.000], loss: 0.024352, mean_squared_error: 9.470700, mean_q: 3.367487, mean_eps: 0.546972\n",
      "  50408/1000000: episode: 747, duration: 1.950s, episode steps: 33, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.818 [0.000, 3.000], mean observation: 40.010 [0.000, 142.000], loss: 0.018750, mean_squared_error: 9.200236, mean_q: 3.317326, mean_eps: 0.546481\n",
      "  50474/1000000: episode: 748, duration: 3.858s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.879 [0.000, 3.000], mean observation: 39.643 [0.000, 142.000], loss: 0.029552, mean_squared_error: 9.567420, mean_q: 3.386216, mean_eps: 0.546036\n",
      "  50532/1000000: episode: 749, duration: 3.413s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.690 [0.000, 3.000], mean observation: 39.732 [0.000, 142.000], loss: 0.024860, mean_squared_error: 9.610737, mean_q: 3.379111, mean_eps: 0.545478\n",
      "  50603/1000000: episode: 750, duration: 4.144s, episode steps: 71, steps per second: 17, episode reward: 7.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.746 [0.000, 3.000], mean observation: 39.698 [0.000, 142.000], loss: 0.026090, mean_squared_error: 9.473962, mean_q: 3.359264, mean_eps: 0.544897\n",
      "  50662/1000000: episode: 751, duration: 3.451s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.695 [0.000, 3.000], mean observation: 39.740 [0.000, 142.000], loss: 0.025448, mean_squared_error: 9.763847, mean_q: 3.426356, mean_eps: 0.544312\n",
      "  50753/1000000: episode: 752, duration: 5.263s, episode steps: 91, steps per second: 17, episode reward: 6.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.725 [0.000, 3.000], mean observation: 39.454 [0.000, 142.000], loss: 0.029369, mean_squared_error: 9.675524, mean_q: 3.405833, mean_eps: 0.543637\n",
      "  50799/1000000: episode: 753, duration: 2.715s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.717 [0.000, 3.000], mean observation: 39.772 [0.000, 142.000], loss: 0.025986, mean_squared_error: 9.618389, mean_q: 3.397902, mean_eps: 0.543020\n",
      "  50853/1000000: episode: 754, duration: 3.216s, episode steps: 54, steps per second: 17, episode reward: 3.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.685 [0.000, 3.000], mean observation: 39.717 [0.000, 142.000], loss: 0.019987, mean_squared_error: 9.607260, mean_q: 3.394121, mean_eps: 0.542570\n",
      "  50903/1000000: episode: 755, duration: 2.885s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.900 [0.000, 3.000], mean observation: 39.776 [0.000, 142.000], loss: 0.018953, mean_squared_error: 9.632593, mean_q: 3.393742, mean_eps: 0.542103\n",
      "  50951/1000000: episode: 756, duration: 2.840s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.312 [0.000, 3.000], mean observation: 39.769 [0.000, 142.000], loss: 0.019813, mean_squared_error: 9.644514, mean_q: 3.393189, mean_eps: 0.541662\n",
      "  51040/1000000: episode: 757, duration: 5.137s, episode steps: 89, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.472 [0.000, 3.000], mean observation: 39.461 [0.000, 142.000], loss: 0.027439, mean_squared_error: 9.466018, mean_q: 3.363121, mean_eps: 0.541045\n",
      "  51123/1000000: episode: 758, duration: 4.844s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.759 [0.000, 3.000], mean observation: 39.524 [0.000, 142.000], loss: 0.020690, mean_squared_error: 9.671739, mean_q: 3.415879, mean_eps: 0.540271\n",
      "  51170/1000000: episode: 759, duration: 2.769s, episode steps: 47, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.638 [0.000, 3.000], mean observation: 39.815 [0.000, 142.000], loss: 0.019233, mean_squared_error: 9.731867, mean_q: 3.401174, mean_eps: 0.539686\n",
      "  51220/1000000: episode: 760, duration: 2.935s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.820 [0.000, 3.000], mean observation: 39.788 [0.000, 142.000], loss: 0.024100, mean_squared_error: 9.750966, mean_q: 3.424484, mean_eps: 0.539250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  51266/1000000: episode: 761, duration: 2.738s, episode steps: 46, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.674 [0.000, 3.000], mean observation: 39.968 [0.000, 142.000], loss: 0.018671, mean_squared_error: 9.751016, mean_q: 3.427230, mean_eps: 0.538817\n",
      "  51376/1000000: episode: 762, duration: 6.422s, episode steps: 110, steps per second: 17, episode reward: 10.000, mean reward: 0.091 [0.000, 4.000], mean action: 1.555 [0.000, 3.000], mean observation: 39.403 [0.000, 142.000], loss: 0.026200, mean_squared_error: 9.571097, mean_q: 3.370174, mean_eps: 0.538115\n",
      "  51435/1000000: episode: 763, duration: 3.433s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.711 [0.000, 142.000], loss: 0.019086, mean_squared_error: 9.745186, mean_q: 3.432001, mean_eps: 0.537355\n",
      "  51523/1000000: episode: 764, duration: 5.242s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.761 [0.000, 3.000], mean observation: 39.494 [0.000, 142.000], loss: 0.021543, mean_squared_error: 9.482648, mean_q: 3.360182, mean_eps: 0.536694\n",
      "  51555/1000000: episode: 765, duration: 1.884s, episode steps: 32, steps per second: 17, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 1.219 [0.000, 3.000], mean observation: 40.050 [0.000, 142.000], loss: 0.023920, mean_squared_error: 9.624884, mean_q: 3.382537, mean_eps: 0.536153\n",
      "  51634/1000000: episode: 766, duration: 4.603s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.633 [0.000, 3.000], mean observation: 39.611 [0.000, 142.000], loss: 0.023426, mean_squared_error: 9.812445, mean_q: 3.419864, mean_eps: 0.535654\n",
      "  51689/1000000: episode: 767, duration: 3.313s, episode steps: 55, steps per second: 17, episode reward: 3.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.636 [0.000, 3.000], mean observation: 39.702 [0.000, 142.000], loss: 0.026312, mean_squared_error: 9.713226, mean_q: 3.394799, mean_eps: 0.535051\n",
      "  51771/1000000: episode: 768, duration: 4.742s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.768 [0.000, 3.000], mean observation: 39.516 [0.000, 142.000], loss: 0.020200, mean_squared_error: 9.429926, mean_q: 3.342311, mean_eps: 0.534434\n",
      "  51811/1000000: episode: 769, duration: 2.373s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.550 [0.000, 3.000], mean observation: 39.744 [0.000, 142.000], loss: 0.017132, mean_squared_error: 9.518862, mean_q: 3.355239, mean_eps: 0.533886\n",
      "  51884/1000000: episode: 770, duration: 4.210s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.575 [0.000, 3.000], mean observation: 39.668 [0.000, 142.000], loss: 0.027588, mean_squared_error: 9.414179, mean_q: 3.349158, mean_eps: 0.533377\n",
      "  51980/1000000: episode: 771, duration: 5.685s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.865 [0.000, 3.000], mean observation: 39.419 [0.000, 142.000], loss: 0.027717, mean_squared_error: 9.656309, mean_q: 3.383385, mean_eps: 0.532616\n",
      "  52039/1000000: episode: 772, duration: 3.447s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.475 [0.000, 3.000], mean observation: 39.696 [0.000, 142.000], loss: 0.018449, mean_squared_error: 9.490203, mean_q: 3.365988, mean_eps: 0.531919\n",
      "  52131/1000000: episode: 773, duration: 5.394s, episode steps: 92, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.511 [0.000, 3.000], mean observation: 39.502 [0.000, 142.000], loss: 0.024531, mean_squared_error: 9.680903, mean_q: 3.392728, mean_eps: 0.531239\n",
      "  52184/1000000: episode: 774, duration: 3.181s, episode steps: 53, steps per second: 17, episode reward: 3.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.566 [0.000, 3.000], mean observation: 39.703 [0.000, 142.000], loss: 0.028463, mean_squared_error: 9.470518, mean_q: 3.354093, mean_eps: 0.530587\n",
      "  52283/1000000: episode: 775, duration: 5.804s, episode steps: 99, steps per second: 17, episode reward: 7.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.606 [0.000, 3.000], mean observation: 39.389 [0.000, 142.000], loss: 0.023651, mean_squared_error: 9.496122, mean_q: 3.363084, mean_eps: 0.529903\n",
      "  52358/1000000: episode: 776, duration: 4.289s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.680 [0.000, 3.000], mean observation: 39.551 [0.000, 142.000], loss: 0.024666, mean_squared_error: 9.564667, mean_q: 3.374423, mean_eps: 0.529120\n",
      "  52428/1000000: episode: 777, duration: 4.140s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.814 [0.000, 3.000], mean observation: 39.704 [0.000, 142.000], loss: 0.023224, mean_squared_error: 9.509021, mean_q: 3.360544, mean_eps: 0.528467\n",
      "  52490/1000000: episode: 778, duration: 3.642s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.516 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.021678, mean_squared_error: 9.717940, mean_q: 3.405791, mean_eps: 0.527873\n",
      "  52558/1000000: episode: 779, duration: 4.025s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.706 [0.000, 3.000], mean observation: 39.647 [0.000, 142.000], loss: 0.023667, mean_squared_error: 9.497875, mean_q: 3.355197, mean_eps: 0.527289\n",
      "  52645/1000000: episode: 780, duration: 5.114s, episode steps: 87, steps per second: 17, episode reward: 6.000, mean reward: 0.069 [0.000, 1.000], mean action: 1.506 [0.000, 3.000], mean observation: 39.498 [0.000, 142.000], loss: 0.023313, mean_squared_error: 9.620887, mean_q: 3.385054, mean_eps: 0.526591\n",
      "  52708/1000000: episode: 781, duration: 3.645s, episode steps: 63, steps per second: 17, episode reward: 7.000, mean reward: 0.111 [0.000, 4.000], mean action: 1.540 [0.000, 3.000], mean observation: 39.647 [0.000, 142.000], loss: 0.022885, mean_squared_error: 9.536434, mean_q: 3.364639, mean_eps: 0.525916\n",
      "  52756/1000000: episode: 782, duration: 2.789s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.604 [0.000, 3.000], mean observation: 39.689 [0.000, 142.000], loss: 0.020796, mean_squared_error: 9.686834, mean_q: 3.400763, mean_eps: 0.525416\n",
      "  52837/1000000: episode: 783, duration: 4.743s, episode steps: 81, steps per second: 17, episode reward: 8.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.901 [0.000, 3.000], mean observation: 39.627 [0.000, 142.000], loss: 0.020275, mean_squared_error: 9.605807, mean_q: 3.380735, mean_eps: 0.524836\n",
      "  52893/1000000: episode: 784, duration: 3.336s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.393 [0.000, 3.000], mean observation: 39.758 [0.000, 142.000], loss: 0.023797, mean_squared_error: 9.756503, mean_q: 3.404824, mean_eps: 0.524219\n",
      "  52933/1000000: episode: 785, duration: 2.310s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.940 [0.000, 142.000], loss: 0.032368, mean_squared_error: 9.627307, mean_q: 3.365619, mean_eps: 0.523787\n",
      "  53025/1000000: episode: 786, duration: 5.368s, episode steps: 92, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.609 [0.000, 3.000], mean observation: 39.591 [0.000, 142.000], loss: 0.023732, mean_squared_error: 9.410537, mean_q: 3.336580, mean_eps: 0.523193\n",
      "  53078/1000000: episode: 787, duration: 3.139s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.509 [0.000, 3.000], mean observation: 39.752 [0.000, 142.000], loss: 0.022183, mean_squared_error: 9.780683, mean_q: 3.415459, mean_eps: 0.522541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  53175/1000000: episode: 788, duration: 5.553s, episode steps: 97, steps per second: 17, episode reward: 7.000, mean reward: 0.072 [0.000, 1.000], mean action: 1.629 [0.000, 3.000], mean observation: 39.421 [0.000, 142.000], loss: 0.026361, mean_squared_error: 9.588667, mean_q: 3.375672, mean_eps: 0.521866\n",
      "  53263/1000000: episode: 789, duration: 5.051s, episode steps: 88, steps per second: 17, episode reward: 6.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.545 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.025033, mean_squared_error: 9.807171, mean_q: 3.407275, mean_eps: 0.521033\n",
      "  53301/1000000: episode: 790, duration: 2.274s, episode steps: 38, steps per second: 17, episode reward: 1.000, mean reward: 0.026 [0.000, 1.000], mean action: 1.526 [0.000, 3.000], mean observation: 39.746 [0.000, 142.000], loss: 0.018651, mean_squared_error: 9.859452, mean_q: 3.431975, mean_eps: 0.520466\n",
      "  53378/1000000: episode: 791, duration: 4.451s, episode steps: 77, steps per second: 17, episode reward: 4.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.675 [0.000, 3.000], mean observation: 39.635 [0.000, 142.000], loss: 0.020974, mean_squared_error: 9.535637, mean_q: 3.353038, mean_eps: 0.519949\n",
      "  53432/1000000: episode: 792, duration: 3.101s, episode steps: 54, steps per second: 17, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.778 [0.000, 3.000], mean observation: 39.762 [0.000, 142.000], loss: 0.022484, mean_squared_error: 9.910395, mean_q: 3.461561, mean_eps: 0.519359\n",
      "  53510/1000000: episode: 793, duration: 4.476s, episode steps: 78, steps per second: 17, episode reward: 5.000, mean reward: 0.064 [0.000, 1.000], mean action: 1.538 [0.000, 3.000], mean observation: 39.585 [0.000, 142.000], loss: 0.022857, mean_squared_error: 9.645305, mean_q: 3.371604, mean_eps: 0.518765\n",
      "  53584/1000000: episode: 794, duration: 4.344s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.811 [0.000, 3.000], mean observation: 39.621 [0.000, 142.000], loss: 0.022085, mean_squared_error: 9.775435, mean_q: 3.404907, mean_eps: 0.518081\n",
      "  53651/1000000: episode: 795, duration: 3.974s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.791 [0.000, 3.000], mean observation: 39.662 [0.000, 142.000], loss: 0.021712, mean_squared_error: 9.798038, mean_q: 3.422287, mean_eps: 0.517447\n",
      "  53708/1000000: episode: 796, duration: 3.426s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.579 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.020791, mean_squared_error: 9.546699, mean_q: 3.372584, mean_eps: 0.516889\n",
      "  53754/1000000: episode: 797, duration: 2.722s, episode steps: 46, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.609 [0.000, 3.000], mean observation: 39.764 [0.000, 142.000], loss: 0.025374, mean_squared_error: 9.882257, mean_q: 3.419840, mean_eps: 0.516425\n",
      "  53804/1000000: episode: 798, duration: 2.965s, episode steps: 50, steps per second: 17, episode reward: 2.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.780 [0.000, 3.000], mean observation: 39.870 [0.000, 142.000], loss: 0.027801, mean_squared_error: 9.987614, mean_q: 3.444024, mean_eps: 0.515993\n",
      "  53874/1000000: episode: 799, duration: 4.173s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.634 [0.000, 142.000], loss: 0.023677, mean_squared_error: 9.884021, mean_q: 3.429059, mean_eps: 0.515454\n",
      "  53937/1000000: episode: 800, duration: 3.697s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.841 [0.000, 3.000], mean observation: 39.687 [0.000, 142.000], loss: 0.025022, mean_squared_error: 9.717597, mean_q: 3.381351, mean_eps: 0.514855\n",
      "  53997/1000000: episode: 801, duration: 3.505s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.517 [0.000, 3.000], mean observation: 39.711 [0.000, 142.000], loss: 0.017099, mean_squared_error: 9.886694, mean_q: 3.438866, mean_eps: 0.514301\n",
      "  54065/1000000: episode: 802, duration: 4.049s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.735 [0.000, 3.000], mean observation: 39.625 [0.000, 142.000], loss: 0.023375, mean_squared_error: 9.761475, mean_q: 3.395182, mean_eps: 0.513725\n",
      "  54118/1000000: episode: 803, duration: 3.056s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.981 [0.000, 3.000], mean observation: 39.742 [0.000, 142.000], loss: 0.027162, mean_squared_error: 9.890503, mean_q: 3.426460, mean_eps: 0.513181\n",
      "  54201/1000000: episode: 804, duration: 4.858s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.627 [0.000, 3.000], mean observation: 39.608 [0.000, 142.000], loss: 0.018955, mean_squared_error: 9.829692, mean_q: 3.422643, mean_eps: 0.512569\n",
      "  54272/1000000: episode: 805, duration: 4.224s, episode steps: 71, steps per second: 17, episode reward: 8.000, mean reward: 0.113 [0.000, 4.000], mean action: 1.493 [0.000, 3.000], mean observation: 39.583 [0.000, 142.000], loss: 0.030604, mean_squared_error: 9.944272, mean_q: 3.443561, mean_eps: 0.511876\n",
      "  54341/1000000: episode: 806, duration: 4.112s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.797 [0.000, 3.000], mean observation: 39.650 [0.000, 142.000], loss: 0.023452, mean_squared_error: 9.842474, mean_q: 3.423220, mean_eps: 0.511246\n",
      "  54401/1000000: episode: 807, duration: 3.566s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.633 [0.000, 3.000], mean observation: 39.693 [0.000, 142.000], loss: 0.023092, mean_squared_error: 10.182463, mean_q: 3.487061, mean_eps: 0.510665\n",
      "  54477/1000000: episode: 808, duration: 4.362s, episode steps: 76, steps per second: 17, episode reward: 5.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.671 [0.000, 3.000], mean observation: 39.570 [0.000, 142.000], loss: 0.026073, mean_squared_error: 9.823769, mean_q: 3.409365, mean_eps: 0.510054\n",
      "  54538/1000000: episode: 809, duration: 3.580s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.525 [0.000, 3.000], mean observation: 39.677 [0.000, 142.000], loss: 0.027592, mean_squared_error: 9.615221, mean_q: 3.363152, mean_eps: 0.509437\n",
      "  54601/1000000: episode: 810, duration: 3.701s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.695 [0.000, 142.000], loss: 0.023388, mean_squared_error: 9.898341, mean_q: 3.419403, mean_eps: 0.508879\n",
      "  54681/1000000: episode: 811, duration: 4.636s, episode steps: 80, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.650 [0.000, 3.000], mean observation: 39.593 [0.000, 142.000], loss: 0.025438, mean_squared_error: 9.812548, mean_q: 3.391370, mean_eps: 0.508235\n",
      "  54749/1000000: episode: 812, duration: 3.911s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.721 [0.000, 3.000], mean observation: 39.632 [0.000, 142.000], loss: 0.025251, mean_squared_error: 9.644426, mean_q: 3.372792, mean_eps: 0.507570\n",
      "  54814/1000000: episode: 813, duration: 3.822s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.569 [0.000, 3.000], mean observation: 39.746 [0.000, 142.000], loss: 0.021846, mean_squared_error: 9.969431, mean_q: 3.433641, mean_eps: 0.506971\n",
      "  54875/1000000: episode: 814, duration: 3.587s, episode steps: 61, steps per second: 17, episode reward: 4.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.639 [0.000, 3.000], mean observation: 39.635 [0.000, 142.000], loss: 0.028049, mean_squared_error: 9.816317, mean_q: 3.401285, mean_eps: 0.506404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  54942/1000000: episode: 815, duration: 3.923s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.657 [0.000, 3.000], mean observation: 39.647 [0.000, 142.000], loss: 0.020480, mean_squared_error: 10.186132, mean_q: 3.486117, mean_eps: 0.505828\n",
      "  55037/1000000: episode: 816, duration: 5.523s, episode steps: 95, steps per second: 17, episode reward: 6.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.716 [0.000, 3.000], mean observation: 39.517 [0.000, 142.000], loss: 0.025855, mean_squared_error: 9.950506, mean_q: 3.437284, mean_eps: 0.505099\n",
      "  55106/1000000: episode: 817, duration: 4.044s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.841 [0.000, 3.000], mean observation: 39.695 [0.000, 142.000], loss: 0.025162, mean_squared_error: 9.986598, mean_q: 3.448590, mean_eps: 0.504361\n",
      "  55161/1000000: episode: 818, duration: 3.247s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.800 [0.000, 3.000], mean observation: 39.846 [0.000, 142.000], loss: 0.019551, mean_squared_error: 10.228213, mean_q: 3.483397, mean_eps: 0.503803\n",
      "  55201/1000000: episode: 819, duration: 2.416s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.675 [0.000, 3.000], mean observation: 39.791 [0.000, 142.000], loss: 0.032054, mean_squared_error: 10.099475, mean_q: 3.470218, mean_eps: 0.503375\n",
      "  55266/1000000: episode: 820, duration: 3.786s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.815 [0.000, 3.000], mean observation: 39.624 [0.000, 142.000], loss: 0.030844, mean_squared_error: 9.776925, mean_q: 3.402777, mean_eps: 0.502903\n",
      "  55318/1000000: episode: 821, duration: 2.996s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.732 [0.000, 142.000], loss: 0.027158, mean_squared_error: 9.971742, mean_q: 3.457177, mean_eps: 0.502377\n",
      "  55376/1000000: episode: 822, duration: 3.448s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.897 [0.000, 3.000], mean observation: 39.722 [0.000, 142.000], loss: 0.026909, mean_squared_error: 9.916697, mean_q: 3.429505, mean_eps: 0.501881\n",
      "  55459/1000000: episode: 823, duration: 4.877s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.651 [0.000, 3.000], mean observation: 39.536 [0.000, 142.000], loss: 0.022997, mean_squared_error: 10.277996, mean_q: 3.500135, mean_eps: 0.501247\n",
      "  55499/1000000: episode: 824, duration: 2.323s, episode steps: 40, steps per second: 17, episode reward: 1.000, mean reward: 0.025 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.950 [0.000, 142.000], loss: 0.023186, mean_squared_error: 10.377588, mean_q: 3.499133, mean_eps: 0.500694\n",
      "  55567/1000000: episode: 825, duration: 4.007s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.588 [0.000, 3.000], mean observation: 39.645 [0.000, 142.000], loss: 0.023639, mean_squared_error: 10.030996, mean_q: 3.446972, mean_eps: 0.500208\n",
      "  55657/1000000: episode: 826, duration: 5.219s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.733 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.023806, mean_squared_error: 10.198008, mean_q: 3.476287, mean_eps: 0.499496\n",
      "  55720/1000000: episode: 827, duration: 3.648s, episode steps: 63, steps per second: 17, episode reward: 4.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.648 [0.000, 142.000], loss: 0.021566, mean_squared_error: 9.847522, mean_q: 3.419600, mean_eps: 0.498808\n",
      "  55838/1000000: episode: 828, duration: 6.826s, episode steps: 118, steps per second: 17, episode reward: 11.000, mean reward: 0.093 [0.000, 4.000], mean action: 1.653 [0.000, 3.000], mean observation: 39.316 [0.000, 142.000], loss: 0.023244, mean_squared_error: 10.138628, mean_q: 3.476247, mean_eps: 0.497993\n",
      "  55925/1000000: episode: 829, duration: 5.024s, episode steps: 87, steps per second: 17, episode reward: 6.000, mean reward: 0.069 [0.000, 1.000], mean action: 1.402 [0.000, 3.000], mean observation: 39.563 [0.000, 142.000], loss: 0.026199, mean_squared_error: 10.243692, mean_q: 3.501013, mean_eps: 0.497071\n",
      "  55996/1000000: episode: 830, duration: 4.271s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.690 [0.000, 3.000], mean observation: 39.643 [0.000, 142.000], loss: 0.026208, mean_squared_error: 10.139913, mean_q: 3.490814, mean_eps: 0.496360\n",
      "  56056/1000000: episode: 831, duration: 3.595s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.583 [0.000, 3.000], mean observation: 39.759 [0.000, 142.000], loss: 0.026339, mean_squared_error: 10.159258, mean_q: 3.470301, mean_eps: 0.495771\n",
      "  56173/1000000: episode: 832, duration: 7.178s, episode steps: 117, steps per second: 16, episode reward: 9.000, mean reward: 0.077 [0.000, 1.000], mean action: 1.863 [0.000, 3.000], mean observation: 39.273 [0.000, 142.000], loss: 0.026797, mean_squared_error: 10.440145, mean_q: 3.531203, mean_eps: 0.494974\n",
      "  56238/1000000: episode: 833, duration: 3.935s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.723 [0.000, 3.000], mean observation: 39.791 [0.000, 142.000], loss: 0.027741, mean_squared_error: 10.197113, mean_q: 3.481406, mean_eps: 0.494155\n",
      "  56285/1000000: episode: 834, duration: 2.782s, episode steps: 47, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.255 [0.000, 3.000], mean observation: 39.814 [0.000, 142.000], loss: 0.029909, mean_squared_error: 10.319989, mean_q: 3.528270, mean_eps: 0.493651\n",
      "  56350/1000000: episode: 835, duration: 3.847s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.708 [0.000, 3.000], mean observation: 39.632 [0.000, 142.000], loss: 0.026419, mean_squared_error: 10.487956, mean_q: 3.547272, mean_eps: 0.493147\n",
      "  56414/1000000: episode: 836, duration: 3.735s, episode steps: 64, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.703 [0.000, 3.000], mean observation: 39.676 [0.000, 142.000], loss: 0.022414, mean_squared_error: 10.413892, mean_q: 3.538401, mean_eps: 0.492567\n",
      "  56480/1000000: episode: 837, duration: 3.812s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.591 [0.000, 3.000], mean observation: 39.660 [0.000, 142.000], loss: 0.022401, mean_squared_error: 10.411820, mean_q: 3.525525, mean_eps: 0.491982\n",
      "  56569/1000000: episode: 838, duration: 5.207s, episode steps: 89, steps per second: 17, episode reward: 5.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.865 [0.000, 3.000], mean observation: 39.536 [0.000, 142.000], loss: 0.023891, mean_squared_error: 10.267492, mean_q: 3.495578, mean_eps: 0.491284\n",
      "  56694/1000000: episode: 839, duration: 7.281s, episode steps: 125, steps per second: 17, episode reward: 7.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.608 [0.000, 3.000], mean observation: 39.353 [0.000, 142.000], loss: 0.026381, mean_squared_error: 10.493397, mean_q: 3.540791, mean_eps: 0.490321\n",
      "  56762/1000000: episode: 840, duration: 3.999s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.544 [0.000, 3.000], mean observation: 39.664 [0.000, 142.000], loss: 0.021508, mean_squared_error: 10.432002, mean_q: 3.540562, mean_eps: 0.489452\n",
      "  56828/1000000: episode: 841, duration: 3.873s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.606 [0.000, 3.000], mean observation: 39.592 [0.000, 142.000], loss: 0.028087, mean_squared_error: 10.485391, mean_q: 3.536736, mean_eps: 0.488849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  56894/1000000: episode: 842, duration: 3.864s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.939 [0.000, 3.000], mean observation: 39.645 [0.000, 142.000], loss: 0.021122, mean_squared_error: 10.801785, mean_q: 3.597953, mean_eps: 0.488256\n",
      "  56963/1000000: episode: 843, duration: 4.073s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.565 [0.000, 3.000], mean observation: 39.650 [0.000, 142.000], loss: 0.021862, mean_squared_error: 10.577893, mean_q: 3.543689, mean_eps: 0.487648\n",
      "  57029/1000000: episode: 844, duration: 3.779s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.803 [0.000, 3.000], mean observation: 39.628 [0.000, 142.000], loss: 0.022704, mean_squared_error: 10.472168, mean_q: 3.537102, mean_eps: 0.487040\n",
      "  57094/1000000: episode: 845, duration: 3.794s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.677 [0.000, 3.000], mean observation: 39.618 [0.000, 142.000], loss: 0.025478, mean_squared_error: 10.827336, mean_q: 3.618751, mean_eps: 0.486451\n",
      "  57163/1000000: episode: 846, duration: 3.993s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.681 [0.000, 3.000], mean observation: 39.640 [0.000, 142.000], loss: 0.023913, mean_squared_error: 10.827672, mean_q: 3.613950, mean_eps: 0.485848\n",
      "  57248/1000000: episode: 847, duration: 4.911s, episode steps: 85, steps per second: 17, episode reward: 6.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.527 [0.000, 142.000], loss: 0.027326, mean_squared_error: 10.772143, mean_q: 3.591059, mean_eps: 0.485155\n",
      "  57327/1000000: episode: 848, duration: 4.571s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.646 [0.000, 3.000], mean observation: 39.548 [0.000, 142.000], loss: 0.023300, mean_squared_error: 10.713461, mean_q: 3.597664, mean_eps: 0.484417\n",
      "  57397/1000000: episode: 849, duration: 4.098s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.786 [0.000, 3.000], mean observation: 39.616 [0.000, 142.000], loss: 0.028599, mean_squared_error: 10.287314, mean_q: 3.488565, mean_eps: 0.483746\n",
      "  57496/1000000: episode: 850, duration: 5.611s, episode steps: 99, steps per second: 18, episode reward: 6.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.636 [0.000, 3.000], mean observation: 39.516 [0.000, 142.000], loss: 0.025074, mean_squared_error: 10.635446, mean_q: 3.581547, mean_eps: 0.482986\n",
      "  57552/1000000: episode: 851, duration: 3.346s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.698 [0.000, 142.000], loss: 0.023162, mean_squared_error: 10.910074, mean_q: 3.609941, mean_eps: 0.482289\n",
      "  57633/1000000: episode: 852, duration: 4.668s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.432 [0.000, 3.000], mean observation: 39.567 [0.000, 142.000], loss: 0.022177, mean_squared_error: 10.806412, mean_q: 3.588397, mean_eps: 0.481672\n",
      "  57696/1000000: episode: 853, duration: 3.791s, episode steps: 63, steps per second: 17, episode reward: 4.000, mean reward: 0.063 [0.000, 1.000], mean action: 2.111 [0.000, 3.000], mean observation: 39.638 [0.000, 142.000], loss: 0.025926, mean_squared_error: 10.941233, mean_q: 3.628464, mean_eps: 0.481024\n",
      "  57769/1000000: episode: 854, duration: 4.273s, episode steps: 73, steps per second: 17, episode reward: 7.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.644 [0.000, 3.000], mean observation: 39.649 [0.000, 142.000], loss: 0.021152, mean_squared_error: 10.766533, mean_q: 3.578529, mean_eps: 0.480412\n",
      "  57842/1000000: episode: 855, duration: 4.312s, episode steps: 73, steps per second: 17, episode reward: 11.000, mean reward: 0.151 [0.000, 4.000], mean action: 1.836 [0.000, 3.000], mean observation: 39.546 [0.000, 142.000], loss: 0.021843, mean_squared_error: 10.783143, mean_q: 3.605106, mean_eps: 0.479755\n",
      "  57919/1000000: episode: 856, duration: 4.558s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.623 [0.000, 3.000], mean observation: 39.552 [0.000, 142.000], loss: 0.022393, mean_squared_error: 10.953007, mean_q: 3.597976, mean_eps: 0.479080\n",
      "  57974/1000000: episode: 857, duration: 3.224s, episode steps: 55, steps per second: 17, episode reward: 3.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.655 [0.000, 3.000], mean observation: 39.729 [0.000, 142.000], loss: 0.022678, mean_squared_error: 11.022954, mean_q: 3.647949, mean_eps: 0.478486\n",
      "  58063/1000000: episode: 858, duration: 5.345s, episode steps: 89, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.843 [0.000, 3.000], mean observation: 39.479 [0.000, 142.000], loss: 0.021904, mean_squared_error: 11.153029, mean_q: 3.646037, mean_eps: 0.477838\n",
      "  58191/1000000: episode: 859, duration: 7.521s, episode steps: 128, steps per second: 17, episode reward: 13.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.688 [0.000, 3.000], mean observation: 39.129 [0.000, 142.000], loss: 0.022586, mean_squared_error: 10.871658, mean_q: 3.598719, mean_eps: 0.476861\n",
      "  58250/1000000: episode: 860, duration: 3.512s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.729 [0.000, 3.000], mean observation: 39.794 [0.000, 142.000], loss: 0.024566, mean_squared_error: 10.819011, mean_q: 3.592679, mean_eps: 0.476020\n",
      "  58318/1000000: episode: 861, duration: 3.943s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.529 [0.000, 3.000], mean observation: 39.672 [0.000, 142.000], loss: 0.024673, mean_squared_error: 11.031950, mean_q: 3.623767, mean_eps: 0.475448\n",
      "  58367/1000000: episode: 862, duration: 2.922s, episode steps: 49, steps per second: 17, episode reward: 2.000, mean reward: 0.041 [0.000, 1.000], mean action: 1.755 [0.000, 3.000], mean observation: 39.731 [0.000, 142.000], loss: 0.024249, mean_squared_error: 10.986125, mean_q: 3.617832, mean_eps: 0.474922\n",
      "  58450/1000000: episode: 863, duration: 4.792s, episode steps: 83, steps per second: 17, episode reward: 6.000, mean reward: 0.072 [0.000, 1.000], mean action: 1.735 [0.000, 3.000], mean observation: 39.461 [0.000, 142.000], loss: 0.027904, mean_squared_error: 11.169644, mean_q: 3.673267, mean_eps: 0.474328\n",
      "  58518/1000000: episode: 864, duration: 4.003s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.638 [0.000, 142.000], loss: 0.022676, mean_squared_error: 11.140265, mean_q: 3.669801, mean_eps: 0.473648\n",
      "  58579/1000000: episode: 865, duration: 3.634s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.820 [0.000, 3.000], mean observation: 39.723 [0.000, 142.000], loss: 0.024864, mean_squared_error: 11.603255, mean_q: 3.743313, mean_eps: 0.473068\n",
      "  58641/1000000: episode: 866, duration: 3.665s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.839 [0.000, 3.000], mean observation: 39.722 [0.000, 142.000], loss: 0.024117, mean_squared_error: 11.305069, mean_q: 3.698773, mean_eps: 0.472515\n",
      "  58710/1000000: episode: 867, duration: 4.080s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.855 [0.000, 3.000], mean observation: 39.639 [0.000, 142.000], loss: 0.020835, mean_squared_error: 11.304802, mean_q: 3.694005, mean_eps: 0.471925\n",
      "  58767/1000000: episode: 868, duration: 3.368s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.526 [0.000, 3.000], mean observation: 39.728 [0.000, 142.000], loss: 0.020869, mean_squared_error: 11.175764, mean_q: 3.650803, mean_eps: 0.471358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  58825/1000000: episode: 869, duration: 3.405s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.862 [0.000, 3.000], mean observation: 39.685 [0.000, 142.000], loss: 0.022248, mean_squared_error: 10.999170, mean_q: 3.614929, mean_eps: 0.470840\n",
      "  58922/1000000: episode: 870, duration: 5.692s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.753 [0.000, 3.000], mean observation: 39.416 [0.000, 142.000], loss: 0.021772, mean_squared_error: 11.084542, mean_q: 3.643129, mean_eps: 0.470143\n",
      "  58981/1000000: episode: 871, duration: 3.481s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.688 [0.000, 142.000], loss: 0.025494, mean_squared_error: 11.364409, mean_q: 3.686292, mean_eps: 0.469441\n",
      "  59080/1000000: episode: 872, duration: 5.741s, episode steps: 99, steps per second: 17, episode reward: 9.000, mean reward: 0.091 [0.000, 4.000], mean action: 1.768 [0.000, 3.000], mean observation: 39.539 [0.000, 142.000], loss: 0.022547, mean_squared_error: 11.028625, mean_q: 3.628674, mean_eps: 0.468730\n",
      "  59149/1000000: episode: 873, duration: 4.031s, episode steps: 69, steps per second: 17, episode reward: 3.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.565 [0.000, 3.000], mean observation: 39.696 [0.000, 142.000], loss: 0.025444, mean_squared_error: 11.271047, mean_q: 3.678054, mean_eps: 0.467974\n",
      "  59207/1000000: episode: 874, duration: 3.380s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.655 [0.000, 3.000], mean observation: 39.728 [0.000, 142.000], loss: 0.022773, mean_squared_error: 11.341866, mean_q: 3.679882, mean_eps: 0.467402\n",
      "  59286/1000000: episode: 875, duration: 4.713s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.797 [0.000, 3.000], mean observation: 39.569 [0.000, 142.000], loss: 0.021131, mean_squared_error: 11.403579, mean_q: 3.691190, mean_eps: 0.466786\n",
      "  59345/1000000: episode: 876, duration: 3.465s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.576 [0.000, 3.000], mean observation: 39.792 [0.000, 142.000], loss: 0.024998, mean_squared_error: 11.312000, mean_q: 3.671013, mean_eps: 0.466165\n",
      "  59435/1000000: episode: 877, duration: 5.194s, episode steps: 90, steps per second: 17, episode reward: 5.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.722 [0.000, 3.000], mean observation: 39.651 [0.000, 142.000], loss: 0.022948, mean_squared_error: 11.332427, mean_q: 3.661962, mean_eps: 0.465495\n",
      "  59483/1000000: episode: 878, duration: 2.883s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.521 [0.000, 3.000], mean observation: 39.867 [0.000, 142.000], loss: 0.024807, mean_squared_error: 11.619064, mean_q: 3.736525, mean_eps: 0.464873\n",
      "  59586/1000000: episode: 879, duration: 5.902s, episode steps: 103, steps per second: 17, episode reward: 7.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.680 [0.000, 3.000], mean observation: 39.387 [0.000, 142.000], loss: 0.024218, mean_squared_error: 11.333247, mean_q: 3.675558, mean_eps: 0.464194\n",
      "  59655/1000000: episode: 880, duration: 4.088s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.478 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.023425, mean_squared_error: 11.377777, mean_q: 3.691840, mean_eps: 0.463420\n",
      "  59703/1000000: episode: 881, duration: 2.804s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.792 [0.000, 3.000], mean observation: 39.810 [0.000, 142.000], loss: 0.026218, mean_squared_error: 11.517384, mean_q: 3.707585, mean_eps: 0.462894\n",
      "  59748/1000000: episode: 882, duration: 2.598s, episode steps: 45, steps per second: 17, episode reward: 1.000, mean reward: 0.022 [0.000, 1.000], mean action: 1.978 [0.000, 3.000], mean observation: 39.952 [0.000, 142.000], loss: 0.020955, mean_squared_error: 11.656038, mean_q: 3.746408, mean_eps: 0.462475\n",
      "  59822/1000000: episode: 883, duration: 4.269s, episode steps: 74, steps per second: 17, episode reward: 8.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.919 [0.000, 3.000], mean observation: 39.567 [0.000, 142.000], loss: 0.023174, mean_squared_error: 11.539960, mean_q: 3.714091, mean_eps: 0.461940\n",
      "  59907/1000000: episode: 884, duration: 4.977s, episode steps: 85, steps per second: 17, episode reward: 5.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.729 [0.000, 3.000], mean observation: 39.578 [0.000, 142.000], loss: 0.022410, mean_squared_error: 11.511946, mean_q: 3.710704, mean_eps: 0.461224\n",
      "  59972/1000000: episode: 885, duration: 3.839s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.985 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.026430, mean_squared_error: 11.297852, mean_q: 3.662769, mean_eps: 0.460549\n",
      "  60083/1000000: episode: 886, duration: 6.436s, episode steps: 111, steps per second: 17, episode reward: 11.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.901 [0.000, 3.000], mean observation: 39.303 [0.000, 142.000], loss: 0.027145, mean_squared_error: 11.498266, mean_q: 3.701201, mean_eps: 0.459757\n",
      "  60141/1000000: episode: 887, duration: 3.363s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.810 [0.000, 3.000], mean observation: 39.702 [0.000, 142.000], loss: 0.021332, mean_squared_error: 11.547904, mean_q: 3.735009, mean_eps: 0.458996\n",
      "  60199/1000000: episode: 888, duration: 3.348s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.603 [0.000, 3.000], mean observation: 39.759 [0.000, 142.000], loss: 0.023890, mean_squared_error: 11.658506, mean_q: 3.743231, mean_eps: 0.458474\n",
      "  60256/1000000: episode: 889, duration: 3.305s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.789 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.026613, mean_squared_error: 11.370196, mean_q: 3.687910, mean_eps: 0.457957\n",
      "  60339/1000000: episode: 890, duration: 4.782s, episode steps: 83, steps per second: 17, episode reward: 8.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.711 [0.000, 3.000], mean observation: 39.582 [0.000, 142.000], loss: 0.024658, mean_squared_error: 11.679026, mean_q: 3.737119, mean_eps: 0.457327\n",
      "  60417/1000000: episode: 891, duration: 4.579s, episode steps: 78, steps per second: 17, episode reward: 11.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.897 [0.000, 3.000], mean observation: 39.534 [0.000, 142.000], loss: 0.026668, mean_squared_error: 11.583672, mean_q: 3.711375, mean_eps: 0.456603\n",
      "  60491/1000000: episode: 892, duration: 4.315s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.784 [0.000, 3.000], mean observation: 39.673 [0.000, 142.000], loss: 0.021823, mean_squared_error: 11.729461, mean_q: 3.763228, mean_eps: 0.455919\n",
      "  60607/1000000: episode: 893, duration: 6.658s, episode steps: 116, steps per second: 17, episode reward: 11.000, mean reward: 0.095 [0.000, 4.000], mean action: 1.828 [0.000, 3.000], mean observation: 39.352 [0.000, 142.000], loss: 0.022356, mean_squared_error: 11.567490, mean_q: 3.711627, mean_eps: 0.455064\n",
      "  60682/1000000: episode: 894, duration: 4.331s, episode steps: 75, steps per second: 17, episode reward: 5.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.520 [0.000, 3.000], mean observation: 39.569 [0.000, 142.000], loss: 0.029280, mean_squared_error: 11.881048, mean_q: 3.781323, mean_eps: 0.454204\n",
      "  60740/1000000: episode: 895, duration: 3.385s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.569 [0.000, 3.000], mean observation: 39.721 [0.000, 142.000], loss: 0.028236, mean_squared_error: 11.999726, mean_q: 3.785395, mean_eps: 0.453605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60797/1000000: episode: 896, duration: 3.334s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.702 [0.000, 3.000], mean observation: 39.798 [0.000, 142.000], loss: 0.023130, mean_squared_error: 11.508604, mean_q: 3.701175, mean_eps: 0.453088\n",
      "  60882/1000000: episode: 897, duration: 4.848s, episode steps: 85, steps per second: 18, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.729 [0.000, 3.000], mean observation: 39.502 [0.000, 142.000], loss: 0.024031, mean_squared_error: 11.824450, mean_q: 3.769752, mean_eps: 0.452449\n",
      "  60937/1000000: episode: 898, duration: 3.135s, episode steps: 55, steps per second: 18, episode reward: 3.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.891 [0.000, 3.000], mean observation: 39.702 [0.000, 142.000], loss: 0.027368, mean_squared_error: 11.538199, mean_q: 3.709350, mean_eps: 0.451819\n",
      "  61002/1000000: episode: 899, duration: 3.834s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.631 [0.000, 3.000], mean observation: 39.724 [0.000, 142.000], loss: 0.024723, mean_squared_error: 11.805792, mean_q: 3.755165, mean_eps: 0.451279\n",
      "  61087/1000000: episode: 900, duration: 4.919s, episode steps: 85, steps per second: 17, episode reward: 5.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.753 [0.000, 3.000], mean observation: 39.570 [0.000, 142.000], loss: 0.026422, mean_squared_error: 11.904588, mean_q: 3.769206, mean_eps: 0.450604\n",
      "  61151/1000000: episode: 901, duration: 3.734s, episode steps: 64, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.922 [0.000, 3.000], mean observation: 39.639 [0.000, 142.000], loss: 0.027874, mean_squared_error: 11.631693, mean_q: 3.714412, mean_eps: 0.449933\n",
      "  61230/1000000: episode: 902, duration: 4.567s, episode steps: 79, steps per second: 17, episode reward: 4.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.772 [0.000, 3.000], mean observation: 39.613 [0.000, 142.000], loss: 0.023160, mean_squared_error: 11.693084, mean_q: 3.714812, mean_eps: 0.449290\n",
      "  61288/1000000: episode: 903, duration: 3.323s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.707 [0.000, 3.000], mean observation: 39.708 [0.000, 142.000], loss: 0.023420, mean_squared_error: 11.682671, mean_q: 3.706813, mean_eps: 0.448673\n",
      "  61358/1000000: episode: 904, duration: 4.051s, episode steps: 70, steps per second: 17, episode reward: 7.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.657 [0.000, 3.000], mean observation: 39.619 [0.000, 142.000], loss: 0.029735, mean_squared_error: 11.721626, mean_q: 3.746113, mean_eps: 0.448097\n",
      "  61465/1000000: episode: 905, duration: 6.198s, episode steps: 107, steps per second: 17, episode reward: 7.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.907 [0.000, 3.000], mean observation: 39.436 [0.000, 142.000], loss: 0.023866, mean_squared_error: 11.894421, mean_q: 3.765533, mean_eps: 0.447301\n",
      "  61512/1000000: episode: 906, duration: 2.761s, episode steps: 47, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.702 [0.000, 3.000], mean observation: 39.695 [0.000, 142.000], loss: 0.023296, mean_squared_error: 11.842636, mean_q: 3.740415, mean_eps: 0.446608\n",
      "  61607/1000000: episode: 907, duration: 5.613s, episode steps: 95, steps per second: 17, episode reward: 6.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.632 [0.000, 3.000], mean observation: 39.525 [0.000, 142.000], loss: 0.024657, mean_squared_error: 12.146648, mean_q: 3.817281, mean_eps: 0.445969\n",
      "  61679/1000000: episode: 908, duration: 4.196s, episode steps: 72, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.667 [0.000, 142.000], loss: 0.031755, mean_squared_error: 11.542622, mean_q: 3.694033, mean_eps: 0.445217\n",
      "  61772/1000000: episode: 909, duration: 5.452s, episode steps: 93, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.720 [0.000, 3.000], mean observation: 39.549 [0.000, 142.000], loss: 0.024159, mean_squared_error: 12.155486, mean_q: 3.806481, mean_eps: 0.444475\n",
      "  61815/1000000: episode: 910, duration: 2.488s, episode steps: 43, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.791 [0.000, 3.000], mean observation: 39.747 [0.000, 142.000], loss: 0.023207, mean_squared_error: 12.108786, mean_q: 3.802085, mean_eps: 0.443863\n",
      "  61901/1000000: episode: 911, duration: 4.912s, episode steps: 86, steps per second: 18, episode reward: 5.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.709 [0.000, 3.000], mean observation: 39.623 [0.000, 142.000], loss: 0.024603, mean_squared_error: 11.915066, mean_q: 3.774846, mean_eps: 0.443283\n",
      "  61977/1000000: episode: 912, duration: 4.575s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.487 [0.000, 3.000], mean observation: 39.584 [0.000, 142.000], loss: 0.026063, mean_squared_error: 11.855402, mean_q: 3.738076, mean_eps: 0.442553\n",
      "  62055/1000000: episode: 913, duration: 4.684s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.603 [0.000, 3.000], mean observation: 39.546 [0.000, 142.000], loss: 0.030302, mean_squared_error: 12.229712, mean_q: 3.833868, mean_eps: 0.441860\n",
      "  62130/1000000: episode: 914, duration: 4.354s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.920 [0.000, 3.000], mean observation: 39.585 [0.000, 142.000], loss: 0.026694, mean_squared_error: 12.277448, mean_q: 3.839750, mean_eps: 0.441172\n",
      "  62187/1000000: episode: 915, duration: 3.313s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.706 [0.000, 142.000], loss: 0.021730, mean_squared_error: 12.256284, mean_q: 3.822951, mean_eps: 0.440578\n",
      "  62252/1000000: episode: 916, duration: 3.739s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.662 [0.000, 3.000], mean observation: 39.692 [0.000, 142.000], loss: 0.028771, mean_squared_error: 12.059288, mean_q: 3.779321, mean_eps: 0.440029\n",
      "  62322/1000000: episode: 917, duration: 4.144s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.757 [0.000, 3.000], mean observation: 39.652 [0.000, 142.000], loss: 0.019912, mean_squared_error: 12.323238, mean_q: 3.846656, mean_eps: 0.439421\n",
      "  62411/1000000: episode: 918, duration: 5.265s, episode steps: 89, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.497 [0.000, 142.000], loss: 0.023336, mean_squared_error: 12.228887, mean_q: 3.826982, mean_eps: 0.438706\n",
      "  62478/1000000: episode: 919, duration: 3.937s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.851 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.026810, mean_squared_error: 12.475725, mean_q: 3.879793, mean_eps: 0.438004\n",
      "  62545/1000000: episode: 920, duration: 3.905s, episode steps: 67, steps per second: 17, episode reward: 7.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.731 [0.000, 3.000], mean observation: 39.630 [0.000, 142.000], loss: 0.026379, mean_squared_error: 12.117651, mean_q: 3.791129, mean_eps: 0.437401\n",
      "  62612/1000000: episode: 921, duration: 3.932s, episode steps: 67, steps per second: 17, episode reward: 7.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.955 [0.000, 3.000], mean observation: 39.590 [0.000, 142.000], loss: 0.026804, mean_squared_error: 12.235223, mean_q: 3.825890, mean_eps: 0.436798\n",
      "  62686/1000000: episode: 922, duration: 4.327s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.811 [0.000, 3.000], mean observation: 39.594 [0.000, 142.000], loss: 0.023698, mean_squared_error: 12.309340, mean_q: 3.845261, mean_eps: 0.436163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  62739/1000000: episode: 923, duration: 3.125s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.830 [0.000, 3.000], mean observation: 39.772 [0.000, 142.000], loss: 0.023801, mean_squared_error: 12.531870, mean_q: 3.884921, mean_eps: 0.435592\n",
      "  62797/1000000: episode: 924, duration: 3.386s, episode steps: 58, steps per second: 17, episode reward: 2.000, mean reward: 0.034 [0.000, 1.000], mean action: 1.897 [0.000, 3.000], mean observation: 39.825 [0.000, 142.000], loss: 0.023833, mean_squared_error: 12.462458, mean_q: 3.860937, mean_eps: 0.435093\n",
      "  62873/1000000: episode: 925, duration: 4.371s, episode steps: 76, steps per second: 17, episode reward: 5.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.724 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.026643, mean_squared_error: 12.458872, mean_q: 3.862076, mean_eps: 0.434489\n",
      "  62952/1000000: episode: 926, duration: 4.629s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.759 [0.000, 3.000], mean observation: 39.569 [0.000, 142.000], loss: 0.024299, mean_squared_error: 12.101605, mean_q: 3.794669, mean_eps: 0.433792\n",
      "  63021/1000000: episode: 927, duration: 4.045s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.536 [0.000, 3.000], mean observation: 39.651 [0.000, 142.000], loss: 0.023845, mean_squared_error: 12.304534, mean_q: 3.836249, mean_eps: 0.433126\n",
      "  63090/1000000: episode: 928, duration: 3.999s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.783 [0.000, 3.000], mean observation: 39.659 [0.000, 142.000], loss: 0.030459, mean_squared_error: 12.345115, mean_q: 3.820365, mean_eps: 0.432505\n",
      "  63156/1000000: episode: 929, duration: 3.952s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.818 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.024856, mean_squared_error: 12.475450, mean_q: 3.846582, mean_eps: 0.431897\n",
      "  63246/1000000: episode: 930, duration: 5.202s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.833 [0.000, 3.000], mean observation: 39.452 [0.000, 142.000], loss: 0.023595, mean_squared_error: 12.695105, mean_q: 3.885603, mean_eps: 0.431196\n",
      "  63308/1000000: episode: 931, duration: 3.605s, episode steps: 62, steps per second: 17, episode reward: 4.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.871 [0.000, 3.000], mean observation: 39.646 [0.000, 142.000], loss: 0.031428, mean_squared_error: 12.588431, mean_q: 3.879541, mean_eps: 0.430511\n",
      "  63401/1000000: episode: 932, duration: 5.340s, episode steps: 93, steps per second: 17, episode reward: 9.000, mean reward: 0.097 [0.000, 4.000], mean action: 1.946 [0.000, 3.000], mean observation: 39.487 [0.000, 142.000], loss: 0.022776, mean_squared_error: 12.662519, mean_q: 3.891504, mean_eps: 0.429814\n",
      "  63462/1000000: episode: 933, duration: 3.530s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.902 [0.000, 3.000], mean observation: 39.677 [0.000, 142.000], loss: 0.024670, mean_squared_error: 12.575048, mean_q: 3.869985, mean_eps: 0.429121\n",
      "  63527/1000000: episode: 934, duration: 3.796s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.800 [0.000, 3.000], mean observation: 39.638 [0.000, 142.000], loss: 0.021262, mean_squared_error: 12.769472, mean_q: 3.906606, mean_eps: 0.428554\n",
      "  63611/1000000: episode: 935, duration: 4.771s, episode steps: 84, steps per second: 18, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.738 [0.000, 3.000], mean observation: 39.485 [0.000, 142.000], loss: 0.025033, mean_squared_error: 12.558314, mean_q: 3.852103, mean_eps: 0.427883\n",
      "  63669/1000000: episode: 936, duration: 3.333s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.810 [0.000, 3.000], mean observation: 39.662 [0.000, 142.000], loss: 0.022682, mean_squared_error: 12.655003, mean_q: 3.874693, mean_eps: 0.427244\n",
      "  63753/1000000: episode: 937, duration: 4.884s, episode steps: 84, steps per second: 17, episode reward: 6.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.845 [0.000, 3.000], mean observation: 39.503 [0.000, 142.000], loss: 0.024102, mean_squared_error: 12.836898, mean_q: 3.911073, mean_eps: 0.426606\n",
      "  63828/1000000: episode: 938, duration: 4.352s, episode steps: 75, steps per second: 17, episode reward: 3.000, mean reward: 0.040 [0.000, 1.000], mean action: 1.813 [0.000, 3.000], mean observation: 39.677 [0.000, 142.000], loss: 0.025020, mean_squared_error: 12.836997, mean_q: 3.891476, mean_eps: 0.425890\n",
      "  63897/1000000: episode: 939, duration: 3.983s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.768 [0.000, 3.000], mean observation: 39.643 [0.000, 142.000], loss: 0.021263, mean_squared_error: 12.829113, mean_q: 3.902215, mean_eps: 0.425242\n",
      "  63982/1000000: episode: 940, duration: 4.850s, episode steps: 85, steps per second: 18, episode reward: 5.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.574 [0.000, 142.000], loss: 0.024230, mean_squared_error: 12.704604, mean_q: 3.889830, mean_eps: 0.424549\n",
      "  64047/1000000: episode: 941, duration: 3.744s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.846 [0.000, 3.000], mean observation: 39.614 [0.000, 142.000], loss: 0.021415, mean_squared_error: 12.835171, mean_q: 3.913494, mean_eps: 0.423874\n",
      "  64114/1000000: episode: 942, duration: 3.932s, episode steps: 67, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.731 [0.000, 3.000], mean observation: 39.784 [0.000, 142.000], loss: 0.023433, mean_squared_error: 12.871755, mean_q: 3.904296, mean_eps: 0.423280\n",
      "  64198/1000000: episode: 943, duration: 4.917s, episode steps: 84, steps per second: 17, episode reward: 8.000, mean reward: 0.095 [0.000, 4.000], mean action: 1.905 [0.000, 3.000], mean observation: 39.544 [0.000, 142.000], loss: 0.022692, mean_squared_error: 12.685012, mean_q: 3.866425, mean_eps: 0.422600\n",
      "  64276/1000000: episode: 944, duration: 4.606s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.756 [0.000, 3.000], mean observation: 39.554 [0.000, 142.000], loss: 0.023280, mean_squared_error: 12.910923, mean_q: 3.925776, mean_eps: 0.421872\n",
      "  64378/1000000: episode: 945, duration: 5.914s, episode steps: 102, steps per second: 17, episode reward: 7.000, mean reward: 0.069 [0.000, 1.000], mean action: 1.549 [0.000, 3.000], mean observation: 39.447 [0.000, 142.000], loss: 0.026837, mean_squared_error: 12.854682, mean_q: 3.914806, mean_eps: 0.421061\n",
      "  64445/1000000: episode: 946, duration: 3.869s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.851 [0.000, 3.000], mean observation: 39.635 [0.000, 142.000], loss: 0.022329, mean_squared_error: 12.869332, mean_q: 3.902949, mean_eps: 0.420301\n",
      "  64511/1000000: episode: 947, duration: 3.859s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.955 [0.000, 3.000], mean observation: 39.682 [0.000, 142.000], loss: 0.024003, mean_squared_error: 13.067321, mean_q: 3.936308, mean_eps: 0.419702\n",
      "  64580/1000000: episode: 948, duration: 4.043s, episode steps: 69, steps per second: 17, episode reward: 7.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.855 [0.000, 3.000], mean observation: 39.638 [0.000, 142.000], loss: 0.032742, mean_squared_error: 13.117920, mean_q: 3.957434, mean_eps: 0.419095\n",
      "  64651/1000000: episode: 949, duration: 4.180s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.613 [0.000, 142.000], loss: 0.031484, mean_squared_error: 13.006263, mean_q: 3.936379, mean_eps: 0.418465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  64716/1000000: episode: 950, duration: 3.850s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.938 [0.000, 3.000], mean observation: 39.619 [0.000, 142.000], loss: 0.023410, mean_squared_error: 13.106134, mean_q: 3.936756, mean_eps: 0.417853\n",
      "  64788/1000000: episode: 951, duration: 4.153s, episode steps: 72, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.694 [0.000, 3.000], mean observation: 39.626 [0.000, 142.000], loss: 0.023255, mean_squared_error: 13.219343, mean_q: 3.962187, mean_eps: 0.417237\n",
      "  64853/1000000: episode: 952, duration: 3.853s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.690 [0.000, 142.000], loss: 0.022950, mean_squared_error: 13.470035, mean_q: 4.007677, mean_eps: 0.416620\n",
      "  64947/1000000: episode: 953, duration: 5.520s, episode steps: 94, steps per second: 17, episode reward: 9.000, mean reward: 0.096 [0.000, 4.000], mean action: 2.085 [0.000, 3.000], mean observation: 39.482 [0.000, 142.000], loss: 0.029028, mean_squared_error: 12.927161, mean_q: 3.917652, mean_eps: 0.415905\n",
      "  65015/1000000: episode: 954, duration: 3.940s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.824 [0.000, 3.000], mean observation: 39.609 [0.000, 142.000], loss: 0.022224, mean_squared_error: 13.095938, mean_q: 3.957723, mean_eps: 0.415176\n",
      "  65088/1000000: episode: 955, duration: 4.268s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.651 [0.000, 142.000], loss: 0.023031, mean_squared_error: 13.132148, mean_q: 3.955734, mean_eps: 0.414541\n",
      "  65165/1000000: episode: 956, duration: 4.457s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.896 [0.000, 3.000], mean observation: 39.585 [0.000, 142.000], loss: 0.026210, mean_squared_error: 13.256102, mean_q: 3.975112, mean_eps: 0.413866\n",
      "  65246/1000000: episode: 957, duration: 4.779s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 1.728 [0.000, 3.000], mean observation: 39.517 [0.000, 142.000], loss: 0.025658, mean_squared_error: 13.631638, mean_q: 4.041163, mean_eps: 0.413155\n",
      "  65321/1000000: episode: 958, duration: 4.349s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.213 [0.000, 3.000], mean observation: 39.739 [0.000, 142.000], loss: 0.023270, mean_squared_error: 13.274093, mean_q: 3.969287, mean_eps: 0.412453\n",
      "  65428/1000000: episode: 959, duration: 6.176s, episode steps: 107, steps per second: 17, episode reward: 10.000, mean reward: 0.093 [0.000, 4.000], mean action: 1.897 [0.000, 3.000], mean observation: 39.360 [0.000, 142.000], loss: 0.023060, mean_squared_error: 13.386188, mean_q: 4.007442, mean_eps: 0.411634\n",
      "  65480/1000000: episode: 960, duration: 3.098s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.865 [0.000, 3.000], mean observation: 39.737 [0.000, 142.000], loss: 0.020574, mean_squared_error: 14.001724, mean_q: 4.095922, mean_eps: 0.410919\n",
      "  65568/1000000: episode: 961, duration: 5.059s, episode steps: 88, steps per second: 17, episode reward: 5.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.477 [0.000, 3.000], mean observation: 39.568 [0.000, 142.000], loss: 0.022096, mean_squared_error: 13.591996, mean_q: 4.043746, mean_eps: 0.410289\n",
      "  65645/1000000: episode: 962, duration: 4.427s, episode steps: 77, steps per second: 17, episode reward: 4.000, mean reward: 0.052 [0.000, 1.000], mean action: 2.078 [0.000, 3.000], mean observation: 39.663 [0.000, 142.000], loss: 0.022884, mean_squared_error: 13.342909, mean_q: 3.975935, mean_eps: 0.409546\n",
      "  65717/1000000: episode: 963, duration: 4.130s, episode steps: 72, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.833 [0.000, 3.000], mean observation: 39.662 [0.000, 142.000], loss: 0.022279, mean_squared_error: 13.408518, mean_q: 3.977227, mean_eps: 0.408875\n",
      "  65828/1000000: episode: 964, duration: 6.414s, episode steps: 111, steps per second: 17, episode reward: 11.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.802 [0.000, 3.000], mean observation: 39.298 [0.000, 142.000], loss: 0.024132, mean_squared_error: 13.688672, mean_q: 4.024526, mean_eps: 0.408052\n",
      "  65969/1000000: episode: 965, duration: 8.187s, episode steps: 141, steps per second: 17, episode reward: 17.000, mean reward: 0.121 [0.000, 4.000], mean action: 1.652 [0.000, 3.000], mean observation: 39.007 [0.000, 142.000], loss: 0.024360, mean_squared_error: 13.687511, mean_q: 4.017502, mean_eps: 0.406918\n",
      "  66040/1000000: episode: 966, duration: 4.165s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.901 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.023522, mean_squared_error: 13.256090, mean_q: 3.950775, mean_eps: 0.405964\n",
      "  66108/1000000: episode: 967, duration: 3.992s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.838 [0.000, 3.000], mean observation: 39.613 [0.000, 142.000], loss: 0.029563, mean_squared_error: 13.550900, mean_q: 4.014429, mean_eps: 0.405338\n",
      "  66185/1000000: episode: 968, duration: 4.395s, episode steps: 77, steps per second: 18, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.023839, mean_squared_error: 13.705723, mean_q: 4.043383, mean_eps: 0.404686\n",
      "  66251/1000000: episode: 969, duration: 3.823s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.955 [0.000, 3.000], mean observation: 39.667 [0.000, 142.000], loss: 0.024639, mean_squared_error: 13.667591, mean_q: 4.028963, mean_eps: 0.404043\n",
      "  66351/1000000: episode: 970, duration: 5.841s, episode steps: 100, steps per second: 17, episode reward: 10.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.850 [0.000, 3.000], mean observation: 39.394 [0.000, 142.000], loss: 0.025887, mean_squared_error: 13.607584, mean_q: 3.998478, mean_eps: 0.403295\n",
      "  66429/1000000: episode: 971, duration: 4.552s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.103 [0.000, 3.000], mean observation: 39.568 [0.000, 142.000], loss: 0.028341, mean_squared_error: 13.756510, mean_q: 4.037643, mean_eps: 0.402494\n",
      "  66514/1000000: episode: 972, duration: 4.981s, episode steps: 85, steps per second: 17, episode reward: 5.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.694 [0.000, 3.000], mean observation: 39.578 [0.000, 142.000], loss: 0.026550, mean_squared_error: 13.933068, mean_q: 4.066272, mean_eps: 0.401761\n",
      "  66586/1000000: episode: 973, duration: 4.216s, episode steps: 72, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.986 [0.000, 3.000], mean observation: 39.659 [0.000, 142.000], loss: 0.026590, mean_squared_error: 13.572808, mean_q: 4.009670, mean_eps: 0.401054\n",
      "  66655/1000000: episode: 974, duration: 4.017s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.884 [0.000, 3.000], mean observation: 39.655 [0.000, 142.000], loss: 0.023068, mean_squared_error: 14.080740, mean_q: 4.117097, mean_eps: 0.400420\n",
      "  66729/1000000: episode: 975, duration: 4.355s, episode steps: 74, steps per second: 17, episode reward: 11.000, mean reward: 0.149 [0.000, 4.000], mean action: 1.973 [0.000, 3.000], mean observation: 39.555 [0.000, 142.000], loss: 0.024137, mean_squared_error: 13.858540, mean_q: 4.068648, mean_eps: 0.399776\n",
      "  66800/1000000: episode: 976, duration: 4.157s, episode steps: 71, steps per second: 17, episode reward: 11.000, mean reward: 0.155 [0.000, 4.000], mean action: 1.972 [0.000, 3.000], mean observation: 39.557 [0.000, 142.000], loss: 0.022290, mean_squared_error: 13.709410, mean_q: 4.058472, mean_eps: 0.399124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  66876/1000000: episode: 977, duration: 4.390s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.789 [0.000, 3.000], mean observation: 39.600 [0.000, 142.000], loss: 0.025095, mean_squared_error: 13.987188, mean_q: 4.084259, mean_eps: 0.398462\n",
      "  66959/1000000: episode: 978, duration: 4.883s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.867 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.026710, mean_squared_error: 13.816541, mean_q: 4.054765, mean_eps: 0.397747\n",
      "  67050/1000000: episode: 979, duration: 5.322s, episode steps: 91, steps per second: 17, episode reward: 6.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.769 [0.000, 3.000], mean observation: 39.508 [0.000, 142.000], loss: 0.025948, mean_squared_error: 13.983990, mean_q: 4.083385, mean_eps: 0.396964\n",
      "  67120/1000000: episode: 980, duration: 4.163s, episode steps: 70, steps per second: 17, episode reward: 7.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.886 [0.000, 3.000], mean observation: 39.691 [0.000, 142.000], loss: 0.022128, mean_squared_error: 14.254319, mean_q: 4.130184, mean_eps: 0.396239\n",
      "  67182/1000000: episode: 981, duration: 3.732s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.855 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.027659, mean_squared_error: 14.109275, mean_q: 4.115594, mean_eps: 0.395646\n",
      "  67256/1000000: episode: 982, duration: 4.338s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.635 [0.000, 3.000], mean observation: 39.593 [0.000, 142.000], loss: 0.022221, mean_squared_error: 13.823574, mean_q: 4.055509, mean_eps: 0.395033\n",
      "  67331/1000000: episode: 983, duration: 4.382s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.840 [0.000, 3.000], mean observation: 39.594 [0.000, 142.000], loss: 0.025145, mean_squared_error: 13.878546, mean_q: 4.061306, mean_eps: 0.394363\n",
      "  67424/1000000: episode: 984, duration: 5.403s, episode steps: 93, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.753 [0.000, 3.000], mean observation: 39.495 [0.000, 142.000], loss: 0.022545, mean_squared_error: 14.150710, mean_q: 4.115817, mean_eps: 0.393607\n",
      "  67499/1000000: episode: 985, duration: 4.323s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.733 [0.000, 3.000], mean observation: 39.642 [0.000, 142.000], loss: 0.024048, mean_squared_error: 14.261163, mean_q: 4.116557, mean_eps: 0.392851\n",
      "  67578/1000000: episode: 986, duration: 4.628s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.899 [0.000, 3.000], mean observation: 39.556 [0.000, 142.000], loss: 0.025626, mean_squared_error: 14.193684, mean_q: 4.117335, mean_eps: 0.392158\n",
      "  67646/1000000: episode: 987, duration: 3.959s, episode steps: 68, steps per second: 17, episode reward: 7.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.971 [0.000, 3.000], mean observation: 39.662 [0.000, 142.000], loss: 0.024947, mean_squared_error: 14.231371, mean_q: 4.123277, mean_eps: 0.391496\n",
      "  67716/1000000: episode: 988, duration: 4.156s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.871 [0.000, 3.000], mean observation: 39.638 [0.000, 142.000], loss: 0.026911, mean_squared_error: 14.096201, mean_q: 4.119044, mean_eps: 0.390875\n",
      "  67764/1000000: episode: 989, duration: 2.819s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.896 [0.000, 3.000], mean observation: 39.720 [0.000, 142.000], loss: 0.023744, mean_squared_error: 14.005461, mean_q: 4.089086, mean_eps: 0.390345\n",
      "  67844/1000000: episode: 990, duration: 4.593s, episode steps: 80, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.788 [0.000, 3.000], mean observation: 39.557 [0.000, 142.000], loss: 0.024887, mean_squared_error: 13.958359, mean_q: 4.057147, mean_eps: 0.389769\n",
      "  67919/1000000: episode: 991, duration: 4.487s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.561 [0.000, 142.000], loss: 0.025091, mean_squared_error: 14.104718, mean_q: 4.101710, mean_eps: 0.389071\n",
      "  67967/1000000: episode: 992, duration: 2.786s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 2.083 [0.000, 3.000], mean observation: 39.746 [0.000, 142.000], loss: 0.024689, mean_squared_error: 14.279334, mean_q: 4.154950, mean_eps: 0.388518\n",
      "  68042/1000000: episode: 993, duration: 4.434s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.647 [0.000, 142.000], loss: 0.031250, mean_squared_error: 14.191100, mean_q: 4.112174, mean_eps: 0.387964\n",
      "  68134/1000000: episode: 994, duration: 5.252s, episode steps: 92, steps per second: 18, episode reward: 5.000, mean reward: 0.054 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.598 [0.000, 142.000], loss: 0.024059, mean_squared_error: 14.017470, mean_q: 4.104211, mean_eps: 0.387213\n",
      "  68223/1000000: episode: 995, duration: 5.206s, episode steps: 89, steps per second: 17, episode reward: 5.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.588 [0.000, 142.000], loss: 0.024777, mean_squared_error: 13.978815, mean_q: 4.070594, mean_eps: 0.386398\n",
      "  68299/1000000: episode: 996, duration: 4.434s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.618 [0.000, 3.000], mean observation: 39.611 [0.000, 142.000], loss: 0.024872, mean_squared_error: 13.827020, mean_q: 4.044662, mean_eps: 0.385655\n",
      "  68383/1000000: episode: 997, duration: 4.897s, episode steps: 84, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.548 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.025256, mean_squared_error: 14.077212, mean_q: 4.080681, mean_eps: 0.384935\n",
      "  68454/1000000: episode: 998, duration: 4.174s, episode steps: 71, steps per second: 17, episode reward: 11.000, mean reward: 0.155 [0.000, 4.000], mean action: 1.845 [0.000, 3.000], mean observation: 39.542 [0.000, 142.000], loss: 0.023412, mean_squared_error: 14.067914, mean_q: 4.077228, mean_eps: 0.384238\n",
      "  68531/1000000: episode: 999, duration: 4.463s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.740 [0.000, 3.000], mean observation: 39.625 [0.000, 142.000], loss: 0.030141, mean_squared_error: 13.972881, mean_q: 4.062093, mean_eps: 0.383572\n",
      "  68579/1000000: episode: 1000, duration: 2.769s, episode steps: 48, steps per second: 17, episode reward: 2.000, mean reward: 0.042 [0.000, 1.000], mean action: 1.729 [0.000, 3.000], mean observation: 39.837 [0.000, 142.000], loss: 0.029900, mean_squared_error: 14.099456, mean_q: 4.074114, mean_eps: 0.383010\n",
      "  68644/1000000: episode: 1001, duration: 3.814s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.938 [0.000, 3.000], mean observation: 39.616 [0.000, 142.000], loss: 0.024303, mean_squared_error: 14.688943, mean_q: 4.209342, mean_eps: 0.382501\n",
      "  68720/1000000: episode: 1002, duration: 4.388s, episode steps: 76, steps per second: 17, episode reward: 5.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.816 [0.000, 3.000], mean observation: 39.630 [0.000, 142.000], loss: 0.027175, mean_squared_error: 14.395410, mean_q: 4.146074, mean_eps: 0.381866\n",
      "  68793/1000000: episode: 1003, duration: 4.221s, episode steps: 73, steps per second: 17, episode reward: 5.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.795 [0.000, 3.000], mean observation: 39.558 [0.000, 142.000], loss: 0.030136, mean_squared_error: 14.283160, mean_q: 4.128533, mean_eps: 0.381196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  68844/1000000: episode: 1004, duration: 2.988s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.804 [0.000, 3.000], mean observation: 39.786 [0.000, 142.000], loss: 0.033597, mean_squared_error: 14.357020, mean_q: 4.117881, mean_eps: 0.380638\n",
      "  68900/1000000: episode: 1005, duration: 3.253s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.821 [0.000, 3.000], mean observation: 39.699 [0.000, 142.000], loss: 0.040028, mean_squared_error: 14.265012, mean_q: 4.111021, mean_eps: 0.380157\n",
      "  68987/1000000: episode: 1006, duration: 5.132s, episode steps: 87, steps per second: 17, episode reward: 9.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.805 [0.000, 3.000], mean observation: 39.494 [0.000, 142.000], loss: 0.029233, mean_squared_error: 14.053481, mean_q: 4.059964, mean_eps: 0.379513\n",
      "  69066/1000000: episode: 1007, duration: 4.680s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.759 [0.000, 3.000], mean observation: 39.548 [0.000, 142.000], loss: 0.025633, mean_squared_error: 14.278072, mean_q: 4.117479, mean_eps: 0.378766\n",
      "  69138/1000000: episode: 1008, duration: 4.193s, episode steps: 72, steps per second: 17, episode reward: 7.000, mean reward: 0.097 [0.000, 4.000], mean action: 1.514 [0.000, 3.000], mean observation: 39.683 [0.000, 142.000], loss: 0.027890, mean_squared_error: 14.364932, mean_q: 4.144657, mean_eps: 0.378086\n",
      "  69219/1000000: episode: 1009, duration: 4.727s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.840 [0.000, 3.000], mean observation: 39.541 [0.000, 142.000], loss: 0.027629, mean_squared_error: 14.553989, mean_q: 4.169669, mean_eps: 0.377398\n",
      "  69325/1000000: episode: 1010, duration: 6.175s, episode steps: 106, steps per second: 17, episode reward: 11.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.934 [0.000, 3.000], mean observation: 39.285 [0.000, 142.000], loss: 0.026874, mean_squared_error: 14.425564, mean_q: 4.145459, mean_eps: 0.376556\n",
      "  69404/1000000: episode: 1011, duration: 4.584s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.911 [0.000, 3.000], mean observation: 39.541 [0.000, 142.000], loss: 0.033721, mean_squared_error: 14.549785, mean_q: 4.174843, mean_eps: 0.375724\n",
      "  69474/1000000: episode: 1012, duration: 4.066s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 1.914 [0.000, 3.000], mean observation: 39.542 [0.000, 142.000], loss: 0.030794, mean_squared_error: 14.560222, mean_q: 4.187891, mean_eps: 0.375053\n",
      "  69607/1000000: episode: 1013, duration: 7.603s, episode steps: 133, steps per second: 17, episode reward: 13.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.662 [0.000, 3.000], mean observation: 39.409 [0.000, 142.000], loss: 0.027032, mean_squared_error: 14.449263, mean_q: 4.146177, mean_eps: 0.374140\n",
      "  69676/1000000: episode: 1014, duration: 4.018s, episode steps: 69, steps per second: 17, episode reward: 11.000, mean reward: 0.159 [0.000, 4.000], mean action: 1.899 [0.000, 3.000], mean observation: 39.543 [0.000, 142.000], loss: 0.023977, mean_squared_error: 14.777725, mean_q: 4.198376, mean_eps: 0.373231\n",
      "  69758/1000000: episode: 1015, duration: 4.722s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.817 [0.000, 3.000], mean observation: 39.556 [0.000, 142.000], loss: 0.029166, mean_squared_error: 14.630145, mean_q: 4.180614, mean_eps: 0.372551\n",
      "  69855/1000000: episode: 1016, duration: 5.628s, episode steps: 97, steps per second: 17, episode reward: 6.000, mean reward: 0.062 [0.000, 1.000], mean action: 2.010 [0.000, 3.000], mean observation: 39.481 [0.000, 142.000], loss: 0.024956, mean_squared_error: 14.464028, mean_q: 4.139579, mean_eps: 0.371746\n",
      "  69929/1000000: episode: 1017, duration: 4.316s, episode steps: 74, steps per second: 17, episode reward: 5.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.784 [0.000, 3.000], mean observation: 39.536 [0.000, 142.000], loss: 0.022400, mean_squared_error: 14.690992, mean_q: 4.177181, mean_eps: 0.370976\n",
      "  70009/1000000: episode: 1018, duration: 4.626s, episode steps: 80, steps per second: 17, episode reward: 8.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.850 [0.000, 3.000], mean observation: 39.547 [0.000, 142.000], loss: 0.024703, mean_squared_error: 14.639749, mean_q: 4.187325, mean_eps: 0.370283\n",
      "  70075/1000000: episode: 1019, duration: 3.874s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.909 [0.000, 3.000], mean observation: 39.658 [0.000, 142.000], loss: 0.031323, mean_squared_error: 14.619450, mean_q: 4.174939, mean_eps: 0.369626\n",
      "  70148/1000000: episode: 1020, duration: 4.258s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.849 [0.000, 3.000], mean observation: 39.647 [0.000, 142.000], loss: 0.026764, mean_squared_error: 14.826024, mean_q: 4.197055, mean_eps: 0.369001\n",
      "  70223/1000000: episode: 1021, duration: 4.404s, episode steps: 75, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.024601, mean_squared_error: 14.949225, mean_q: 4.227246, mean_eps: 0.368335\n",
      "  70295/1000000: episode: 1022, duration: 4.249s, episode steps: 72, steps per second: 17, episode reward: 8.000, mean reward: 0.111 [0.000, 4.000], mean action: 2.028 [0.000, 3.000], mean observation: 39.541 [0.000, 142.000], loss: 0.023612, mean_squared_error: 14.784422, mean_q: 4.209722, mean_eps: 0.367673\n",
      "  70361/1000000: episode: 1023, duration: 3.843s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.985 [0.000, 3.000], mean observation: 39.595 [0.000, 142.000], loss: 0.031571, mean_squared_error: 14.920392, mean_q: 4.225544, mean_eps: 0.367053\n",
      "  70437/1000000: episode: 1024, duration: 4.349s, episode steps: 76, steps per second: 17, episode reward: 5.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.711 [0.000, 3.000], mean observation: 39.530 [0.000, 142.000], loss: 0.031813, mean_squared_error: 15.199762, mean_q: 4.270753, mean_eps: 0.366414\n",
      "  70511/1000000: episode: 1025, duration: 4.286s, episode steps: 74, steps per second: 17, episode reward: 4.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.459 [0.000, 3.000], mean observation: 39.612 [0.000, 142.000], loss: 0.029783, mean_squared_error: 15.140650, mean_q: 4.256178, mean_eps: 0.365738\n",
      "  70572/1000000: episode: 1026, duration: 3.600s, episode steps: 61, steps per second: 17, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.607 [0.000, 3.000], mean observation: 39.687 [0.000, 142.000], loss: 0.022999, mean_squared_error: 15.226813, mean_q: 4.268421, mean_eps: 0.365131\n",
      "  70615/1000000: episode: 1027, duration: 2.487s, episode steps: 43, steps per second: 17, episode reward: 1.000, mean reward: 0.023 [0.000, 1.000], mean action: 1.744 [0.000, 3.000], mean observation: 39.842 [0.000, 142.000], loss: 0.024262, mean_squared_error: 14.424632, mean_q: 4.139043, mean_eps: 0.364663\n",
      "  70678/1000000: episode: 1028, duration: 3.662s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.540 [0.000, 3.000], mean observation: 39.779 [0.000, 142.000], loss: 0.023581, mean_squared_error: 15.225868, mean_q: 4.273098, mean_eps: 0.364186\n",
      "  70744/1000000: episode: 1029, duration: 3.811s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.879 [0.000, 3.000], mean observation: 39.589 [0.000, 142.000], loss: 0.027556, mean_squared_error: 14.749194, mean_q: 4.169743, mean_eps: 0.363606\n",
      "  70839/1000000: episode: 1030, duration: 5.578s, episode steps: 95, steps per second: 17, episode reward: 6.000, mean reward: 0.063 [0.000, 1.000], mean action: 2.021 [0.000, 3.000], mean observation: 39.465 [0.000, 142.000], loss: 0.025419, mean_squared_error: 15.202826, mean_q: 4.265512, mean_eps: 0.362881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  70924/1000000: episode: 1031, duration: 4.945s, episode steps: 85, steps per second: 17, episode reward: 5.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.906 [0.000, 3.000], mean observation: 39.557 [0.000, 142.000], loss: 0.024104, mean_squared_error: 15.231049, mean_q: 4.259349, mean_eps: 0.362071\n",
      "  71028/1000000: episode: 1032, duration: 6.023s, episode steps: 104, steps per second: 17, episode reward: 7.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.625 [0.000, 3.000], mean observation: 39.448 [0.000, 142.000], loss: 0.028091, mean_squared_error: 15.415435, mean_q: 4.298744, mean_eps: 0.361220\n",
      "  71092/1000000: episode: 1033, duration: 3.782s, episode steps: 64, steps per second: 17, episode reward: 3.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.766 [0.000, 3.000], mean observation: 39.679 [0.000, 142.000], loss: 0.023392, mean_squared_error: 15.076527, mean_q: 4.247051, mean_eps: 0.360464\n",
      "  71145/1000000: episode: 1034, duration: 3.048s, episode steps: 53, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.962 [0.000, 3.000], mean observation: 39.815 [0.000, 142.000], loss: 0.021888, mean_squared_error: 14.853144, mean_q: 4.181265, mean_eps: 0.359938\n",
      "  71244/1000000: episode: 1035, duration: 5.835s, episode steps: 99, steps per second: 17, episode reward: 6.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.818 [0.000, 3.000], mean observation: 39.492 [0.000, 142.000], loss: 0.025599, mean_squared_error: 15.213275, mean_q: 4.252743, mean_eps: 0.359254\n",
      "  71311/1000000: episode: 1036, duration: 3.896s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.642 [0.000, 3.000], mean observation: 39.607 [0.000, 142.000], loss: 0.031067, mean_squared_error: 14.904430, mean_q: 4.215642, mean_eps: 0.358507\n",
      "  71401/1000000: episode: 1037, duration: 5.237s, episode steps: 90, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.778 [0.000, 3.000], mean observation: 39.497 [0.000, 142.000], loss: 0.023669, mean_squared_error: 15.131305, mean_q: 4.245335, mean_eps: 0.357800\n",
      "  71492/1000000: episode: 1038, duration: 5.314s, episode steps: 91, steps per second: 17, episode reward: 9.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.615 [0.000, 3.000], mean observation: 39.505 [0.000, 142.000], loss: 0.024836, mean_squared_error: 15.472396, mean_q: 4.321085, mean_eps: 0.356986\n",
      "  71575/1000000: episode: 1039, duration: 4.754s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.819 [0.000, 3.000], mean observation: 39.509 [0.000, 142.000], loss: 0.025863, mean_squared_error: 15.517823, mean_q: 4.300514, mean_eps: 0.356203\n",
      "  71668/1000000: episode: 1040, duration: 5.419s, episode steps: 93, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.957 [0.000, 3.000], mean observation: 39.462 [0.000, 142.000], loss: 0.024674, mean_squared_error: 15.824571, mean_q: 4.361467, mean_eps: 0.355411\n",
      "  71728/1000000: episode: 1041, duration: 3.474s, episode steps: 60, steps per second: 17, episode reward: 3.000, mean reward: 0.050 [0.000, 1.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.693 [0.000, 142.000], loss: 0.024351, mean_squared_error: 15.387430, mean_q: 4.304159, mean_eps: 0.354722\n",
      "  71805/1000000: episode: 1042, duration: 4.439s, episode steps: 77, steps per second: 17, episode reward: 4.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.662 [0.000, 3.000], mean observation: 39.593 [0.000, 142.000], loss: 0.024864, mean_squared_error: 15.306885, mean_q: 4.274731, mean_eps: 0.354106\n",
      "  71955/1000000: episode: 1043, duration: 8.629s, episode steps: 150, steps per second: 17, episode reward: 7.000, mean reward: 0.047 [0.000, 1.000], mean action: 2.040 [0.000, 3.000], mean observation: 39.312 [0.000, 142.000], loss: 0.025065, mean_squared_error: 15.770926, mean_q: 4.369619, mean_eps: 0.353085\n",
      "  72006/1000000: episode: 1044, duration: 3.063s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.961 [0.000, 3.000], mean observation: 39.732 [0.000, 142.000], loss: 0.026597, mean_squared_error: 15.459777, mean_q: 4.289770, mean_eps: 0.352180\n",
      "  72115/1000000: episode: 1045, duration: 6.278s, episode steps: 109, steps per second: 17, episode reward: 11.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.725 [0.000, 3.000], mean observation: 39.305 [0.000, 142.000], loss: 0.028085, mean_squared_error: 15.824423, mean_q: 4.366949, mean_eps: 0.351460\n",
      "  72197/1000000: episode: 1046, duration: 4.853s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.793 [0.000, 3.000], mean observation: 39.527 [0.000, 142.000], loss: 0.026927, mean_squared_error: 15.961896, mean_q: 4.386018, mean_eps: 0.350600\n",
      "  72304/1000000: episode: 1047, duration: 6.236s, episode steps: 107, steps per second: 17, episode reward: 14.000, mean reward: 0.131 [0.000, 4.000], mean action: 2.150 [0.000, 3.000], mean observation: 39.317 [0.000, 142.000], loss: 0.026717, mean_squared_error: 15.651373, mean_q: 4.323461, mean_eps: 0.349750\n",
      "  72363/1000000: episode: 1048, duration: 3.427s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 2.017 [0.000, 3.000], mean observation: 39.656 [0.000, 142.000], loss: 0.027332, mean_squared_error: 15.679473, mean_q: 4.325698, mean_eps: 0.349003\n",
      "  72436/1000000: episode: 1049, duration: 4.281s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.849 [0.000, 3.000], mean observation: 39.620 [0.000, 142.000], loss: 0.025546, mean_squared_error: 16.048705, mean_q: 4.402745, mean_eps: 0.348409\n",
      "  72506/1000000: episode: 1050, duration: 4.107s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 1.571 [0.000, 3.000], mean observation: 39.550 [0.000, 142.000], loss: 0.024483, mean_squared_error: 15.937045, mean_q: 4.393058, mean_eps: 0.347766\n",
      "  72593/1000000: episode: 1051, duration: 5.099s, episode steps: 87, steps per second: 17, episode reward: 9.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.454 [0.000, 142.000], loss: 0.029293, mean_squared_error: 15.753567, mean_q: 4.340542, mean_eps: 0.347059\n",
      "  72682/1000000: episode: 1052, duration: 5.201s, episode steps: 89, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.719 [0.000, 3.000], mean observation: 39.544 [0.000, 142.000], loss: 0.026107, mean_squared_error: 15.589325, mean_q: 4.298372, mean_eps: 0.346267\n",
      "  72800/1000000: episode: 1053, duration: 6.737s, episode steps: 118, steps per second: 18, episode reward: 9.000, mean reward: 0.076 [0.000, 1.000], mean action: 1.966 [0.000, 3.000], mean observation: 39.310 [0.000, 142.000], loss: 0.023550, mean_squared_error: 15.777481, mean_q: 4.341307, mean_eps: 0.345335\n",
      "  72859/1000000: episode: 1054, duration: 3.426s, episode steps: 59, steps per second: 17, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.699 [0.000, 142.000], loss: 0.028928, mean_squared_error: 16.394879, mean_q: 4.450771, mean_eps: 0.344539\n",
      "  72923/1000000: episode: 1055, duration: 3.776s, episode steps: 64, steps per second: 17, episode reward: 7.000, mean reward: 0.109 [0.000, 4.000], mean action: 2.031 [0.000, 3.000], mean observation: 39.667 [0.000, 142.000], loss: 0.026489, mean_squared_error: 15.775354, mean_q: 4.341248, mean_eps: 0.343985\n",
      "  73013/1000000: episode: 1056, duration: 5.210s, episode steps: 90, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.656 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.029105, mean_squared_error: 15.607517, mean_q: 4.322577, mean_eps: 0.343293\n",
      "  73109/1000000: episode: 1057, duration: 5.530s, episode steps: 96, steps per second: 17, episode reward: 7.000, mean reward: 0.073 [0.000, 1.000], mean action: 1.948 [0.000, 3.000], mean observation: 39.393 [0.000, 142.000], loss: 0.028752, mean_squared_error: 15.832864, mean_q: 4.354404, mean_eps: 0.342456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  73161/1000000: episode: 1058, duration: 3.044s, episode steps: 52, steps per second: 17, episode reward: 2.000, mean reward: 0.038 [0.000, 1.000], mean action: 1.885 [0.000, 3.000], mean observation: 39.713 [0.000, 142.000], loss: 0.028165, mean_squared_error: 15.394287, mean_q: 4.282257, mean_eps: 0.341789\n",
      "  73240/1000000: episode: 1059, duration: 4.662s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.810 [0.000, 3.000], mean observation: 39.605 [0.000, 142.000], loss: 0.028231, mean_squared_error: 16.117578, mean_q: 4.393546, mean_eps: 0.341200\n",
      "  73324/1000000: episode: 1060, duration: 4.903s, episode steps: 84, steps per second: 17, episode reward: 4.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.869 [0.000, 3.000], mean observation: 39.611 [0.000, 142.000], loss: 0.025696, mean_squared_error: 15.895642, mean_q: 4.349559, mean_eps: 0.340467\n",
      "  73412/1000000: episode: 1061, duration: 5.086s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.795 [0.000, 3.000], mean observation: 39.493 [0.000, 142.000], loss: 0.026496, mean_squared_error: 15.935001, mean_q: 4.375050, mean_eps: 0.339693\n",
      "  73531/1000000: episode: 1062, duration: 6.926s, episode steps: 119, steps per second: 17, episode reward: 9.000, mean reward: 0.076 [0.000, 1.000], mean action: 1.966 [0.000, 3.000], mean observation: 39.235 [0.000, 142.000], loss: 0.023293, mean_squared_error: 15.986029, mean_q: 4.378300, mean_eps: 0.338761\n",
      "  73597/1000000: episode: 1063, duration: 3.865s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.879 [0.000, 3.000], mean observation: 39.680 [0.000, 142.000], loss: 0.022575, mean_squared_error: 16.423678, mean_q: 4.447561, mean_eps: 0.337928\n",
      "  73690/1000000: episode: 1064, duration: 5.411s, episode steps: 93, steps per second: 17, episode reward: 9.000, mean reward: 0.097 [0.000, 4.000], mean action: 1.828 [0.000, 3.000], mean observation: 39.469 [0.000, 142.000], loss: 0.025762, mean_squared_error: 16.217940, mean_q: 4.402308, mean_eps: 0.337213\n",
      "  73808/1000000: episode: 1065, duration: 6.834s, episode steps: 118, steps per second: 17, episode reward: 12.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.017 [0.000, 3.000], mean observation: 39.251 [0.000, 142.000], loss: 0.024622, mean_squared_error: 15.828608, mean_q: 4.339839, mean_eps: 0.336263\n",
      "  73881/1000000: episode: 1066, duration: 4.270s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.945 [0.000, 3.000], mean observation: 39.652 [0.000, 142.000], loss: 0.025401, mean_squared_error: 16.031739, mean_q: 4.387577, mean_eps: 0.335404\n",
      "  73957/1000000: episode: 1067, duration: 4.378s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.816 [0.000, 3.000], mean observation: 39.578 [0.000, 142.000], loss: 0.025879, mean_squared_error: 16.047976, mean_q: 4.374033, mean_eps: 0.334734\n",
      "  74022/1000000: episode: 1068, duration: 3.801s, episode steps: 65, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.681 [0.000, 142.000], loss: 0.027176, mean_squared_error: 16.082040, mean_q: 4.369731, mean_eps: 0.334099\n",
      "  74104/1000000: episode: 1069, duration: 4.714s, episode steps: 82, steps per second: 17, episode reward: 8.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.756 [0.000, 3.000], mean observation: 39.593 [0.000, 142.000], loss: 0.024236, mean_squared_error: 16.265394, mean_q: 4.422120, mean_eps: 0.333437\n",
      "  74174/1000000: episode: 1070, duration: 3.930s, episode steps: 70, steps per second: 18, episode reward: 7.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.957 [0.000, 3.000], mean observation: 39.665 [0.000, 142.000], loss: 0.027978, mean_squared_error: 16.372712, mean_q: 4.430154, mean_eps: 0.332753\n",
      "  74250/1000000: episode: 1071, duration: 4.488s, episode steps: 76, steps per second: 17, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.816 [0.000, 3.000], mean observation: 39.646 [0.000, 142.000], loss: 0.026690, mean_squared_error: 16.358039, mean_q: 4.420080, mean_eps: 0.332097\n",
      "  74331/1000000: episode: 1072, duration: 4.709s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 1.630 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.023691, mean_squared_error: 16.169645, mean_q: 4.390438, mean_eps: 0.331390\n",
      "  74421/1000000: episode: 1073, duration: 5.202s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.856 [0.000, 3.000], mean observation: 39.531 [0.000, 142.000], loss: 0.025648, mean_squared_error: 16.309963, mean_q: 4.417318, mean_eps: 0.330620\n",
      "  74487/1000000: episode: 1074, duration: 3.775s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.603 [0.000, 142.000], loss: 0.037476, mean_squared_error: 16.151430, mean_q: 4.383513, mean_eps: 0.329919\n",
      "  74534/1000000: episode: 1075, duration: 2.771s, episode steps: 47, steps per second: 17, episode reward: 2.000, mean reward: 0.043 [0.000, 1.000], mean action: 1.745 [0.000, 3.000], mean observation: 39.713 [0.000, 142.000], loss: 0.022388, mean_squared_error: 16.436389, mean_q: 4.428857, mean_eps: 0.329410\n",
      "  74628/1000000: episode: 1076, duration: 5.440s, episode steps: 94, steps per second: 17, episode reward: 6.000, mean reward: 0.064 [0.000, 1.000], mean action: 1.862 [0.000, 3.000], mean observation: 39.484 [0.000, 142.000], loss: 0.028631, mean_squared_error: 16.182738, mean_q: 4.388736, mean_eps: 0.328775\n",
      "  74707/1000000: episode: 1077, duration: 4.656s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 2.038 [0.000, 3.000], mean observation: 39.628 [0.000, 142.000], loss: 0.023620, mean_squared_error: 16.360238, mean_q: 4.407670, mean_eps: 0.327997\n",
      "  74775/1000000: episode: 1078, duration: 3.907s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.838 [0.000, 3.000], mean observation: 39.661 [0.000, 142.000], loss: 0.025527, mean_squared_error: 16.475322, mean_q: 4.439223, mean_eps: 0.327335\n",
      "  74856/1000000: episode: 1079, duration: 4.727s, episode steps: 81, steps per second: 17, episode reward: 4.000, mean reward: 0.049 [0.000, 1.000], mean action: 2.062 [0.000, 3.000], mean observation: 39.589 [0.000, 142.000], loss: 0.026427, mean_squared_error: 16.167740, mean_q: 4.402825, mean_eps: 0.326665\n",
      "  74945/1000000: episode: 1080, duration: 5.124s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.910 [0.000, 3.000], mean observation: 39.525 [0.000, 142.000], loss: 0.025770, mean_squared_error: 16.319556, mean_q: 4.422599, mean_eps: 0.325900\n",
      "  75031/1000000: episode: 1081, duration: 5.096s, episode steps: 86, steps per second: 17, episode reward: 8.000, mean reward: 0.093 [0.000, 4.000], mean action: 1.686 [0.000, 3.000], mean observation: 39.568 [0.000, 142.000], loss: 0.028050, mean_squared_error: 15.999381, mean_q: 4.359909, mean_eps: 0.325112\n",
      "  75086/1000000: episode: 1082, duration: 3.263s, episode steps: 55, steps per second: 17, episode reward: 2.000, mean reward: 0.036 [0.000, 1.000], mean action: 1.927 [0.000, 3.000], mean observation: 39.719 [0.000, 142.000], loss: 0.026460, mean_squared_error: 16.260264, mean_q: 4.389282, mean_eps: 0.324478\n",
      "  75161/1000000: episode: 1083, duration: 4.365s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.853 [0.000, 3.000], mean observation: 39.575 [0.000, 142.000], loss: 0.027506, mean_squared_error: 16.128301, mean_q: 4.382846, mean_eps: 0.323893\n",
      "  75237/1000000: episode: 1084, duration: 4.476s, episode steps: 76, steps per second: 17, episode reward: 5.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.671 [0.000, 3.000], mean observation: 39.609 [0.000, 142.000], loss: 0.024166, mean_squared_error: 16.958123, mean_q: 4.510457, mean_eps: 0.323214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  75318/1000000: episode: 1085, duration: 4.734s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.654 [0.000, 3.000], mean observation: 39.552 [0.000, 142.000], loss: 0.026797, mean_squared_error: 16.087572, mean_q: 4.386104, mean_eps: 0.322507\n",
      "  75400/1000000: episode: 1086, duration: 4.798s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.695 [0.000, 3.000], mean observation: 39.539 [0.000, 142.000], loss: 0.024629, mean_squared_error: 16.369939, mean_q: 4.427107, mean_eps: 0.321773\n",
      "  75485/1000000: episode: 1087, duration: 4.942s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.988 [0.000, 3.000], mean observation: 39.505 [0.000, 142.000], loss: 0.024528, mean_squared_error: 16.314042, mean_q: 4.422578, mean_eps: 0.321022\n",
      "  75558/1000000: episode: 1088, duration: 4.220s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.904 [0.000, 3.000], mean observation: 39.591 [0.000, 142.000], loss: 0.024714, mean_squared_error: 16.091707, mean_q: 4.384857, mean_eps: 0.320311\n",
      "  75638/1000000: episode: 1089, duration: 4.609s, episode steps: 80, steps per second: 17, episode reward: 8.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.725 [0.000, 3.000], mean observation: 39.575 [0.000, 142.000], loss: 0.025015, mean_squared_error: 16.341760, mean_q: 4.415278, mean_eps: 0.319622\n",
      "  75742/1000000: episode: 1090, duration: 5.803s, episode steps: 104, steps per second: 18, episode reward: 6.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.683 [0.000, 3.000], mean observation: 39.432 [0.000, 142.000], loss: 0.026347, mean_squared_error: 16.133331, mean_q: 4.376814, mean_eps: 0.318794\n",
      "  75840/1000000: episode: 1091, duration: 5.743s, episode steps: 98, steps per second: 17, episode reward: 13.000, mean reward: 0.133 [0.000, 4.000], mean action: 1.837 [0.000, 3.000], mean observation: 39.428 [0.000, 142.000], loss: 0.023177, mean_squared_error: 16.518527, mean_q: 4.420670, mean_eps: 0.317885\n",
      "  75941/1000000: episode: 1092, duration: 5.791s, episode steps: 101, steps per second: 17, episode reward: 12.000, mean reward: 0.119 [0.000, 4.000], mean action: 1.960 [0.000, 3.000], mean observation: 39.523 [0.000, 142.000], loss: 0.026925, mean_squared_error: 16.304563, mean_q: 4.399953, mean_eps: 0.316990\n",
      "  76020/1000000: episode: 1093, duration: 4.626s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.785 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.022718, mean_squared_error: 16.471531, mean_q: 4.431445, mean_eps: 0.316180\n",
      "  76127/1000000: episode: 1094, duration: 6.205s, episode steps: 107, steps per second: 17, episode reward: 8.000, mean reward: 0.075 [0.000, 1.000], mean action: 2.019 [0.000, 3.000], mean observation: 39.358 [0.000, 142.000], loss: 0.027113, mean_squared_error: 16.371623, mean_q: 4.400225, mean_eps: 0.315343\n",
      "  76212/1000000: episode: 1095, duration: 4.925s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.871 [0.000, 3.000], mean observation: 39.491 [0.000, 142.000], loss: 0.025786, mean_squared_error: 16.586958, mean_q: 4.449712, mean_eps: 0.314479\n",
      "  76278/1000000: episode: 1096, duration: 3.812s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.848 [0.000, 3.000], mean observation: 39.601 [0.000, 142.000], loss: 0.026135, mean_squared_error: 16.215516, mean_q: 4.392226, mean_eps: 0.313800\n",
      "  76354/1000000: episode: 1097, duration: 4.424s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.776 [0.000, 3.000], mean observation: 39.535 [0.000, 142.000], loss: 0.025493, mean_squared_error: 16.271908, mean_q: 4.380771, mean_eps: 0.313161\n",
      "  76455/1000000: episode: 1098, duration: 5.913s, episode steps: 101, steps per second: 17, episode reward: 6.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.941 [0.000, 3.000], mean observation: 39.469 [0.000, 142.000], loss: 0.026781, mean_squared_error: 16.344890, mean_q: 4.413384, mean_eps: 0.312364\n",
      "  76544/1000000: episode: 1099, duration: 5.077s, episode steps: 89, steps per second: 18, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.955 [0.000, 3.000], mean observation: 39.468 [0.000, 142.000], loss: 0.026088, mean_squared_error: 16.424401, mean_q: 4.424807, mean_eps: 0.311509\n",
      "  76598/1000000: episode: 1100, duration: 3.030s, episode steps: 54, steps per second: 18, episode reward: 2.000, mean reward: 0.037 [0.000, 1.000], mean action: 1.889 [0.000, 3.000], mean observation: 39.846 [0.000, 142.000], loss: 0.021666, mean_squared_error: 16.273233, mean_q: 4.418703, mean_eps: 0.310865\n",
      "  76683/1000000: episode: 1101, duration: 4.944s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.694 [0.000, 3.000], mean observation: 39.496 [0.000, 142.000], loss: 0.024640, mean_squared_error: 16.593582, mean_q: 4.447761, mean_eps: 0.310240\n",
      "  76789/1000000: episode: 1102, duration: 6.106s, episode steps: 106, steps per second: 17, episode reward: 7.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.717 [0.000, 3.000], mean observation: 39.484 [0.000, 142.000], loss: 0.026191, mean_squared_error: 16.476514, mean_q: 4.422626, mean_eps: 0.309381\n",
      "  76920/1000000: episode: 1103, duration: 7.795s, episode steps: 131, steps per second: 17, episode reward: 11.000, mean reward: 0.084 [0.000, 4.000], mean action: 1.794 [0.000, 3.000], mean observation: 39.187 [0.000, 142.000], loss: 0.025088, mean_squared_error: 16.867902, mean_q: 4.498985, mean_eps: 0.308314\n",
      "  76977/1000000: episode: 1104, duration: 3.355s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.070 [0.000, 3.000], mean observation: 39.684 [0.000, 142.000], loss: 0.024723, mean_squared_error: 17.080951, mean_q: 4.531093, mean_eps: 0.307468\n",
      "  77066/1000000: episode: 1105, duration: 5.174s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 2.045 [0.000, 3.000], mean observation: 39.490 [0.000, 142.000], loss: 0.030561, mean_squared_error: 16.808389, mean_q: 4.489832, mean_eps: 0.306811\n",
      "  77132/1000000: episode: 1106, duration: 3.838s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.894 [0.000, 3.000], mean observation: 39.626 [0.000, 142.000], loss: 0.024425, mean_squared_error: 16.492458, mean_q: 4.429632, mean_eps: 0.306113\n",
      "  77198/1000000: episode: 1107, duration: 3.896s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.620 [0.000, 142.000], loss: 0.029703, mean_squared_error: 16.678100, mean_q: 4.472164, mean_eps: 0.305519\n",
      "  77286/1000000: episode: 1108, duration: 5.176s, episode steps: 88, steps per second: 17, episode reward: 12.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.989 [0.000, 3.000], mean observation: 39.512 [0.000, 142.000], loss: 0.024342, mean_squared_error: 16.913878, mean_q: 4.507592, mean_eps: 0.304826\n",
      "  77352/1000000: episode: 1109, duration: 3.829s, episode steps: 66, steps per second: 17, episode reward: 4.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.727 [0.000, 3.000], mean observation: 39.630 [0.000, 142.000], loss: 0.026751, mean_squared_error: 16.558023, mean_q: 4.449902, mean_eps: 0.304133\n",
      "  77427/1000000: episode: 1110, duration: 4.251s, episode steps: 75, steps per second: 18, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.440 [0.000, 3.000], mean observation: 39.572 [0.000, 142.000], loss: 0.028092, mean_squared_error: 16.757968, mean_q: 4.463271, mean_eps: 0.303499\n",
      "  77493/1000000: episode: 1111, duration: 3.798s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.818 [0.000, 3.000], mean observation: 39.623 [0.000, 142.000], loss: 0.024202, mean_squared_error: 16.547566, mean_q: 4.464715, mean_eps: 0.302865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  77556/1000000: episode: 1112, duration: 3.609s, episode steps: 63, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 2.032 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.026973, mean_squared_error: 16.783372, mean_q: 4.483533, mean_eps: 0.302284\n",
      "  77644/1000000: episode: 1113, duration: 5.215s, episode steps: 88, steps per second: 17, episode reward: 6.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.909 [0.000, 3.000], mean observation: 39.516 [0.000, 142.000], loss: 0.027890, mean_squared_error: 17.053667, mean_q: 4.530454, mean_eps: 0.301604\n",
      "  77723/1000000: episode: 1114, duration: 4.672s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.975 [0.000, 3.000], mean observation: 39.562 [0.000, 142.000], loss: 0.027140, mean_squared_error: 16.414195, mean_q: 4.378492, mean_eps: 0.300853\n",
      "  77784/1000000: episode: 1115, duration: 3.429s, episode steps: 61, steps per second: 18, episode reward: 3.000, mean reward: 0.049 [0.000, 1.000], mean action: 1.770 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.024887, mean_squared_error: 16.535441, mean_q: 4.438215, mean_eps: 0.300223\n",
      "  77858/1000000: episode: 1116, duration: 4.273s, episode steps: 74, steps per second: 17, episode reward: 8.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.959 [0.000, 3.000], mean observation: 39.558 [0.000, 142.000], loss: 0.028807, mean_squared_error: 16.886817, mean_q: 4.510443, mean_eps: 0.299615\n",
      "  77947/1000000: episode: 1117, duration: 5.200s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.753 [0.000, 3.000], mean observation: 39.511 [0.000, 142.000], loss: 0.023643, mean_squared_error: 16.785308, mean_q: 4.477256, mean_eps: 0.298882\n",
      "  78010/1000000: episode: 1118, duration: 3.694s, episode steps: 63, steps per second: 17, episode reward: 4.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.952 [0.000, 3.000], mean observation: 39.605 [0.000, 142.000], loss: 0.027232, mean_squared_error: 16.561858, mean_q: 4.437387, mean_eps: 0.298198\n",
      "  78067/1000000: episode: 1119, duration: 3.361s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 1.895 [0.000, 3.000], mean observation: 39.696 [0.000, 142.000], loss: 0.023905, mean_squared_error: 17.045864, mean_q: 4.538451, mean_eps: 0.297658\n",
      "  78147/1000000: episode: 1120, duration: 4.725s, episode steps: 80, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.475 [0.000, 3.000], mean observation: 39.573 [0.000, 142.000], loss: 0.026303, mean_squared_error: 17.272025, mean_q: 4.531739, mean_eps: 0.297042\n",
      "  78236/1000000: episode: 1121, duration: 5.260s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 2.124 [0.000, 3.000], mean observation: 39.470 [0.000, 142.000], loss: 0.024529, mean_squared_error: 17.243706, mean_q: 4.544810, mean_eps: 0.296281\n",
      "  78315/1000000: episode: 1122, duration: 4.610s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 2.038 [0.000, 3.000], mean observation: 39.529 [0.000, 142.000], loss: 0.025208, mean_squared_error: 17.327977, mean_q: 4.573375, mean_eps: 0.295525\n",
      "  78366/1000000: episode: 1123, duration: 2.951s, episode steps: 51, steps per second: 17, episode reward: 2.000, mean reward: 0.039 [0.000, 1.000], mean action: 1.745 [0.000, 3.000], mean observation: 39.700 [0.000, 142.000], loss: 0.031035, mean_squared_error: 17.229158, mean_q: 4.536678, mean_eps: 0.294940\n",
      "  78538/1000000: episode: 1124, duration: 10.096s, episode steps: 172, steps per second: 17, episode reward: 8.000, mean reward: 0.047 [0.000, 1.000], mean action: 1.971 [0.000, 3.000], mean observation: 39.203 [0.000, 142.000], loss: 0.024266, mean_squared_error: 17.031171, mean_q: 4.509368, mean_eps: 0.293936\n",
      "  78648/1000000: episode: 1125, duration: 6.378s, episode steps: 110, steps per second: 17, episode reward: 10.000, mean reward: 0.091 [0.000, 4.000], mean action: 1.918 [0.000, 3.000], mean observation: 39.396 [0.000, 142.000], loss: 0.025441, mean_squared_error: 17.161205, mean_q: 4.525833, mean_eps: 0.292667\n",
      "  78758/1000000: episode: 1126, duration: 6.348s, episode steps: 110, steps per second: 17, episode reward: 10.000, mean reward: 0.091 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.400 [0.000, 142.000], loss: 0.025394, mean_squared_error: 17.209505, mean_q: 4.540126, mean_eps: 0.291677\n",
      "  78816/1000000: episode: 1127, duration: 3.387s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.776 [0.000, 3.000], mean observation: 39.692 [0.000, 142.000], loss: 0.024206, mean_squared_error: 17.302373, mean_q: 4.553978, mean_eps: 0.290921\n",
      "  78892/1000000: episode: 1128, duration: 4.426s, episode steps: 76, steps per second: 17, episode reward: 5.000, mean reward: 0.066 [0.000, 1.000], mean action: 1.789 [0.000, 3.000], mean observation: 39.578 [0.000, 142.000], loss: 0.026300, mean_squared_error: 17.230921, mean_q: 4.530454, mean_eps: 0.290319\n",
      "  78964/1000000: episode: 1129, duration: 4.258s, episode steps: 72, steps per second: 17, episode reward: 8.000, mean reward: 0.111 [0.000, 4.000], mean action: 1.931 [0.000, 3.000], mean observation: 39.567 [0.000, 142.000], loss: 0.025441, mean_squared_error: 17.199418, mean_q: 4.523794, mean_eps: 0.289653\n",
      "  79029/1000000: episode: 1130, duration: 3.895s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 1.846 [0.000, 3.000], mean observation: 39.686 [0.000, 142.000], loss: 0.024156, mean_squared_error: 17.276566, mean_q: 4.547391, mean_eps: 0.289036\n",
      "  79106/1000000: episode: 1131, duration: 4.434s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.701 [0.000, 3.000], mean observation: 39.564 [0.000, 142.000], loss: 0.024903, mean_squared_error: 17.016137, mean_q: 4.491892, mean_eps: 0.288397\n",
      "  79178/1000000: episode: 1132, duration: 4.123s, episode steps: 72, steps per second: 17, episode reward: 11.000, mean reward: 0.153 [0.000, 4.000], mean action: 1.903 [0.000, 3.000], mean observation: 39.533 [0.000, 142.000], loss: 0.025097, mean_squared_error: 17.407713, mean_q: 4.575860, mean_eps: 0.287726\n",
      "  79235/1000000: episode: 1133, duration: 3.384s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.025678, mean_squared_error: 17.308805, mean_q: 4.567387, mean_eps: 0.287146\n",
      "  79302/1000000: episode: 1134, duration: 3.937s, episode steps: 67, steps per second: 17, episode reward: 7.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.060 [0.000, 3.000], mean observation: 39.606 [0.000, 142.000], loss: 0.031661, mean_squared_error: 17.101317, mean_q: 4.504861, mean_eps: 0.286588\n",
      "  79380/1000000: episode: 1135, duration: 4.569s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.897 [0.000, 3.000], mean observation: 39.612 [0.000, 142.000], loss: 0.028644, mean_squared_error: 17.374226, mean_q: 4.552913, mean_eps: 0.285935\n",
      "  79498/1000000: episode: 1136, duration: 6.892s, episode steps: 118, steps per second: 17, episode reward: 15.000, mean reward: 0.127 [0.000, 4.000], mean action: 1.822 [0.000, 3.000], mean observation: 39.171 [0.000, 142.000], loss: 0.023795, mean_squared_error: 17.233880, mean_q: 4.545042, mean_eps: 0.285053\n",
      "  79579/1000000: episode: 1137, duration: 4.770s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.827 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.021518, mean_squared_error: 17.238560, mean_q: 4.561796, mean_eps: 0.284158\n",
      "  79671/1000000: episode: 1138, duration: 5.452s, episode steps: 92, steps per second: 17, episode reward: 10.000, mean reward: 0.109 [0.000, 4.000], mean action: 1.913 [0.000, 3.000], mean observation: 39.437 [0.000, 142.000], loss: 0.026573, mean_squared_error: 17.740069, mean_q: 4.619271, mean_eps: 0.283379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  79752/1000000: episode: 1139, duration: 4.685s, episode steps: 81, steps per second: 17, episode reward: 8.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.963 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.025269, mean_squared_error: 17.233960, mean_q: 4.537260, mean_eps: 0.282601\n",
      "  79850/1000000: episode: 1140, duration: 5.695s, episode steps: 98, steps per second: 17, episode reward: 7.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.653 [0.000, 3.000], mean observation: 39.458 [0.000, 142.000], loss: 0.024571, mean_squared_error: 17.297284, mean_q: 4.538481, mean_eps: 0.281795\n",
      "  79921/1000000: episode: 1141, duration: 4.074s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.817 [0.000, 3.000], mean observation: 39.700 [0.000, 142.000], loss: 0.030370, mean_squared_error: 17.247122, mean_q: 4.543705, mean_eps: 0.281035\n",
      "  79991/1000000: episode: 1142, duration: 4.162s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.800 [0.000, 3.000], mean observation: 39.655 [0.000, 142.000], loss: 0.021873, mean_squared_error: 17.466721, mean_q: 4.575698, mean_eps: 0.280400\n",
      "  80085/1000000: episode: 1143, duration: 5.460s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.766 [0.000, 3.000], mean observation: 39.463 [0.000, 142.000], loss: 0.027293, mean_squared_error: 17.555239, mean_q: 4.587869, mean_eps: 0.279662\n",
      "  80164/1000000: episode: 1144, duration: 4.589s, episode steps: 79, steps per second: 17, episode reward: 4.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.886 [0.000, 3.000], mean observation: 39.689 [0.000, 142.000], loss: 0.023829, mean_squared_error: 17.735964, mean_q: 4.619876, mean_eps: 0.278884\n",
      "  80252/1000000: episode: 1145, duration: 5.120s, episode steps: 88, steps per second: 17, episode reward: 12.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.830 [0.000, 3.000], mean observation: 39.510 [0.000, 142.000], loss: 0.020829, mean_squared_error: 17.673385, mean_q: 4.607552, mean_eps: 0.278132\n",
      "  80317/1000000: episode: 1146, duration: 3.824s, episode steps: 65, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.785 [0.000, 3.000], mean observation: 39.682 [0.000, 142.000], loss: 0.023299, mean_squared_error: 17.654532, mean_q: 4.599121, mean_eps: 0.277444\n",
      "  80393/1000000: episode: 1147, duration: 4.463s, episode steps: 76, steps per second: 17, episode reward: 11.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.908 [0.000, 3.000], mean observation: 39.543 [0.000, 142.000], loss: 0.025407, mean_squared_error: 17.617518, mean_q: 4.605494, mean_eps: 0.276809\n",
      "  80482/1000000: episode: 1148, duration: 5.117s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.640 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.025465, mean_squared_error: 17.904237, mean_q: 4.649382, mean_eps: 0.276067\n",
      "  80561/1000000: episode: 1149, duration: 4.573s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.620 [0.000, 3.000], mean observation: 39.595 [0.000, 142.000], loss: 0.025894, mean_squared_error: 17.803479, mean_q: 4.643052, mean_eps: 0.275311\n",
      "  80671/1000000: episode: 1150, duration: 6.242s, episode steps: 110, steps per second: 18, episode reward: 8.000, mean reward: 0.073 [0.000, 1.000], mean action: 1.691 [0.000, 3.000], mean observation: 39.373 [0.000, 142.000], loss: 0.028699, mean_squared_error: 17.631944, mean_q: 4.603710, mean_eps: 0.274460\n",
      "  80768/1000000: episode: 1151, duration: 5.621s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.366 [0.000, 142.000], loss: 0.025341, mean_squared_error: 17.728723, mean_q: 4.597470, mean_eps: 0.273529\n",
      "  80859/1000000: episode: 1152, duration: 5.396s, episode steps: 91, steps per second: 17, episode reward: 9.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.824 [0.000, 3.000], mean observation: 39.480 [0.000, 142.000], loss: 0.030170, mean_squared_error: 17.769637, mean_q: 4.636141, mean_eps: 0.272683\n",
      "  80943/1000000: episode: 1153, duration: 4.843s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.857 [0.000, 3.000], mean observation: 39.535 [0.000, 142.000], loss: 0.030336, mean_squared_error: 18.250837, mean_q: 4.694069, mean_eps: 0.271896\n",
      "  81016/1000000: episode: 1154, duration: 4.248s, episode steps: 73, steps per second: 17, episode reward: 11.000, mean reward: 0.151 [0.000, 4.000], mean action: 1.562 [0.000, 3.000], mean observation: 39.558 [0.000, 142.000], loss: 0.030615, mean_squared_error: 18.016166, mean_q: 4.667256, mean_eps: 0.271189\n",
      "  81093/1000000: episode: 1155, duration: 4.487s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 2.260 [0.000, 3.000], mean observation: 39.573 [0.000, 142.000], loss: 0.028778, mean_squared_error: 17.853022, mean_q: 4.646580, mean_eps: 0.270514\n",
      "  81200/1000000: episode: 1156, duration: 6.104s, episode steps: 107, steps per second: 18, episode reward: 7.000, mean reward: 0.065 [0.000, 1.000], mean action: 2.019 [0.000, 3.000], mean observation: 39.428 [0.000, 142.000], loss: 0.024476, mean_squared_error: 18.085375, mean_q: 4.669486, mean_eps: 0.269686\n",
      "  81275/1000000: episode: 1157, duration: 4.332s, episode steps: 75, steps per second: 17, episode reward: 5.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.747 [0.000, 3.000], mean observation: 39.591 [0.000, 142.000], loss: 0.023844, mean_squared_error: 18.082060, mean_q: 4.676167, mean_eps: 0.268867\n",
      "  81385/1000000: episode: 1158, duration: 6.434s, episode steps: 110, steps per second: 17, episode reward: 13.000, mean reward: 0.118 [0.000, 4.000], mean action: 1.891 [0.000, 3.000], mean observation: 39.406 [0.000, 142.000], loss: 0.025604, mean_squared_error: 17.741535, mean_q: 4.629359, mean_eps: 0.268035\n",
      "  81468/1000000: episode: 1159, duration: 4.786s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.711 [0.000, 3.000], mean observation: 39.525 [0.000, 142.000], loss: 0.025571, mean_squared_error: 18.148941, mean_q: 4.674741, mean_eps: 0.267166\n",
      "  81584/1000000: episode: 1160, duration: 6.824s, episode steps: 116, steps per second: 17, episode reward: 15.000, mean reward: 0.129 [0.000, 4.000], mean action: 1.784 [0.000, 3.000], mean observation: 39.182 [0.000, 142.000], loss: 0.030044, mean_squared_error: 18.411420, mean_q: 4.699702, mean_eps: 0.266270\n",
      "  81648/1000000: episode: 1161, duration: 3.677s, episode steps: 64, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.844 [0.000, 3.000], mean observation: 39.672 [0.000, 142.000], loss: 0.025440, mean_squared_error: 17.805913, mean_q: 4.618620, mean_eps: 0.265460\n",
      "  81710/1000000: episode: 1162, duration: 3.530s, episode steps: 62, steps per second: 18, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.952 [0.000, 3.000], mean observation: 39.728 [0.000, 142.000], loss: 0.026448, mean_squared_error: 18.101509, mean_q: 4.666568, mean_eps: 0.264893\n",
      "  81802/1000000: episode: 1163, duration: 5.319s, episode steps: 92, steps per second: 17, episode reward: 6.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.522 [0.000, 3.000], mean observation: 39.481 [0.000, 142.000], loss: 0.027833, mean_squared_error: 18.217595, mean_q: 4.691768, mean_eps: 0.264200\n",
      "  81903/1000000: episode: 1164, duration: 5.873s, episode steps: 101, steps per second: 17, episode reward: 10.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.891 [0.000, 3.000], mean observation: 39.418 [0.000, 142.000], loss: 0.028245, mean_squared_error: 18.210639, mean_q: 4.676712, mean_eps: 0.263332\n",
      "  81961/1000000: episode: 1165, duration: 3.332s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.983 [0.000, 3.000], mean observation: 39.776 [0.000, 142.000], loss: 0.029829, mean_squared_error: 18.085757, mean_q: 4.676255, mean_eps: 0.262616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  82045/1000000: episode: 1166, duration: 4.833s, episode steps: 84, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 2.107 [0.000, 3.000], mean observation: 39.499 [0.000, 142.000], loss: 0.023357, mean_squared_error: 18.515723, mean_q: 4.743246, mean_eps: 0.261977\n",
      "  82127/1000000: episode: 1167, duration: 4.805s, episode steps: 82, steps per second: 17, episode reward: 9.000, mean reward: 0.110 [0.000, 4.000], mean action: 2.061 [0.000, 3.000], mean observation: 39.520 [0.000, 142.000], loss: 0.028228, mean_squared_error: 18.442922, mean_q: 4.717307, mean_eps: 0.261230\n",
      "  82231/1000000: episode: 1168, duration: 6.100s, episode steps: 104, steps per second: 17, episode reward: 9.000, mean reward: 0.087 [0.000, 4.000], mean action: 2.067 [0.000, 3.000], mean observation: 39.448 [0.000, 142.000], loss: 0.025004, mean_squared_error: 18.253530, mean_q: 4.696381, mean_eps: 0.260393\n",
      "  82313/1000000: episode: 1169, duration: 4.775s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.720 [0.000, 3.000], mean observation: 39.605 [0.000, 142.000], loss: 0.025426, mean_squared_error: 18.379086, mean_q: 4.713839, mean_eps: 0.259556\n",
      "  82379/1000000: episode: 1170, duration: 3.905s, episode steps: 66, steps per second: 17, episode reward: 3.000, mean reward: 0.045 [0.000, 1.000], mean action: 1.788 [0.000, 3.000], mean observation: 39.697 [0.000, 142.000], loss: 0.025768, mean_squared_error: 18.460842, mean_q: 4.712135, mean_eps: 0.258890\n",
      "  82457/1000000: episode: 1171, duration: 4.582s, episode steps: 78, steps per second: 17, episode reward: 12.000, mean reward: 0.154 [0.000, 4.000], mean action: 1.936 [0.000, 3.000], mean observation: 39.500 [0.000, 142.000], loss: 0.029150, mean_squared_error: 18.345135, mean_q: 4.706893, mean_eps: 0.258242\n",
      "  82566/1000000: episode: 1172, duration: 6.388s, episode steps: 109, steps per second: 17, episode reward: 10.000, mean reward: 0.092 [0.000, 4.000], mean action: 1.917 [0.000, 3.000], mean observation: 39.384 [0.000, 142.000], loss: 0.027295, mean_squared_error: 18.461271, mean_q: 4.726314, mean_eps: 0.257401\n",
      "  82675/1000000: episode: 1173, duration: 6.320s, episode steps: 109, steps per second: 17, episode reward: 14.000, mean reward: 0.128 [0.000, 4.000], mean action: 2.083 [0.000, 3.000], mean observation: 39.324 [0.000, 142.000], loss: 0.026950, mean_squared_error: 18.721696, mean_q: 4.764061, mean_eps: 0.256420\n",
      "  82750/1000000: episode: 1174, duration: 4.416s, episode steps: 75, steps per second: 17, episode reward: 5.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.558 [0.000, 142.000], loss: 0.025736, mean_squared_error: 18.988974, mean_q: 4.797822, mean_eps: 0.255592\n",
      "  82827/1000000: episode: 1175, duration: 4.399s, episode steps: 77, steps per second: 18, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.701 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.028940, mean_squared_error: 18.708618, mean_q: 4.765199, mean_eps: 0.254908\n",
      "  82931/1000000: episode: 1176, duration: 6.070s, episode steps: 104, steps per second: 17, episode reward: 7.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.468 [0.000, 142.000], loss: 0.031278, mean_squared_error: 19.010345, mean_q: 4.787651, mean_eps: 0.254093\n",
      "  83009/1000000: episode: 1177, duration: 4.666s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.718 [0.000, 3.000], mean observation: 39.577 [0.000, 142.000], loss: 0.024452, mean_squared_error: 18.829745, mean_q: 4.749063, mean_eps: 0.253274\n",
      "  83097/1000000: episode: 1178, duration: 5.260s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.494 [0.000, 142.000], loss: 0.026458, mean_squared_error: 18.822901, mean_q: 4.761960, mean_eps: 0.252528\n",
      "  83174/1000000: episode: 1179, duration: 4.499s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.974 [0.000, 3.000], mean observation: 39.567 [0.000, 142.000], loss: 0.028828, mean_squared_error: 18.891521, mean_q: 4.760271, mean_eps: 0.251785\n",
      "  83263/1000000: episode: 1180, duration: 5.131s, episode steps: 89, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.798 [0.000, 3.000], mean observation: 39.508 [0.000, 142.000], loss: 0.025666, mean_squared_error: 19.099916, mean_q: 4.805467, mean_eps: 0.251038\n",
      "  83322/1000000: episode: 1181, duration: 3.369s, episode steps: 59, steps per second: 18, episode reward: 3.000, mean reward: 0.051 [0.000, 1.000], mean action: 1.898 [0.000, 3.000], mean observation: 39.762 [0.000, 142.000], loss: 0.032243, mean_squared_error: 18.959302, mean_q: 4.765715, mean_eps: 0.250372\n",
      "  83406/1000000: episode: 1182, duration: 4.953s, episode steps: 84, steps per second: 17, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.940 [0.000, 3.000], mean observation: 39.535 [0.000, 142.000], loss: 0.026685, mean_squared_error: 19.024037, mean_q: 4.794648, mean_eps: 0.249729\n",
      "  83495/1000000: episode: 1183, duration: 5.129s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.944 [0.000, 3.000], mean observation: 39.495 [0.000, 142.000], loss: 0.028058, mean_squared_error: 18.654345, mean_q: 4.735473, mean_eps: 0.248950\n",
      "  83568/1000000: episode: 1184, duration: 4.187s, episode steps: 73, steps per second: 17, episode reward: 4.000, mean reward: 0.055 [0.000, 1.000], mean action: 1.630 [0.000, 3.000], mean observation: 39.630 [0.000, 142.000], loss: 0.027766, mean_squared_error: 19.493951, mean_q: 4.864214, mean_eps: 0.248221\n",
      "  83651/1000000: episode: 1185, duration: 4.753s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.940 [0.000, 3.000], mean observation: 39.520 [0.000, 142.000], loss: 0.030242, mean_squared_error: 18.923961, mean_q: 4.773562, mean_eps: 0.247519\n",
      "  83725/1000000: episode: 1186, duration: 4.329s, episode steps: 74, steps per second: 17, episode reward: 8.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.797 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.025164, mean_squared_error: 18.929665, mean_q: 4.757345, mean_eps: 0.246812\n",
      "  83800/1000000: episode: 1187, duration: 4.355s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.933 [0.000, 3.000], mean observation: 39.579 [0.000, 142.000], loss: 0.026338, mean_squared_error: 19.117025, mean_q: 4.778480, mean_eps: 0.246142\n",
      "  83908/1000000: episode: 1188, duration: 6.217s, episode steps: 108, steps per second: 17, episode reward: 14.000, mean reward: 0.130 [0.000, 4.000], mean action: 1.981 [0.000, 3.000], mean observation: 39.319 [0.000, 142.000], loss: 0.027090, mean_squared_error: 18.950058, mean_q: 4.766348, mean_eps: 0.245318\n",
      "  83985/1000000: episode: 1189, duration: 4.507s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.831 [0.000, 3.000], mean observation: 39.565 [0.000, 142.000], loss: 0.023491, mean_squared_error: 18.903520, mean_q: 4.763669, mean_eps: 0.244486\n",
      "  84080/1000000: episode: 1190, duration: 5.467s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.811 [0.000, 3.000], mean observation: 39.423 [0.000, 142.000], loss: 0.028591, mean_squared_error: 19.298270, mean_q: 4.821183, mean_eps: 0.243712\n",
      "  84186/1000000: episode: 1191, duration: 6.208s, episode steps: 106, steps per second: 17, episode reward: 9.000, mean reward: 0.085 [0.000, 4.000], mean action: 1.717 [0.000, 3.000], mean observation: 39.488 [0.000, 142.000], loss: 0.025566, mean_squared_error: 19.290362, mean_q: 4.822644, mean_eps: 0.242807\n",
      "  84261/1000000: episode: 1192, duration: 4.345s, episode steps: 75, steps per second: 17, episode reward: 5.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.747 [0.000, 3.000], mean observation: 39.555 [0.000, 142.000], loss: 0.026276, mean_squared_error: 19.536372, mean_q: 4.848216, mean_eps: 0.241993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  84337/1000000: episode: 1193, duration: 4.415s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.658 [0.000, 3.000], mean observation: 39.539 [0.000, 142.000], loss: 0.032937, mean_squared_error: 19.593402, mean_q: 4.842492, mean_eps: 0.241313\n",
      "  84446/1000000: episode: 1194, duration: 6.449s, episode steps: 109, steps per second: 17, episode reward: 11.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.862 [0.000, 3.000], mean observation: 39.275 [0.000, 142.000], loss: 0.025931, mean_squared_error: 19.251125, mean_q: 4.799543, mean_eps: 0.240481\n",
      "  84511/1000000: episode: 1195, duration: 3.784s, episode steps: 65, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.689 [0.000, 142.000], loss: 0.032182, mean_squared_error: 19.036627, mean_q: 4.766130, mean_eps: 0.239698\n",
      "  84568/1000000: episode: 1196, duration: 3.287s, episode steps: 57, steps per second: 17, episode reward: 3.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.018 [0.000, 3.000], mean observation: 39.692 [0.000, 142.000], loss: 0.025626, mean_squared_error: 19.588483, mean_q: 4.865811, mean_eps: 0.239149\n",
      "  84624/1000000: episode: 1197, duration: 3.257s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.692 [0.000, 142.000], loss: 0.025152, mean_squared_error: 19.664875, mean_q: 4.859305, mean_eps: 0.238641\n",
      "  84713/1000000: episode: 1198, duration: 5.164s, episode steps: 89, steps per second: 17, episode reward: 10.000, mean reward: 0.112 [0.000, 4.000], mean action: 1.674 [0.000, 3.000], mean observation: 39.395 [0.000, 142.000], loss: 0.025630, mean_squared_error: 19.518912, mean_q: 4.844251, mean_eps: 0.237988\n",
      "  84825/1000000: episode: 1199, duration: 6.398s, episode steps: 112, steps per second: 18, episode reward: 11.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.973 [0.000, 3.000], mean observation: 39.282 [0.000, 142.000], loss: 0.026614, mean_squared_error: 19.193648, mean_q: 4.810099, mean_eps: 0.237083\n",
      "  84940/1000000: episode: 1200, duration: 6.594s, episode steps: 115, steps per second: 17, episode reward: 11.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.722 [0.000, 3.000], mean observation: 39.264 [0.000, 142.000], loss: 0.026985, mean_squared_error: 19.431896, mean_q: 4.847954, mean_eps: 0.236062\n",
      "  85025/1000000: episode: 1201, duration: 4.964s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.512 [0.000, 142.000], loss: 0.029112, mean_squared_error: 19.368207, mean_q: 4.804158, mean_eps: 0.235162\n",
      "  85093/1000000: episode: 1202, duration: 3.957s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.971 [0.000, 3.000], mean observation: 39.650 [0.000, 142.000], loss: 0.026373, mean_squared_error: 19.334597, mean_q: 4.811200, mean_eps: 0.234473\n",
      "  85169/1000000: episode: 1203, duration: 4.396s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.934 [0.000, 3.000], mean observation: 39.576 [0.000, 142.000], loss: 0.023668, mean_squared_error: 19.517823, mean_q: 4.851922, mean_eps: 0.233825\n",
      "  85268/1000000: episode: 1204, duration: 5.755s, episode steps: 99, steps per second: 17, episode reward: 7.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.909 [0.000, 3.000], mean observation: 39.405 [0.000, 142.000], loss: 0.026475, mean_squared_error: 19.566372, mean_q: 4.842713, mean_eps: 0.233038\n",
      "  85353/1000000: episode: 1205, duration: 5.018s, episode steps: 85, steps per second: 17, episode reward: 6.000, mean reward: 0.071 [0.000, 1.000], mean action: 1.976 [0.000, 3.000], mean observation: 39.492 [0.000, 142.000], loss: 0.024124, mean_squared_error: 19.672283, mean_q: 4.875439, mean_eps: 0.232210\n",
      "  85448/1000000: episode: 1206, duration: 5.558s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.916 [0.000, 3.000], mean observation: 39.439 [0.000, 142.000], loss: 0.025361, mean_squared_error: 19.500351, mean_q: 4.823126, mean_eps: 0.231400\n",
      "  85510/1000000: episode: 1207, duration: 3.680s, episode steps: 62, steps per second: 17, episode reward: 3.000, mean reward: 0.048 [0.000, 1.000], mean action: 1.823 [0.000, 3.000], mean observation: 39.713 [0.000, 142.000], loss: 0.026977, mean_squared_error: 20.447733, mean_q: 4.949255, mean_eps: 0.230693\n",
      "  85566/1000000: episode: 1208, duration: 3.238s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.692 [0.000, 142.000], loss: 0.027364, mean_squared_error: 19.206249, mean_q: 4.774576, mean_eps: 0.230162\n",
      "  85669/1000000: episode: 1209, duration: 5.940s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.942 [0.000, 3.000], mean observation: 39.314 [0.000, 142.000], loss: 0.025979, mean_squared_error: 19.631745, mean_q: 4.825426, mean_eps: 0.229447\n",
      "  85748/1000000: episode: 1210, duration: 4.609s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.937 [0.000, 3.000], mean observation: 39.580 [0.000, 142.000], loss: 0.027183, mean_squared_error: 19.748405, mean_q: 4.840570, mean_eps: 0.228628\n",
      "  85804/1000000: episode: 1211, duration: 3.265s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.699 [0.000, 142.000], loss: 0.023491, mean_squared_error: 19.752110, mean_q: 4.853237, mean_eps: 0.228020\n",
      "  85902/1000000: episode: 1212, duration: 5.636s, episode steps: 98, steps per second: 17, episode reward: 14.000, mean reward: 0.143 [0.000, 4.000], mean action: 2.204 [0.000, 3.000], mean observation: 39.309 [0.000, 142.000], loss: 0.026895, mean_squared_error: 19.885463, mean_q: 4.881808, mean_eps: 0.227327\n",
      "  86009/1000000: episode: 1213, duration: 6.260s, episode steps: 107, steps per second: 17, episode reward: 13.000, mean reward: 0.121 [0.000, 4.000], mean action: 2.065 [0.000, 3.000], mean observation: 39.439 [0.000, 142.000], loss: 0.027477, mean_squared_error: 19.971072, mean_q: 4.882762, mean_eps: 0.226405\n",
      "  86105/1000000: episode: 1214, duration: 5.527s, episode steps: 96, steps per second: 17, episode reward: 9.000, mean reward: 0.094 [0.000, 4.000], mean action: 2.094 [0.000, 3.000], mean observation: 39.484 [0.000, 142.000], loss: 0.024955, mean_squared_error: 19.852042, mean_q: 4.888096, mean_eps: 0.225491\n",
      "  86161/1000000: episode: 1215, duration: 3.320s, episode steps: 56, steps per second: 17, episode reward: 3.000, mean reward: 0.054 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.692 [0.000, 142.000], loss: 0.026098, mean_squared_error: 20.124067, mean_q: 4.922656, mean_eps: 0.224807\n",
      "  86252/1000000: episode: 1216, duration: 5.355s, episode steps: 91, steps per second: 17, episode reward: 6.000, mean reward: 0.066 [0.000, 1.000], mean action: 2.044 [0.000, 3.000], mean observation: 39.494 [0.000, 142.000], loss: 0.026116, mean_squared_error: 19.976754, mean_q: 4.888450, mean_eps: 0.224146\n",
      "  86317/1000000: episode: 1217, duration: 3.840s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.877 [0.000, 3.000], mean observation: 39.601 [0.000, 142.000], loss: 0.030453, mean_squared_error: 20.342896, mean_q: 4.949746, mean_eps: 0.223444\n",
      "  86404/1000000: episode: 1218, duration: 5.112s, episode steps: 87, steps per second: 17, episode reward: 9.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.839 [0.000, 3.000], mean observation: 39.478 [0.000, 142.000], loss: 0.029015, mean_squared_error: 20.235196, mean_q: 4.921703, mean_eps: 0.222760\n",
      "  86509/1000000: episode: 1219, duration: 6.089s, episode steps: 105, steps per second: 17, episode reward: 7.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.695 [0.000, 3.000], mean observation: 39.388 [0.000, 142.000], loss: 0.028871, mean_squared_error: 19.987685, mean_q: 4.864019, mean_eps: 0.221896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  86599/1000000: episode: 1220, duration: 5.130s, episode steps: 90, steps per second: 18, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 1.900 [0.000, 3.000], mean observation: 39.432 [0.000, 142.000], loss: 0.026692, mean_squared_error: 20.342355, mean_q: 4.926936, mean_eps: 0.221019\n",
      "  86710/1000000: episode: 1221, duration: 6.372s, episode steps: 111, steps per second: 17, episode reward: 11.000, mean reward: 0.099 [0.000, 4.000], mean action: 2.018 [0.000, 3.000], mean observation: 39.306 [0.000, 142.000], loss: 0.024215, mean_squared_error: 20.443488, mean_q: 4.951489, mean_eps: 0.220114\n",
      "  86805/1000000: episode: 1222, duration: 5.376s, episode steps: 95, steps per second: 18, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.821 [0.000, 3.000], mean observation: 39.399 [0.000, 142.000], loss: 0.033706, mean_squared_error: 20.339958, mean_q: 4.933842, mean_eps: 0.219187\n",
      "  86897/1000000: episode: 1223, duration: 5.352s, episode steps: 92, steps per second: 17, episode reward: 7.000, mean reward: 0.076 [0.000, 1.000], mean action: 1.500 [0.000, 3.000], mean observation: 39.372 [0.000, 142.000], loss: 0.027138, mean_squared_error: 20.807841, mean_q: 5.014155, mean_eps: 0.218346\n",
      "  86967/1000000: episode: 1224, duration: 4.153s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.644 [0.000, 142.000], loss: 0.028272, mean_squared_error: 20.408779, mean_q: 4.940394, mean_eps: 0.217616\n",
      "  87025/1000000: episode: 1225, duration: 3.374s, episode steps: 58, steps per second: 17, episode reward: 3.000, mean reward: 0.052 [0.000, 1.000], mean action: 1.741 [0.000, 3.000], mean observation: 39.689 [0.000, 142.000], loss: 0.023796, mean_squared_error: 20.743183, mean_q: 5.020587, mean_eps: 0.217040\n",
      "  87126/1000000: episode: 1226, duration: 5.879s, episode steps: 101, steps per second: 17, episode reward: 14.000, mean reward: 0.139 [0.000, 4.000], mean action: 2.109 [0.000, 3.000], mean observation: 39.262 [0.000, 142.000], loss: 0.023786, mean_squared_error: 21.015460, mean_q: 5.020768, mean_eps: 0.216325\n",
      "  87196/1000000: episode: 1227, duration: 4.029s, episode steps: 70, steps per second: 17, episode reward: 4.000, mean reward: 0.057 [0.000, 1.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.588 [0.000, 142.000], loss: 0.026555, mean_squared_error: 20.734807, mean_q: 4.981183, mean_eps: 0.215555\n",
      "  87272/1000000: episode: 1228, duration: 4.314s, episode steps: 76, steps per second: 18, episode reward: 4.000, mean reward: 0.053 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.610 [0.000, 142.000], loss: 0.027181, mean_squared_error: 20.685806, mean_q: 4.969961, mean_eps: 0.214898\n",
      "  87354/1000000: episode: 1229, duration: 4.699s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.878 [0.000, 3.000], mean observation: 39.572 [0.000, 142.000], loss: 0.026065, mean_squared_error: 20.532971, mean_q: 4.956101, mean_eps: 0.214187\n",
      "  87436/1000000: episode: 1230, duration: 4.828s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.963 [0.000, 3.000], mean observation: 39.540 [0.000, 142.000], loss: 0.023678, mean_squared_error: 20.694809, mean_q: 4.963581, mean_eps: 0.213450\n",
      "  87501/1000000: episode: 1231, duration: 3.775s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 2.138 [0.000, 3.000], mean observation: 39.596 [0.000, 142.000], loss: 0.029666, mean_squared_error: 20.141801, mean_q: 4.880416, mean_eps: 0.212788\n",
      "  87636/1000000: episode: 1232, duration: 7.812s, episode steps: 135, steps per second: 17, episode reward: 10.000, mean reward: 0.074 [0.000, 1.000], mean action: 1.911 [0.000, 3.000], mean observation: 39.262 [0.000, 142.000], loss: 0.024986, mean_squared_error: 20.581918, mean_q: 4.967034, mean_eps: 0.211888\n",
      "  87707/1000000: episode: 1233, duration: 4.099s, episode steps: 71, steps per second: 17, episode reward: 8.000, mean reward: 0.113 [0.000, 4.000], mean action: 1.915 [0.000, 3.000], mean observation: 39.582 [0.000, 142.000], loss: 0.024928, mean_squared_error: 20.927277, mean_q: 5.006947, mean_eps: 0.210961\n",
      "  87795/1000000: episode: 1234, duration: 5.103s, episode steps: 88, steps per second: 17, episode reward: 6.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.909 [0.000, 3.000], mean observation: 39.463 [0.000, 142.000], loss: 0.026509, mean_squared_error: 20.007348, mean_q: 4.853384, mean_eps: 0.210246\n",
      "  87889/1000000: episode: 1235, duration: 5.480s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.617 [0.000, 3.000], mean observation: 39.437 [0.000, 142.000], loss: 0.024444, mean_squared_error: 20.960153, mean_q: 5.020910, mean_eps: 0.209427\n",
      "  87970/1000000: episode: 1236, duration: 4.747s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 2.099 [0.000, 3.000], mean observation: 39.541 [0.000, 142.000], loss: 0.026639, mean_squared_error: 20.988250, mean_q: 5.029485, mean_eps: 0.208639\n",
      "  88100/1000000: episode: 1237, duration: 7.664s, episode steps: 130, steps per second: 17, episode reward: 10.000, mean reward: 0.077 [0.000, 1.000], mean action: 1.915 [0.000, 3.000], mean observation: 39.196 [0.000, 142.000], loss: 0.028710, mean_squared_error: 20.652680, mean_q: 4.972340, mean_eps: 0.207689\n",
      "  88200/1000000: episode: 1238, duration: 5.688s, episode steps: 100, steps per second: 18, episode reward: 6.000, mean reward: 0.060 [0.000, 1.000], mean action: 2.110 [0.000, 3.000], mean observation: 39.484 [0.000, 142.000], loss: 0.024996, mean_squared_error: 20.885549, mean_q: 5.005235, mean_eps: 0.206654\n",
      "  88282/1000000: episode: 1239, duration: 4.749s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.927 [0.000, 3.000], mean observation: 39.569 [0.000, 142.000], loss: 0.029510, mean_squared_error: 20.538112, mean_q: 4.933634, mean_eps: 0.205836\n",
      "  88423/1000000: episode: 1240, duration: 8.194s, episode steps: 141, steps per second: 17, episode reward: 10.000, mean reward: 0.071 [0.000, 4.000], mean action: 2.199 [0.000, 3.000], mean observation: 39.289 [0.000, 142.000], loss: 0.029555, mean_squared_error: 21.027922, mean_q: 5.015429, mean_eps: 0.204832\n",
      "  88571/1000000: episode: 1241, duration: 8.523s, episode steps: 148, steps per second: 17, episode reward: 9.000, mean reward: 0.061 [0.000, 1.000], mean action: 2.196 [0.000, 3.000], mean observation: 39.252 [0.000, 142.000], loss: 0.024454, mean_squared_error: 20.927038, mean_q: 5.019627, mean_eps: 0.203531\n",
      "  88658/1000000: episode: 1242, duration: 5.061s, episode steps: 87, steps per second: 17, episode reward: 6.000, mean reward: 0.069 [0.000, 1.000], mean action: 1.655 [0.000, 3.000], mean observation: 39.472 [0.000, 142.000], loss: 0.025884, mean_squared_error: 21.187426, mean_q: 5.058200, mean_eps: 0.202474\n",
      "  88735/1000000: episode: 1243, duration: 4.494s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 2.078 [0.000, 3.000], mean observation: 39.593 [0.000, 142.000], loss: 0.025520, mean_squared_error: 21.327093, mean_q: 5.085693, mean_eps: 0.201736\n",
      "  88837/1000000: episode: 1244, duration: 5.947s, episode steps: 102, steps per second: 17, episode reward: 10.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.804 [0.000, 3.000], mean observation: 39.397 [0.000, 142.000], loss: 0.027117, mean_squared_error: 21.431353, mean_q: 5.081925, mean_eps: 0.200930\n",
      "  88939/1000000: episode: 1245, duration: 6.045s, episode steps: 102, steps per second: 17, episode reward: 10.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.775 [0.000, 3.000], mean observation: 39.373 [0.000, 142.000], loss: 0.028895, mean_squared_error: 21.183208, mean_q: 5.054806, mean_eps: 0.200012\n",
      "  89021/1000000: episode: 1246, duration: 4.806s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.526 [0.000, 142.000], loss: 0.028045, mean_squared_error: 21.039328, mean_q: 5.039411, mean_eps: 0.199184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  89129/1000000: episode: 1247, duration: 6.266s, episode steps: 108, steps per second: 17, episode reward: 11.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.148 [0.000, 3.000], mean observation: 39.281 [0.000, 142.000], loss: 0.025269, mean_squared_error: 21.112983, mean_q: 5.034755, mean_eps: 0.198329\n",
      "  89200/1000000: episode: 1248, duration: 4.149s, episode steps: 71, steps per second: 17, episode reward: 4.000, mean reward: 0.056 [0.000, 1.000], mean action: 1.859 [0.000, 3.000], mean observation: 39.631 [0.000, 142.000], loss: 0.030193, mean_squared_error: 21.055427, mean_q: 5.016177, mean_eps: 0.197524\n",
      "  89325/1000000: episode: 1249, duration: 7.275s, episode steps: 125, steps per second: 17, episode reward: 15.000, mean reward: 0.120 [0.000, 4.000], mean action: 2.072 [0.000, 3.000], mean observation: 39.222 [0.000, 142.000], loss: 0.029761, mean_squared_error: 21.100034, mean_q: 5.030595, mean_eps: 0.196642\n",
      "  89414/1000000: episode: 1250, duration: 5.220s, episode steps: 89, steps per second: 17, episode reward: 12.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.910 [0.000, 3.000], mean observation: 39.504 [0.000, 142.000], loss: 0.029880, mean_squared_error: 21.551410, mean_q: 5.103141, mean_eps: 0.195679\n",
      "  89494/1000000: episode: 1251, duration: 4.527s, episode steps: 80, steps per second: 18, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 2.025 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.027497, mean_squared_error: 20.872213, mean_q: 4.983918, mean_eps: 0.194918\n",
      "  89579/1000000: episode: 1252, duration: 4.928s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.976 [0.000, 3.000], mean observation: 39.468 [0.000, 142.000], loss: 0.027689, mean_squared_error: 20.971871, mean_q: 4.994378, mean_eps: 0.194176\n",
      "  89683/1000000: episode: 1253, duration: 5.922s, episode steps: 104, steps per second: 18, episode reward: 12.000, mean reward: 0.115 [0.000, 4.000], mean action: 2.087 [0.000, 3.000], mean observation: 39.470 [0.000, 142.000], loss: 0.029563, mean_squared_error: 21.178894, mean_q: 5.043319, mean_eps: 0.193325\n",
      "  89798/1000000: episode: 1254, duration: 6.464s, episode steps: 115, steps per second: 18, episode reward: 11.000, mean reward: 0.096 [0.000, 4.000], mean action: 2.243 [0.000, 3.000], mean observation: 39.290 [0.000, 142.000], loss: 0.027495, mean_squared_error: 20.352190, mean_q: 4.938108, mean_eps: 0.192340\n",
      "  89905/1000000: episode: 1255, duration: 6.294s, episode steps: 107, steps per second: 17, episode reward: 8.000, mean reward: 0.075 [0.000, 1.000], mean action: 1.785 [0.000, 3.000], mean observation: 39.316 [0.000, 142.000], loss: 0.026882, mean_squared_error: 21.504563, mean_q: 5.107686, mean_eps: 0.191341\n",
      "  89997/1000000: episode: 1256, duration: 5.409s, episode steps: 92, steps per second: 17, episode reward: 9.000, mean reward: 0.098 [0.000, 4.000], mean action: 2.217 [0.000, 3.000], mean observation: 39.500 [0.000, 142.000], loss: 0.024385, mean_squared_error: 21.368330, mean_q: 5.087768, mean_eps: 0.190445\n",
      "  90080/1000000: episode: 1257, duration: 4.816s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 2.012 [0.000, 3.000], mean observation: 39.525 [0.000, 142.000], loss: 0.025976, mean_squared_error: 21.396048, mean_q: 5.080423, mean_eps: 0.189658\n",
      "  90181/1000000: episode: 1258, duration: 5.753s, episode steps: 101, steps per second: 18, episode reward: 10.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.782 [0.000, 3.000], mean observation: 39.427 [0.000, 142.000], loss: 0.027392, mean_squared_error: 21.391522, mean_q: 5.087477, mean_eps: 0.188830\n",
      "  90263/1000000: episode: 1259, duration: 4.702s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.841 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.024543, mean_squared_error: 21.418894, mean_q: 5.074709, mean_eps: 0.188006\n",
      "  90351/1000000: episode: 1260, duration: 5.128s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.068 [0.000, 3.000], mean observation: 39.462 [0.000, 142.000], loss: 0.025640, mean_squared_error: 21.645817, mean_q: 5.118274, mean_eps: 0.187242\n",
      "  90439/1000000: episode: 1261, duration: 5.080s, episode steps: 88, steps per second: 17, episode reward: 5.000, mean reward: 0.057 [0.000, 1.000], mean action: 2.227 [0.000, 3.000], mean observation: 39.576 [0.000, 142.000], loss: 0.031517, mean_squared_error: 21.233540, mean_q: 5.061060, mean_eps: 0.186449\n",
      "  90506/1000000: episode: 1262, duration: 3.856s, episode steps: 67, steps per second: 17, episode reward: 7.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.552 [0.000, 3.000], mean observation: 39.612 [0.000, 142.000], loss: 0.019504, mean_squared_error: 21.232566, mean_q: 5.045941, mean_eps: 0.185752\n",
      "  90603/1000000: episode: 1263, duration: 5.648s, episode steps: 97, steps per second: 17, episode reward: 14.000, mean reward: 0.144 [0.000, 4.000], mean action: 1.856 [0.000, 3.000], mean observation: 39.310 [0.000, 142.000], loss: 0.025861, mean_squared_error: 21.529219, mean_q: 5.107873, mean_eps: 0.185014\n",
      "  90703/1000000: episode: 1264, duration: 5.770s, episode steps: 100, steps per second: 17, episode reward: 9.000, mean reward: 0.090 [0.000, 4.000], mean action: 2.180 [0.000, 3.000], mean observation: 39.479 [0.000, 142.000], loss: 0.030016, mean_squared_error: 21.207697, mean_q: 5.046403, mean_eps: 0.184128\n",
      "  90799/1000000: episode: 1265, duration: 5.613s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.552 [0.000, 3.000], mean observation: 39.417 [0.000, 142.000], loss: 0.026086, mean_squared_error: 20.930798, mean_q: 4.990865, mean_eps: 0.183246\n",
      "  90883/1000000: episode: 1266, duration: 4.946s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.881 [0.000, 3.000], mean observation: 39.504 [0.000, 142.000], loss: 0.025492, mean_squared_error: 21.192811, mean_q: 5.045146, mean_eps: 0.182435\n",
      "  90958/1000000: episode: 1267, duration: 4.420s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.907 [0.000, 3.000], mean observation: 39.587 [0.000, 142.000], loss: 0.024110, mean_squared_error: 21.450976, mean_q: 5.093987, mean_eps: 0.181720\n",
      "  91028/1000000: episode: 1268, duration: 4.140s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 1.814 [0.000, 3.000], mean observation: 39.556 [0.000, 142.000], loss: 0.026807, mean_squared_error: 21.450470, mean_q: 5.093718, mean_eps: 0.181067\n",
      "  91150/1000000: episode: 1269, duration: 6.956s, episode steps: 122, steps per second: 18, episode reward: 15.000, mean reward: 0.123 [0.000, 4.000], mean action: 1.959 [0.000, 3.000], mean observation: 39.170 [0.000, 142.000], loss: 0.032252, mean_squared_error: 21.757643, mean_q: 5.132800, mean_eps: 0.180203\n",
      "  91267/1000000: episode: 1270, duration: 6.695s, episode steps: 117, steps per second: 17, episode reward: 12.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.880 [0.000, 3.000], mean observation: 39.243 [0.000, 142.000], loss: 0.024700, mean_squared_error: 21.416225, mean_q: 5.075215, mean_eps: 0.179128\n",
      "  91355/1000000: episode: 1271, duration: 5.075s, episode steps: 88, steps per second: 17, episode reward: 6.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.886 [0.000, 3.000], mean observation: 39.475 [0.000, 142.000], loss: 0.035521, mean_squared_error: 21.164862, mean_q: 5.036293, mean_eps: 0.178205\n",
      "  91465/1000000: episode: 1272, duration: 6.224s, episode steps: 110, steps per second: 18, episode reward: 11.000, mean reward: 0.100 [0.000, 4.000], mean action: 2.136 [0.000, 3.000], mean observation: 39.311 [0.000, 142.000], loss: 0.026758, mean_squared_error: 21.537585, mean_q: 5.095397, mean_eps: 0.177314\n",
      "  91557/1000000: episode: 1273, duration: 5.449s, episode steps: 92, steps per second: 17, episode reward: 7.000, mean reward: 0.076 [0.000, 1.000], mean action: 1.848 [0.000, 3.000], mean observation: 39.431 [0.000, 142.000], loss: 0.027444, mean_squared_error: 21.294920, mean_q: 5.060814, mean_eps: 0.176406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  91666/1000000: episode: 1274, duration: 6.291s, episode steps: 109, steps per second: 17, episode reward: 14.000, mean reward: 0.128 [0.000, 4.000], mean action: 1.991 [0.000, 3.000], mean observation: 39.309 [0.000, 142.000], loss: 0.028023, mean_squared_error: 21.386158, mean_q: 5.051615, mean_eps: 0.175501\n",
      "  91772/1000000: episode: 1275, duration: 6.013s, episode steps: 106, steps per second: 18, episode reward: 8.000, mean reward: 0.075 [0.000, 1.000], mean action: 1.755 [0.000, 3.000], mean observation: 39.291 [0.000, 142.000], loss: 0.031189, mean_squared_error: 21.357574, mean_q: 5.055067, mean_eps: 0.174534\n",
      "  91891/1000000: episode: 1276, duration: 6.958s, episode steps: 119, steps per second: 17, episode reward: 12.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.824 [0.000, 3.000], mean observation: 39.216 [0.000, 142.000], loss: 0.024636, mean_squared_error: 21.871317, mean_q: 5.121054, mean_eps: 0.173521\n",
      "  91963/1000000: episode: 1277, duration: 4.212s, episode steps: 72, steps per second: 17, episode reward: 8.000, mean reward: 0.111 [0.000, 4.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.562 [0.000, 142.000], loss: 0.025993, mean_squared_error: 21.802336, mean_q: 5.107561, mean_eps: 0.172661\n",
      "  92051/1000000: episode: 1278, duration: 5.011s, episode steps: 88, steps per second: 18, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.023 [0.000, 3.000], mean observation: 39.491 [0.000, 142.000], loss: 0.029047, mean_squared_error: 21.532436, mean_q: 5.082046, mean_eps: 0.171941\n",
      "  92171/1000000: episode: 1279, duration: 6.938s, episode steps: 120, steps per second: 17, episode reward: 12.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.917 [0.000, 3.000], mean observation: 39.267 [0.000, 142.000], loss: 0.029357, mean_squared_error: 21.749835, mean_q: 5.120668, mean_eps: 0.171006\n",
      "  92261/1000000: episode: 1280, duration: 5.285s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.789 [0.000, 3.000], mean observation: 39.478 [0.000, 142.000], loss: 0.029124, mean_squared_error: 21.655724, mean_q: 5.100123, mean_eps: 0.170061\n",
      "  92358/1000000: episode: 1281, duration: 5.715s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.165 [0.000, 3.000], mean observation: 39.414 [0.000, 142.000], loss: 0.027439, mean_squared_error: 22.175347, mean_q: 5.155384, mean_eps: 0.169219\n",
      "  92426/1000000: episode: 1282, duration: 3.977s, episode steps: 68, steps per second: 17, episode reward: 4.000, mean reward: 0.059 [0.000, 1.000], mean action: 1.912 [0.000, 3.000], mean observation: 39.620 [0.000, 142.000], loss: 0.028736, mean_squared_error: 21.970594, mean_q: 5.134239, mean_eps: 0.168477\n",
      "  92506/1000000: episode: 1283, duration: 4.591s, episode steps: 80, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 2.087 [0.000, 3.000], mean observation: 39.548 [0.000, 142.000], loss: 0.023615, mean_squared_error: 22.237201, mean_q: 5.182782, mean_eps: 0.167810\n",
      "  92588/1000000: episode: 1284, duration: 4.777s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 2.037 [0.000, 3.000], mean observation: 39.510 [0.000, 142.000], loss: 0.028749, mean_squared_error: 21.877920, mean_q: 5.138149, mean_eps: 0.167081\n",
      "  92659/1000000: episode: 1285, duration: 4.117s, episode steps: 71, steps per second: 17, episode reward: 11.000, mean reward: 0.155 [0.000, 4.000], mean action: 1.986 [0.000, 3.000], mean observation: 39.549 [0.000, 142.000], loss: 0.027318, mean_squared_error: 21.766023, mean_q: 5.110216, mean_eps: 0.166393\n",
      "  92766/1000000: episode: 1286, duration: 6.329s, episode steps: 107, steps per second: 17, episode reward: 14.000, mean reward: 0.131 [0.000, 4.000], mean action: 2.112 [0.000, 3.000], mean observation: 39.332 [0.000, 142.000], loss: 0.027805, mean_squared_error: 22.287411, mean_q: 5.194326, mean_eps: 0.165592\n",
      "  92864/1000000: episode: 1287, duration: 5.682s, episode steps: 98, steps per second: 17, episode reward: 10.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.827 [0.000, 3.000], mean observation: 39.385 [0.000, 142.000], loss: 0.030100, mean_squared_error: 21.983401, mean_q: 5.141436, mean_eps: 0.164669\n",
      "  92952/1000000: episode: 1288, duration: 5.010s, episode steps: 88, steps per second: 18, episode reward: 6.000, mean reward: 0.068 [0.000, 1.000], mean action: 1.761 [0.000, 3.000], mean observation: 39.464 [0.000, 142.000], loss: 0.031377, mean_squared_error: 22.002608, mean_q: 5.125764, mean_eps: 0.163832\n",
      "  93019/1000000: episode: 1289, duration: 3.904s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 2.060 [0.000, 3.000], mean observation: 39.621 [0.000, 142.000], loss: 0.033834, mean_squared_error: 21.790730, mean_q: 5.115518, mean_eps: 0.163135\n",
      "  93108/1000000: episode: 1290, duration: 5.066s, episode steps: 89, steps per second: 18, episode reward: 13.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.809 [0.000, 3.000], mean observation: 39.415 [0.000, 142.000], loss: 0.028340, mean_squared_error: 21.775376, mean_q: 5.098579, mean_eps: 0.162433\n",
      "  93194/1000000: episode: 1291, duration: 4.883s, episode steps: 86, steps per second: 18, episode reward: 9.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.198 [0.000, 3.000], mean observation: 39.501 [0.000, 142.000], loss: 0.033068, mean_squared_error: 22.443697, mean_q: 5.212115, mean_eps: 0.161645\n",
      "  93291/1000000: episode: 1292, duration: 5.707s, episode steps: 97, steps per second: 17, episode reward: 7.000, mean reward: 0.072 [0.000, 1.000], mean action: 1.567 [0.000, 3.000], mean observation: 39.436 [0.000, 142.000], loss: 0.026159, mean_squared_error: 22.022079, mean_q: 5.148104, mean_eps: 0.160822\n",
      "  93376/1000000: episode: 1293, duration: 4.901s, episode steps: 85, steps per second: 17, episode reward: 12.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.906 [0.000, 3.000], mean observation: 39.517 [0.000, 142.000], loss: 0.030166, mean_squared_error: 22.235644, mean_q: 5.175180, mean_eps: 0.160003\n",
      "  93448/1000000: episode: 1294, duration: 4.119s, episode steps: 72, steps per second: 17, episode reward: 11.000, mean reward: 0.153 [0.000, 4.000], mean action: 2.014 [0.000, 3.000], mean observation: 39.546 [0.000, 142.000], loss: 0.029087, mean_squared_error: 22.427065, mean_q: 5.194068, mean_eps: 0.159297\n",
      "  93544/1000000: episode: 1295, duration: 5.480s, episode steps: 96, steps per second: 18, episode reward: 10.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.052 [0.000, 3.000], mean observation: 39.411 [0.000, 142.000], loss: 0.030151, mean_squared_error: 22.037305, mean_q: 5.119257, mean_eps: 0.158540\n",
      "  93621/1000000: episode: 1296, duration: 4.500s, episode steps: 77, steps per second: 17, episode reward: 5.000, mean reward: 0.065 [0.000, 1.000], mean action: 1.961 [0.000, 3.000], mean observation: 39.594 [0.000, 142.000], loss: 0.026847, mean_squared_error: 22.763248, mean_q: 5.248452, mean_eps: 0.157762\n",
      "  93717/1000000: episode: 1297, duration: 5.591s, episode steps: 96, steps per second: 17, episode reward: 7.000, mean reward: 0.073 [0.000, 1.000], mean action: 1.969 [0.000, 3.000], mean observation: 39.382 [0.000, 142.000], loss: 0.028014, mean_squared_error: 22.805719, mean_q: 5.248048, mean_eps: 0.156983\n",
      "  93804/1000000: episode: 1298, duration: 5.028s, episode steps: 87, steps per second: 17, episode reward: 6.000, mean reward: 0.069 [0.000, 1.000], mean action: 1.448 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.028056, mean_squared_error: 22.358150, mean_q: 5.166466, mean_eps: 0.156160\n",
      "  93870/1000000: episode: 1299, duration: 3.857s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.667 [0.000, 3.000], mean observation: 39.620 [0.000, 142.000], loss: 0.031598, mean_squared_error: 22.687176, mean_q: 5.212194, mean_eps: 0.155471\n",
      "  93974/1000000: episode: 1300, duration: 5.941s, episode steps: 104, steps per second: 18, episode reward: 14.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.827 [0.000, 3.000], mean observation: 39.319 [0.000, 142.000], loss: 0.027101, mean_squared_error: 22.985916, mean_q: 5.242018, mean_eps: 0.154706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  94060/1000000: episode: 1301, duration: 4.988s, episode steps: 86, steps per second: 17, episode reward: 9.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.872 [0.000, 3.000], mean observation: 39.467 [0.000, 142.000], loss: 0.026199, mean_squared_error: 23.049091, mean_q: 5.255681, mean_eps: 0.153852\n",
      "  94162/1000000: episode: 1302, duration: 5.964s, episode steps: 102, steps per second: 17, episode reward: 13.000, mean reward: 0.127 [0.000, 4.000], mean action: 2.167 [0.000, 3.000], mean observation: 39.432 [0.000, 142.000], loss: 0.025158, mean_squared_error: 23.094445, mean_q: 5.278294, mean_eps: 0.153005\n",
      "  94232/1000000: episode: 1303, duration: 4.080s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.544 [0.000, 142.000], loss: 0.025816, mean_squared_error: 23.105031, mean_q: 5.277189, mean_eps: 0.152231\n",
      "  94342/1000000: episode: 1304, duration: 6.383s, episode steps: 110, steps per second: 17, episode reward: 14.000, mean reward: 0.127 [0.000, 4.000], mean action: 1.845 [0.000, 3.000], mean observation: 39.315 [0.000, 142.000], loss: 0.030831, mean_squared_error: 23.294418, mean_q: 5.285095, mean_eps: 0.151421\n",
      "  94442/1000000: episode: 1305, duration: 5.813s, episode steps: 100, steps per second: 17, episode reward: 9.000, mean reward: 0.090 [0.000, 4.000], mean action: 1.930 [0.000, 3.000], mean observation: 39.488 [0.000, 142.000], loss: 0.030238, mean_squared_error: 22.999906, mean_q: 5.250282, mean_eps: 0.150476\n",
      "  94507/1000000: episode: 1306, duration: 3.783s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.596 [0.000, 142.000], loss: 0.025911, mean_squared_error: 23.394946, mean_q: 5.298400, mean_eps: 0.149734\n",
      "  94590/1000000: episode: 1307, duration: 4.902s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.880 [0.000, 3.000], mean observation: 39.497 [0.000, 142.000], loss: 0.030625, mean_squared_error: 23.319310, mean_q: 5.285118, mean_eps: 0.149068\n",
      "  94677/1000000: episode: 1308, duration: 4.958s, episode steps: 87, steps per second: 18, episode reward: 9.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.747 [0.000, 3.000], mean observation: 39.496 [0.000, 142.000], loss: 0.029957, mean_squared_error: 22.646548, mean_q: 5.204316, mean_eps: 0.148303\n",
      "  94748/1000000: episode: 1309, duration: 4.053s, episode steps: 71, steps per second: 18, episode reward: 11.000, mean reward: 0.155 [0.000, 4.000], mean action: 2.169 [0.000, 3.000], mean observation: 39.539 [0.000, 142.000], loss: 0.024984, mean_squared_error: 23.351442, mean_q: 5.287989, mean_eps: 0.147592\n",
      "  94843/1000000: episode: 1310, duration: 5.529s, episode steps: 95, steps per second: 17, episode reward: 7.000, mean reward: 0.074 [0.000, 1.000], mean action: 2.116 [0.000, 3.000], mean observation: 39.419 [0.000, 142.000], loss: 0.025334, mean_squared_error: 23.593110, mean_q: 5.344883, mean_eps: 0.146845\n",
      "  94909/1000000: episode: 1311, duration: 3.828s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.636 [0.000, 3.000], mean observation: 39.614 [0.000, 142.000], loss: 0.025114, mean_squared_error: 23.369512, mean_q: 5.306793, mean_eps: 0.146120\n",
      "  95004/1000000: episode: 1312, duration: 5.621s, episode steps: 95, steps per second: 17, episode reward: 10.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.053 [0.000, 3.000], mean observation: 39.359 [0.000, 142.000], loss: 0.030756, mean_squared_error: 23.186313, mean_q: 5.261631, mean_eps: 0.145396\n",
      "  95081/1000000: episode: 1313, duration: 4.497s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.844 [0.000, 3.000], mean observation: 39.585 [0.000, 142.000], loss: 0.024704, mean_squared_error: 23.470755, mean_q: 5.338108, mean_eps: 0.144622\n",
      "  95159/1000000: episode: 1314, duration: 4.590s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.872 [0.000, 3.000], mean observation: 39.551 [0.000, 142.000], loss: 0.028629, mean_squared_error: 23.244554, mean_q: 5.283356, mean_eps: 0.143924\n",
      "  95255/1000000: episode: 1315, duration: 5.544s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.719 [0.000, 3.000], mean observation: 39.438 [0.000, 142.000], loss: 0.030922, mean_squared_error: 23.326291, mean_q: 5.268051, mean_eps: 0.143142\n",
      "  95343/1000000: episode: 1316, duration: 5.134s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.977 [0.000, 3.000], mean observation: 39.474 [0.000, 142.000], loss: 0.031702, mean_squared_error: 23.302535, mean_q: 5.262790, mean_eps: 0.142313\n",
      "  95474/1000000: episode: 1317, duration: 7.484s, episode steps: 131, steps per second: 18, episode reward: 13.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.931 [0.000, 3.000], mean observation: 39.179 [0.000, 142.000], loss: 0.030720, mean_squared_error: 23.131140, mean_q: 5.260913, mean_eps: 0.141328\n",
      "  95566/1000000: episode: 1318, duration: 5.449s, episode steps: 92, steps per second: 17, episode reward: 12.000, mean reward: 0.130 [0.000, 4.000], mean action: 1.924 [0.000, 3.000], mean observation: 39.534 [0.000, 142.000], loss: 0.027434, mean_squared_error: 23.218782, mean_q: 5.264216, mean_eps: 0.140324\n",
      "  95656/1000000: episode: 1319, duration: 5.293s, episode steps: 90, steps per second: 17, episode reward: 6.000, mean reward: 0.067 [0.000, 1.000], mean action: 1.778 [0.000, 3.000], mean observation: 39.474 [0.000, 142.000], loss: 0.024460, mean_squared_error: 23.439695, mean_q: 5.323854, mean_eps: 0.139505\n",
      "  95760/1000000: episode: 1320, duration: 6.059s, episode steps: 104, steps per second: 17, episode reward: 10.000, mean reward: 0.096 [0.000, 4.000], mean action: 2.048 [0.000, 3.000], mean observation: 39.396 [0.000, 142.000], loss: 0.024458, mean_squared_error: 23.925932, mean_q: 5.389704, mean_eps: 0.138632\n",
      "  95851/1000000: episode: 1321, duration: 5.287s, episode steps: 91, steps per second: 17, episode reward: 9.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.846 [0.000, 3.000], mean observation: 39.467 [0.000, 142.000], loss: 0.029671, mean_squared_error: 23.230680, mean_q: 5.293028, mean_eps: 0.137755\n",
      "  95954/1000000: episode: 1322, duration: 5.907s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 2.262 [0.000, 3.000], mean observation: 39.308 [0.000, 142.000], loss: 0.023678, mean_squared_error: 23.726717, mean_q: 5.346982, mean_eps: 0.136882\n",
      "  96018/1000000: episode: 1323, duration: 3.768s, episode steps: 64, steps per second: 17, episode reward: 4.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.641 [0.000, 3.000], mean observation: 39.629 [0.000, 142.000], loss: 0.025339, mean_squared_error: 23.500075, mean_q: 5.315914, mean_eps: 0.136130\n",
      "  96102/1000000: episode: 1324, duration: 4.920s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 2.036 [0.000, 3.000], mean observation: 39.527 [0.000, 142.000], loss: 0.029265, mean_squared_error: 23.994794, mean_q: 5.382755, mean_eps: 0.135464\n",
      "  96174/1000000: episode: 1325, duration: 4.160s, episode steps: 72, steps per second: 17, episode reward: 8.000, mean reward: 0.111 [0.000, 4.000], mean action: 1.847 [0.000, 3.000], mean observation: 39.571 [0.000, 142.000], loss: 0.026870, mean_squared_error: 24.191060, mean_q: 5.419507, mean_eps: 0.134762\n",
      "  96272/1000000: episode: 1326, duration: 5.661s, episode steps: 98, steps per second: 17, episode reward: 13.000, mean reward: 0.133 [0.000, 4.000], mean action: 1.857 [0.000, 3.000], mean observation: 39.437 [0.000, 142.000], loss: 0.029792, mean_squared_error: 23.863185, mean_q: 5.367068, mean_eps: 0.133997\n",
      "  96371/1000000: episode: 1327, duration: 5.669s, episode steps: 99, steps per second: 17, episode reward: 10.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.405 [0.000, 142.000], loss: 0.030721, mean_squared_error: 23.721518, mean_q: 5.361105, mean_eps: 0.133111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  96445/1000000: episode: 1328, duration: 4.289s, episode steps: 74, steps per second: 17, episode reward: 8.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.959 [0.000, 3.000], mean observation: 39.562 [0.000, 142.000], loss: 0.027379, mean_squared_error: 23.578450, mean_q: 5.327236, mean_eps: 0.132332\n",
      "  96539/1000000: episode: 1329, duration: 5.394s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.862 [0.000, 3.000], mean observation: 39.408 [0.000, 142.000], loss: 0.026578, mean_squared_error: 23.846751, mean_q: 5.355601, mean_eps: 0.131576\n",
      "  96632/1000000: episode: 1330, duration: 5.331s, episode steps: 93, steps per second: 17, episode reward: 13.000, mean reward: 0.140 [0.000, 4.000], mean action: 2.043 [0.000, 3.000], mean observation: 39.430 [0.000, 142.000], loss: 0.028084, mean_squared_error: 24.070963, mean_q: 5.387333, mean_eps: 0.130735\n",
      "  96733/1000000: episode: 1331, duration: 5.932s, episode steps: 101, steps per second: 17, episode reward: 10.000, mean reward: 0.099 [0.000, 4.000], mean action: 2.010 [0.000, 3.000], mean observation: 39.361 [0.000, 142.000], loss: 0.030769, mean_squared_error: 23.847768, mean_q: 5.362402, mean_eps: 0.129862\n",
      "  96830/1000000: episode: 1332, duration: 5.680s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.876 [0.000, 3.000], mean observation: 39.393 [0.000, 142.000], loss: 0.025320, mean_squared_error: 24.330403, mean_q: 5.431927, mean_eps: 0.128971\n",
      "  96914/1000000: episode: 1333, duration: 4.808s, episode steps: 84, steps per second: 17, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.857 [0.000, 3.000], mean observation: 39.496 [0.000, 142.000], loss: 0.029037, mean_squared_error: 24.254144, mean_q: 5.405618, mean_eps: 0.128156\n",
      "  97022/1000000: episode: 1334, duration: 6.255s, episode steps: 108, steps per second: 17, episode reward: 14.000, mean reward: 0.130 [0.000, 4.000], mean action: 1.806 [0.000, 3.000], mean observation: 39.338 [0.000, 142.000], loss: 0.033398, mean_squared_error: 24.038906, mean_q: 5.392529, mean_eps: 0.127293\n",
      "  97125/1000000: episode: 1335, duration: 5.974s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.942 [0.000, 3.000], mean observation: 39.359 [0.000, 142.000], loss: 0.029989, mean_squared_error: 23.948351, mean_q: 5.362563, mean_eps: 0.126343\n",
      "  97191/1000000: episode: 1336, duration: 3.779s, episode steps: 66, steps per second: 17, episode reward: 7.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.924 [0.000, 3.000], mean observation: 39.605 [0.000, 142.000], loss: 0.033212, mean_squared_error: 24.051863, mean_q: 5.395216, mean_eps: 0.125582\n",
      "  97272/1000000: episode: 1337, duration: 4.668s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 1.642 [0.000, 3.000], mean observation: 39.511 [0.000, 142.000], loss: 0.027759, mean_squared_error: 24.218722, mean_q: 5.398323, mean_eps: 0.124921\n",
      "  97354/1000000: episode: 1338, duration: 4.739s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 2.122 [0.000, 3.000], mean observation: 39.523 [0.000, 142.000], loss: 0.029428, mean_squared_error: 24.151130, mean_q: 5.377275, mean_eps: 0.124187\n",
      "  97419/1000000: episode: 1339, duration: 3.761s, episode steps: 65, steps per second: 17, episode reward: 3.000, mean reward: 0.046 [0.000, 1.000], mean action: 2.108 [0.000, 3.000], mean observation: 39.700 [0.000, 142.000], loss: 0.031721, mean_squared_error: 23.689074, mean_q: 5.329037, mean_eps: 0.123526\n",
      "  97533/1000000: episode: 1340, duration: 6.559s, episode steps: 114, steps per second: 17, episode reward: 12.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.912 [0.000, 3.000], mean observation: 39.230 [0.000, 142.000], loss: 0.029284, mean_squared_error: 24.122061, mean_q: 5.390455, mean_eps: 0.122720\n",
      "  97630/1000000: episode: 1341, duration: 5.660s, episode steps: 97, steps per second: 17, episode reward: 13.000, mean reward: 0.134 [0.000, 4.000], mean action: 1.825 [0.000, 3.000], mean observation: 39.445 [0.000, 142.000], loss: 0.027083, mean_squared_error: 24.286356, mean_q: 5.415791, mean_eps: 0.121771\n",
      "  97715/1000000: episode: 1342, duration: 4.805s, episode steps: 85, steps per second: 18, episode reward: 12.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.682 [0.000, 3.000], mean observation: 39.519 [0.000, 142.000], loss: 0.028390, mean_squared_error: 24.191839, mean_q: 5.409199, mean_eps: 0.120952\n",
      "  97809/1000000: episode: 1343, duration: 5.474s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.755 [0.000, 3.000], mean observation: 39.417 [0.000, 142.000], loss: 0.033032, mean_squared_error: 24.132203, mean_q: 5.394285, mean_eps: 0.120146\n",
      "  97890/1000000: episode: 1344, duration: 4.721s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 1.926 [0.000, 3.000], mean observation: 39.504 [0.000, 142.000], loss: 0.024777, mean_squared_error: 24.377275, mean_q: 5.434601, mean_eps: 0.119359\n",
      "  97995/1000000: episode: 1345, duration: 6.081s, episode steps: 105, steps per second: 17, episode reward: 11.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.038 [0.000, 3.000], mean observation: 39.311 [0.000, 142.000], loss: 0.027236, mean_squared_error: 25.211591, mean_q: 5.540661, mean_eps: 0.118522\n",
      "  98082/1000000: episode: 1346, duration: 4.983s, episode steps: 87, steps per second: 17, episode reward: 12.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.161 [0.000, 3.000], mean observation: 39.520 [0.000, 142.000], loss: 0.026408, mean_squared_error: 24.071178, mean_q: 5.392736, mean_eps: 0.117658\n",
      "  98152/1000000: episode: 1347, duration: 4.043s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 1.757 [0.000, 3.000], mean observation: 39.553 [0.000, 142.000], loss: 0.034063, mean_squared_error: 25.091129, mean_q: 5.520549, mean_eps: 0.116951\n",
      "  98248/1000000: episode: 1348, duration: 5.593s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.958 [0.000, 3.000], mean observation: 39.425 [0.000, 142.000], loss: 0.030669, mean_squared_error: 25.058270, mean_q: 5.511762, mean_eps: 0.116204\n",
      "  98343/1000000: episode: 1349, duration: 5.428s, episode steps: 95, steps per second: 18, episode reward: 6.000, mean reward: 0.063 [0.000, 1.000], mean action: 1.884 [0.000, 3.000], mean observation: 39.448 [0.000, 142.000], loss: 0.028232, mean_squared_error: 24.082350, mean_q: 5.374286, mean_eps: 0.115345\n",
      "  98426/1000000: episode: 1350, duration: 4.904s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 2.096 [0.000, 3.000], mean observation: 39.504 [0.000, 142.000], loss: 0.024936, mean_squared_error: 24.676331, mean_q: 5.463467, mean_eps: 0.114544\n",
      "  98537/1000000: episode: 1351, duration: 6.399s, episode steps: 111, steps per second: 17, episode reward: 15.000, mean reward: 0.135 [0.000, 4.000], mean action: 2.072 [0.000, 3.000], mean observation: 39.172 [0.000, 142.000], loss: 0.030444, mean_squared_error: 24.481442, mean_q: 5.449501, mean_eps: 0.113671\n",
      "  98619/1000000: episode: 1352, duration: 4.737s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.963 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.030186, mean_squared_error: 25.359296, mean_q: 5.559062, mean_eps: 0.112802\n",
      "  98697/1000000: episode: 1353, duration: 4.508s, episode steps: 78, steps per second: 17, episode reward: 8.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.718 [0.000, 3.000], mean observation: 39.562 [0.000, 142.000], loss: 0.033208, mean_squared_error: 25.303414, mean_q: 5.557864, mean_eps: 0.112083\n",
      "  98779/1000000: episode: 1354, duration: 4.645s, episode steps: 82, steps per second: 18, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 2.195 [0.000, 3.000], mean observation: 39.507 [0.000, 142.000], loss: 0.028642, mean_squared_error: 24.776285, mean_q: 5.484058, mean_eps: 0.111362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  98861/1000000: episode: 1355, duration: 4.673s, episode steps: 82, steps per second: 18, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.951 [0.000, 3.000], mean observation: 39.502 [0.000, 142.000], loss: 0.024970, mean_squared_error: 24.840837, mean_q: 5.492832, mean_eps: 0.110624\n",
      "  98943/1000000: episode: 1356, duration: 4.712s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.988 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.027630, mean_squared_error: 24.721167, mean_q: 5.466335, mean_eps: 0.109886\n",
      "  99050/1000000: episode: 1357, duration: 6.126s, episode steps: 107, steps per second: 17, episode reward: 7.000, mean reward: 0.065 [0.000, 1.000], mean action: 2.150 [0.000, 3.000], mean observation: 39.393 [0.000, 142.000], loss: 0.026972, mean_squared_error: 25.239382, mean_q: 5.530905, mean_eps: 0.109036\n",
      "  99132/1000000: episode: 1358, duration: 4.772s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.915 [0.000, 3.000], mean observation: 39.498 [0.000, 142.000], loss: 0.025631, mean_squared_error: 25.400174, mean_q: 5.540316, mean_eps: 0.108185\n",
      "  99216/1000000: episode: 1359, duration: 4.758s, episode steps: 84, steps per second: 18, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.762 [0.000, 3.000], mean observation: 39.525 [0.000, 142.000], loss: 0.033202, mean_squared_error: 25.058432, mean_q: 5.518727, mean_eps: 0.107438\n",
      "  99310/1000000: episode: 1360, duration: 5.493s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.713 [0.000, 3.000], mean observation: 39.422 [0.000, 142.000], loss: 0.029181, mean_squared_error: 26.024998, mean_q: 5.633733, mean_eps: 0.106637\n",
      "  99377/1000000: episode: 1361, duration: 3.789s, episode steps: 67, steps per second: 18, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 2.030 [0.000, 3.000], mean observation: 39.626 [0.000, 142.000], loss: 0.026960, mean_squared_error: 25.139178, mean_q: 5.507884, mean_eps: 0.105913\n",
      "  99468/1000000: episode: 1362, duration: 5.368s, episode steps: 91, steps per second: 17, episode reward: 9.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.901 [0.000, 3.000], mean observation: 39.551 [0.000, 142.000], loss: 0.034643, mean_squared_error: 25.603299, mean_q: 5.569675, mean_eps: 0.105202\n",
      "  99585/1000000: episode: 1363, duration: 6.817s, episode steps: 117, steps per second: 17, episode reward: 12.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.128 [0.000, 3.000], mean observation: 39.198 [0.000, 142.000], loss: 0.029588, mean_squared_error: 26.062627, mean_q: 5.649777, mean_eps: 0.104266\n",
      "  99667/1000000: episode: 1364, duration: 4.701s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.939 [0.000, 3.000], mean observation: 39.514 [0.000, 142.000], loss: 0.027060, mean_squared_error: 25.614976, mean_q: 5.594147, mean_eps: 0.103370\n",
      "  99774/1000000: episode: 1365, duration: 6.161s, episode steps: 107, steps per second: 17, episode reward: 15.000, mean reward: 0.140 [0.000, 4.000], mean action: 2.065 [0.000, 3.000], mean observation: 39.243 [0.000, 142.000], loss: 0.026399, mean_squared_error: 25.625324, mean_q: 5.583917, mean_eps: 0.102520\n",
      "  99864/1000000: episode: 1366, duration: 5.237s, episode steps: 90, steps per second: 17, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 2.033 [0.000, 3.000], mean observation: 39.407 [0.000, 142.000], loss: 0.026124, mean_squared_error: 25.397936, mean_q: 5.568817, mean_eps: 0.101633\n",
      "  99967/1000000: episode: 1367, duration: 5.858s, episode steps: 103, steps per second: 18, episode reward: 11.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.971 [0.000, 3.000], mean observation: 39.266 [0.000, 142.000], loss: 0.033281, mean_squared_error: 25.321000, mean_q: 5.520778, mean_eps: 0.100765\n",
      " 100053/1000000: episode: 1368, duration: 4.988s, episode steps: 86, steps per second: 17, episode reward: 9.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.942 [0.000, 3.000], mean observation: 39.489 [0.000, 142.000], loss: 0.028844, mean_squared_error: 25.164588, mean_q: 5.516521, mean_eps: 0.100059\n",
      " 100141/1000000: episode: 1369, duration: 5.032s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.580 [0.000, 3.000], mean observation: 39.470 [0.000, 142.000], loss: 0.027560, mean_squared_error: 25.766806, mean_q: 5.595968, mean_eps: 0.100000\n",
      " 100211/1000000: episode: 1370, duration: 4.019s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 2.071 [0.000, 3.000], mean observation: 39.550 [0.000, 142.000], loss: 0.027988, mean_squared_error: 24.934835, mean_q: 5.465757, mean_eps: 0.100000\n",
      " 100293/1000000: episode: 1371, duration: 4.667s, episode steps: 82, steps per second: 18, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 2.061 [0.000, 3.000], mean observation: 39.512 [0.000, 142.000], loss: 0.027029, mean_squared_error: 25.298166, mean_q: 5.536876, mean_eps: 0.100000\n",
      " 100377/1000000: episode: 1372, duration: 4.719s, episode steps: 84, steps per second: 18, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.469 [0.000, 142.000], loss: 0.031502, mean_squared_error: 25.650980, mean_q: 5.584102, mean_eps: 0.100000\n",
      " 100444/1000000: episode: 1373, duration: 3.805s, episode steps: 67, steps per second: 18, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 2.060 [0.000, 3.000], mean observation: 39.680 [0.000, 142.000], loss: 0.024843, mean_squared_error: 26.020873, mean_q: 5.627902, mean_eps: 0.100000\n",
      " 100534/1000000: episode: 1374, duration: 5.146s, episode steps: 90, steps per second: 17, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.431 [0.000, 142.000], loss: 0.028850, mean_squared_error: 25.913023, mean_q: 5.627835, mean_eps: 0.100000\n",
      " 100640/1000000: episode: 1375, duration: 5.907s, episode steps: 106, steps per second: 18, episode reward: 15.000, mean reward: 0.142 [0.000, 4.000], mean action: 2.028 [0.000, 3.000], mean observation: 39.254 [0.000, 142.000], loss: 0.028101, mean_squared_error: 25.416284, mean_q: 5.531884, mean_eps: 0.100000\n",
      " 100716/1000000: episode: 1376, duration: 4.368s, episode steps: 76, steps per second: 17, episode reward: 8.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.868 [0.000, 3.000], mean observation: 39.563 [0.000, 142.000], loss: 0.028037, mean_squared_error: 25.167924, mean_q: 5.502418, mean_eps: 0.100000\n",
      " 100800/1000000: episode: 1377, duration: 4.826s, episode steps: 84, steps per second: 17, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.917 [0.000, 3.000], mean observation: 39.508 [0.000, 142.000], loss: 0.028165, mean_squared_error: 26.476232, mean_q: 5.678936, mean_eps: 0.100000\n",
      " 100888/1000000: episode: 1378, duration: 5.055s, episode steps: 88, steps per second: 17, episode reward: 10.000, mean reward: 0.114 [0.000, 4.000], mean action: 2.011 [0.000, 3.000], mean observation: 39.373 [0.000, 142.000], loss: 0.030848, mean_squared_error: 25.423219, mean_q: 5.543309, mean_eps: 0.100000\n",
      " 100965/1000000: episode: 1379, duration: 4.488s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.896 [0.000, 3.000], mean observation: 39.561 [0.000, 142.000], loss: 0.028922, mean_squared_error: 25.775151, mean_q: 5.590031, mean_eps: 0.100000\n",
      " 101048/1000000: episode: 1380, duration: 4.763s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 2.012 [0.000, 3.000], mean observation: 39.511 [0.000, 142.000], loss: 0.028027, mean_squared_error: 26.135080, mean_q: 5.639499, mean_eps: 0.100000\n",
      " 101125/1000000: episode: 1381, duration: 4.338s, episode steps: 77, steps per second: 18, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.961 [0.000, 3.000], mean observation: 39.597 [0.000, 142.000], loss: 0.024983, mean_squared_error: 26.213276, mean_q: 5.638659, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 101234/1000000: episode: 1382, duration: 6.196s, episode steps: 109, steps per second: 18, episode reward: 14.000, mean reward: 0.128 [0.000, 4.000], mean action: 1.917 [0.000, 3.000], mean observation: 39.342 [0.000, 142.000], loss: 0.030508, mean_squared_error: 26.048898, mean_q: 5.622448, mean_eps: 0.100000\n",
      " 101303/1000000: episode: 1383, duration: 4.031s, episode steps: 69, steps per second: 17, episode reward: 11.000, mean reward: 0.159 [0.000, 4.000], mean action: 1.797 [0.000, 3.000], mean observation: 39.543 [0.000, 142.000], loss: 0.028943, mean_squared_error: 26.133599, mean_q: 5.611781, mean_eps: 0.100000\n",
      " 101408/1000000: episode: 1384, duration: 6.103s, episode steps: 105, steps per second: 17, episode reward: 11.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.105 [0.000, 3.000], mean observation: 39.307 [0.000, 142.000], loss: 0.029630, mean_squared_error: 26.396904, mean_q: 5.664710, mean_eps: 0.100000\n",
      " 101489/1000000: episode: 1385, duration: 4.679s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 1.963 [0.000, 3.000], mean observation: 39.507 [0.000, 142.000], loss: 0.026973, mean_squared_error: 26.039872, mean_q: 5.610915, mean_eps: 0.100000\n",
      " 101591/1000000: episode: 1386, duration: 5.954s, episode steps: 102, steps per second: 17, episode reward: 10.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.676 [0.000, 3.000], mean observation: 39.392 [0.000, 142.000], loss: 0.026507, mean_squared_error: 26.310328, mean_q: 5.649913, mean_eps: 0.100000\n",
      " 101673/1000000: episode: 1387, duration: 4.710s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.890 [0.000, 3.000], mean observation: 39.516 [0.000, 142.000], loss: 0.026290, mean_squared_error: 26.448964, mean_q: 5.670329, mean_eps: 0.100000\n",
      " 101763/1000000: episode: 1388, duration: 5.372s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.867 [0.000, 3.000], mean observation: 39.496 [0.000, 142.000], loss: 0.030992, mean_squared_error: 26.870098, mean_q: 5.726991, mean_eps: 0.100000\n",
      " 101859/1000000: episode: 1389, duration: 5.505s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 2.052 [0.000, 3.000], mean observation: 39.442 [0.000, 142.000], loss: 0.032206, mean_squared_error: 26.160710, mean_q: 5.639540, mean_eps: 0.100000\n",
      " 101943/1000000: episode: 1390, duration: 4.900s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.857 [0.000, 3.000], mean observation: 39.515 [0.000, 142.000], loss: 0.029527, mean_squared_error: 26.078280, mean_q: 5.630508, mean_eps: 0.100000\n",
      " 102081/1000000: episode: 1391, duration: 7.899s, episode steps: 138, steps per second: 17, episode reward: 15.000, mean reward: 0.109 [0.000, 4.000], mean action: 2.123 [0.000, 3.000], mean observation: 38.915 [0.000, 142.000], loss: 0.025712, mean_squared_error: 26.222136, mean_q: 5.625991, mean_eps: 0.100000\n",
      " 102162/1000000: episode: 1392, duration: 4.729s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 1.642 [0.000, 3.000], mean observation: 39.502 [0.000, 142.000], loss: 0.026044, mean_squared_error: 26.971097, mean_q: 5.732535, mean_eps: 0.100000\n",
      " 102252/1000000: episode: 1393, duration: 5.094s, episode steps: 90, steps per second: 18, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 1.967 [0.000, 3.000], mean observation: 39.421 [0.000, 142.000], loss: 0.030761, mean_squared_error: 26.540890, mean_q: 5.673749, mean_eps: 0.100000\n",
      " 102333/1000000: episode: 1394, duration: 4.656s, episode steps: 81, steps per second: 17, episode reward: 5.000, mean reward: 0.062 [0.000, 1.000], mean action: 1.827 [0.000, 3.000], mean observation: 39.577 [0.000, 142.000], loss: 0.029032, mean_squared_error: 26.007217, mean_q: 5.596588, mean_eps: 0.100000\n",
      " 102417/1000000: episode: 1395, duration: 4.745s, episode steps: 84, steps per second: 18, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.869 [0.000, 3.000], mean observation: 39.509 [0.000, 142.000], loss: 0.028474, mean_squared_error: 26.001438, mean_q: 5.603284, mean_eps: 0.100000\n",
      " 102538/1000000: episode: 1396, duration: 6.926s, episode steps: 121, steps per second: 17, episode reward: 12.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.669 [0.000, 3.000], mean observation: 39.134 [0.000, 142.000], loss: 0.034204, mean_squared_error: 26.131028, mean_q: 5.616375, mean_eps: 0.100000\n",
      " 102640/1000000: episode: 1397, duration: 5.895s, episode steps: 102, steps per second: 17, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.325 [0.000, 142.000], loss: 0.026954, mean_squared_error: 26.292106, mean_q: 5.642909, mean_eps: 0.100000\n",
      " 102720/1000000: episode: 1398, duration: 4.569s, episode steps: 80, steps per second: 18, episode reward: 9.000, mean reward: 0.113 [0.000, 4.000], mean action: 1.900 [0.000, 3.000], mean observation: 39.509 [0.000, 142.000], loss: 0.027780, mean_squared_error: 26.106777, mean_q: 5.615094, mean_eps: 0.100000\n",
      " 102830/1000000: episode: 1399, duration: 6.219s, episode steps: 110, steps per second: 18, episode reward: 11.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.573 [0.000, 3.000], mean observation: 39.249 [0.000, 142.000], loss: 0.028131, mean_squared_error: 26.894403, mean_q: 5.731129, mean_eps: 0.100000\n",
      " 102926/1000000: episode: 1400, duration: 5.517s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.938 [0.000, 3.000], mean observation: 39.423 [0.000, 142.000], loss: 0.035218, mean_squared_error: 26.643885, mean_q: 5.687004, mean_eps: 0.100000\n",
      " 103016/1000000: episode: 1401, duration: 5.177s, episode steps: 90, steps per second: 17, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 2.011 [0.000, 3.000], mean observation: 39.417 [0.000, 142.000], loss: 0.026968, mean_squared_error: 27.071595, mean_q: 5.724614, mean_eps: 0.100000\n",
      " 103104/1000000: episode: 1402, duration: 5.105s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.886 [0.000, 3.000], mean observation: 39.490 [0.000, 142.000], loss: 0.029188, mean_squared_error: 27.260894, mean_q: 5.764068, mean_eps: 0.100000\n",
      " 103210/1000000: episode: 1403, duration: 6.026s, episode steps: 106, steps per second: 18, episode reward: 14.000, mean reward: 0.132 [0.000, 4.000], mean action: 1.604 [0.000, 3.000], mean observation: 39.314 [0.000, 142.000], loss: 0.030811, mean_squared_error: 27.107516, mean_q: 5.727694, mean_eps: 0.100000\n",
      " 103304/1000000: episode: 1404, duration: 5.396s, episode steps: 94, steps per second: 17, episode reward: 10.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.894 [0.000, 3.000], mean observation: 39.416 [0.000, 142.000], loss: 0.030597, mean_squared_error: 26.524258, mean_q: 5.668319, mean_eps: 0.100000\n",
      " 103386/1000000: episode: 1405, duration: 4.663s, episode steps: 82, steps per second: 18, episode reward: 9.000, mean reward: 0.110 [0.000, 4.000], mean action: 2.122 [0.000, 3.000], mean observation: 39.506 [0.000, 142.000], loss: 0.025054, mean_squared_error: 27.060114, mean_q: 5.735362, mean_eps: 0.100000\n",
      " 103489/1000000: episode: 1406, duration: 5.955s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.845 [0.000, 3.000], mean observation: 39.307 [0.000, 142.000], loss: 0.026626, mean_squared_error: 27.247902, mean_q: 5.764741, mean_eps: 0.100000\n",
      " 103571/1000000: episode: 1407, duration: 4.757s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.805 [0.000, 3.000], mean observation: 39.499 [0.000, 142.000], loss: 0.031071, mean_squared_error: 26.872485, mean_q: 5.691599, mean_eps: 0.100000\n",
      " 103680/1000000: episode: 1408, duration: 6.266s, episode steps: 109, steps per second: 17, episode reward: 12.000, mean reward: 0.110 [0.000, 4.000], mean action: 2.101 [0.000, 3.000], mean observation: 39.150 [0.000, 142.000], loss: 0.028784, mean_squared_error: 26.829436, mean_q: 5.710634, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 103745/1000000: episode: 1409, duration: 3.748s, episode steps: 65, steps per second: 17, episode reward: 7.000, mean reward: 0.108 [0.000, 4.000], mean action: 2.015 [0.000, 3.000], mean observation: 39.633 [0.000, 142.000], loss: 0.028259, mean_squared_error: 27.073283, mean_q: 5.748540, mean_eps: 0.100000\n",
      " 103830/1000000: episode: 1410, duration: 4.879s, episode steps: 85, steps per second: 17, episode reward: 12.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.976 [0.000, 3.000], mean observation: 39.511 [0.000, 142.000], loss: 0.026881, mean_squared_error: 27.252870, mean_q: 5.761135, mean_eps: 0.100000\n",
      " 103934/1000000: episode: 1411, duration: 6.070s, episode steps: 104, steps per second: 17, episode reward: 14.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.990 [0.000, 3.000], mean observation: 39.306 [0.000, 142.000], loss: 0.029466, mean_squared_error: 27.328943, mean_q: 5.744739, mean_eps: 0.100000\n",
      " 104020/1000000: episode: 1412, duration: 4.990s, episode steps: 86, steps per second: 17, episode reward: 9.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.105 [0.000, 3.000], mean observation: 39.484 [0.000, 142.000], loss: 0.030385, mean_squared_error: 27.278359, mean_q: 5.750233, mean_eps: 0.100000\n",
      " 104117/1000000: episode: 1413, duration: 5.578s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.072 [0.000, 3.000], mean observation: 39.397 [0.000, 142.000], loss: 0.027819, mean_squared_error: 27.099931, mean_q: 5.744459, mean_eps: 0.100000\n",
      " 104207/1000000: episode: 1414, duration: 5.141s, episode steps: 90, steps per second: 18, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.867 [0.000, 3.000], mean observation: 39.478 [0.000, 142.000], loss: 0.025377, mean_squared_error: 26.983055, mean_q: 5.727942, mean_eps: 0.100000\n",
      " 104301/1000000: episode: 1415, duration: 5.493s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.064 [0.000, 3.000], mean observation: 39.428 [0.000, 142.000], loss: 0.024407, mean_squared_error: 27.495100, mean_q: 5.803707, mean_eps: 0.100000\n",
      " 104396/1000000: episode: 1416, duration: 5.471s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.021 [0.000, 3.000], mean observation: 39.432 [0.000, 142.000], loss: 0.027626, mean_squared_error: 26.891945, mean_q: 5.695523, mean_eps: 0.100000\n",
      " 104466/1000000: episode: 1417, duration: 4.002s, episode steps: 70, steps per second: 17, episode reward: 5.000, mean reward: 0.071 [0.000, 1.000], mean action: 2.129 [0.000, 3.000], mean observation: 39.536 [0.000, 142.000], loss: 0.026540, mean_squared_error: 27.328618, mean_q: 5.751328, mean_eps: 0.100000\n",
      " 104552/1000000: episode: 1418, duration: 5.133s, episode steps: 86, steps per second: 17, episode reward: 9.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.919 [0.000, 3.000], mean observation: 39.497 [0.000, 142.000], loss: 0.030082, mean_squared_error: 27.754566, mean_q: 5.835811, mean_eps: 0.100000\n",
      " 104648/1000000: episode: 1419, duration: 5.555s, episode steps: 96, steps per second: 17, episode reward: 10.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.021 [0.000, 3.000], mean observation: 39.398 [0.000, 142.000], loss: 0.025445, mean_squared_error: 27.683485, mean_q: 5.823565, mean_eps: 0.100000\n",
      " 104746/1000000: episode: 1420, duration: 5.548s, episode steps: 98, steps per second: 18, episode reward: 10.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.969 [0.000, 3.000], mean observation: 39.402 [0.000, 142.000], loss: 0.025936, mean_squared_error: 27.109869, mean_q: 5.727322, mean_eps: 0.100000\n",
      " 104831/1000000: episode: 1421, duration: 4.908s, episode steps: 85, steps per second: 17, episode reward: 12.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.882 [0.000, 3.000], mean observation: 39.510 [0.000, 142.000], loss: 0.031028, mean_squared_error: 27.934989, mean_q: 5.843263, mean_eps: 0.100000\n",
      " 104937/1000000: episode: 1422, duration: 5.982s, episode steps: 106, steps per second: 18, episode reward: 11.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.085 [0.000, 3.000], mean observation: 39.285 [0.000, 142.000], loss: 0.030619, mean_squared_error: 27.403531, mean_q: 5.774523, mean_eps: 0.100000\n",
      " 105008/1000000: episode: 1423, duration: 4.125s, episode steps: 71, steps per second: 17, episode reward: 11.000, mean reward: 0.155 [0.000, 4.000], mean action: 1.901 [0.000, 3.000], mean observation: 39.546 [0.000, 142.000], loss: 0.023312, mean_squared_error: 27.782969, mean_q: 5.817849, mean_eps: 0.100000\n",
      " 105104/1000000: episode: 1424, duration: 5.509s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.833 [0.000, 3.000], mean observation: 39.442 [0.000, 142.000], loss: 0.029071, mean_squared_error: 27.506482, mean_q: 5.762990, mean_eps: 0.100000\n",
      " 105199/1000000: episode: 1425, duration: 5.467s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.937 [0.000, 3.000], mean observation: 39.423 [0.000, 142.000], loss: 0.027084, mean_squared_error: 27.345835, mean_q: 5.749454, mean_eps: 0.100000\n",
      " 105300/1000000: episode: 1426, duration: 5.744s, episode steps: 101, steps per second: 18, episode reward: 14.000, mean reward: 0.139 [0.000, 4.000], mean action: 1.792 [0.000, 3.000], mean observation: 39.341 [0.000, 142.000], loss: 0.027744, mean_squared_error: 27.491609, mean_q: 5.771086, mean_eps: 0.100000\n",
      " 105385/1000000: episode: 1427, duration: 4.868s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.988 [0.000, 3.000], mean observation: 39.480 [0.000, 142.000], loss: 0.027609, mean_squared_error: 28.233136, mean_q: 5.852013, mean_eps: 0.100000\n",
      " 105520/1000000: episode: 1428, duration: 7.728s, episode steps: 135, steps per second: 17, episode reward: 13.000, mean reward: 0.096 [0.000, 4.000], mean action: 2.089 [0.000, 3.000], mean observation: 39.170 [0.000, 142.000], loss: 0.027269, mean_squared_error: 27.951077, mean_q: 5.838773, mean_eps: 0.100000\n",
      " 105604/1000000: episode: 1429, duration: 4.759s, episode steps: 84, steps per second: 18, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.988 [0.000, 3.000], mean observation: 39.512 [0.000, 142.000], loss: 0.027469, mean_squared_error: 28.026869, mean_q: 5.861483, mean_eps: 0.100000\n",
      " 105686/1000000: episode: 1430, duration: 4.659s, episode steps: 82, steps per second: 18, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.780 [0.000, 3.000], mean observation: 39.507 [0.000, 142.000], loss: 0.029035, mean_squared_error: 28.121959, mean_q: 5.839646, mean_eps: 0.100000\n",
      " 105769/1000000: episode: 1431, duration: 4.805s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.916 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.029355, mean_squared_error: 28.018826, mean_q: 5.838124, mean_eps: 0.100000\n",
      " 105863/1000000: episode: 1432, duration: 5.447s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.043 [0.000, 3.000], mean observation: 39.430 [0.000, 142.000], loss: 0.032033, mean_squared_error: 28.149981, mean_q: 5.838488, mean_eps: 0.100000\n",
      " 106013/1000000: episode: 1433, duration: 8.623s, episode steps: 150, steps per second: 17, episode reward: 16.000, mean reward: 0.107 [0.000, 4.000], mean action: 2.380 [0.000, 3.000], mean observation: 39.118 [0.000, 142.000], loss: 0.029018, mean_squared_error: 27.975790, mean_q: 5.833121, mean_eps: 0.100000\n",
      " 106119/1000000: episode: 1434, duration: 6.176s, episode steps: 106, steps per second: 17, episode reward: 14.000, mean reward: 0.132 [0.000, 4.000], mean action: 2.038 [0.000, 3.000], mean observation: 39.321 [0.000, 142.000], loss: 0.029167, mean_squared_error: 28.070217, mean_q: 5.847864, mean_eps: 0.100000\n",
      " 106202/1000000: episode: 1435, duration: 4.761s, episode steps: 83, steps per second: 17, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 1.867 [0.000, 3.000], mean observation: 39.517 [0.000, 142.000], loss: 0.026152, mean_squared_error: 28.388099, mean_q: 5.870967, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 106302/1000000: episode: 1436, duration: 5.714s, episode steps: 100, steps per second: 17, episode reward: 10.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.890 [0.000, 3.000], mean observation: 39.373 [0.000, 142.000], loss: 0.024042, mean_squared_error: 27.940833, mean_q: 5.825455, mean_eps: 0.100000\n",
      " 106391/1000000: episode: 1437, duration: 4.949s, episode steps: 89, steps per second: 18, episode reward: 13.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.989 [0.000, 3.000], mean observation: 39.414 [0.000, 142.000], loss: 0.026897, mean_squared_error: 27.904599, mean_q: 5.825568, mean_eps: 0.100000\n",
      " 106482/1000000: episode: 1438, duration: 5.227s, episode steps: 91, steps per second: 17, episode reward: 9.000, mean reward: 0.099 [0.000, 4.000], mean action: 1.560 [0.000, 3.000], mean observation: 39.500 [0.000, 142.000], loss: 0.030671, mean_squared_error: 28.103115, mean_q: 5.835249, mean_eps: 0.100000\n",
      " 106578/1000000: episode: 1439, duration: 5.461s, episode steps: 96, steps per second: 18, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.885 [0.000, 3.000], mean observation: 39.436 [0.000, 142.000], loss: 0.024804, mean_squared_error: 28.220296, mean_q: 5.863996, mean_eps: 0.100000\n",
      " 106663/1000000: episode: 1440, duration: 4.948s, episode steps: 85, steps per second: 17, episode reward: 12.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.882 [0.000, 3.000], mean observation: 39.511 [0.000, 142.000], loss: 0.033490, mean_squared_error: 28.309744, mean_q: 5.874266, mean_eps: 0.100000\n",
      " 106757/1000000: episode: 1441, duration: 5.336s, episode steps: 94, steps per second: 18, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.872 [0.000, 3.000], mean observation: 39.422 [0.000, 142.000], loss: 0.034559, mean_squared_error: 28.662512, mean_q: 5.898715, mean_eps: 0.100000\n",
      " 106846/1000000: episode: 1442, duration: 5.114s, episode steps: 89, steps per second: 17, episode reward: 13.000, mean reward: 0.146 [0.000, 4.000], mean action: 2.090 [0.000, 3.000], mean observation: 39.421 [0.000, 142.000], loss: 0.027868, mean_squared_error: 28.251321, mean_q: 5.868902, mean_eps: 0.100000\n",
      " 106961/1000000: episode: 1443, duration: 6.500s, episode steps: 115, steps per second: 18, episode reward: 15.000, mean reward: 0.130 [0.000, 4.000], mean action: 2.139 [0.000, 3.000], mean observation: 39.182 [0.000, 142.000], loss: 0.027890, mean_squared_error: 28.609588, mean_q: 5.908567, mean_eps: 0.100000\n",
      " 107033/1000000: episode: 1444, duration: 4.135s, episode steps: 72, steps per second: 17, episode reward: 11.000, mean reward: 0.153 [0.000, 4.000], mean action: 1.931 [0.000, 3.000], mean observation: 39.545 [0.000, 142.000], loss: 0.032294, mean_squared_error: 28.283209, mean_q: 5.851347, mean_eps: 0.100000\n",
      " 107129/1000000: episode: 1445, duration: 5.544s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.844 [0.000, 3.000], mean observation: 39.432 [0.000, 142.000], loss: 0.026879, mean_squared_error: 28.769956, mean_q: 5.915970, mean_eps: 0.100000\n",
      " 107221/1000000: episode: 1446, duration: 5.277s, episode steps: 92, steps per second: 17, episode reward: 13.000, mean reward: 0.141 [0.000, 4.000], mean action: 2.022 [0.000, 3.000], mean observation: 39.412 [0.000, 142.000], loss: 0.025420, mean_squared_error: 28.568405, mean_q: 5.908224, mean_eps: 0.100000\n",
      " 107356/1000000: episode: 1447, duration: 7.708s, episode steps: 135, steps per second: 18, episode reward: 14.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.630 [0.000, 3.000], mean observation: 39.043 [0.000, 142.000], loss: 0.025315, mean_squared_error: 28.076340, mean_q: 5.839622, mean_eps: 0.100000\n",
      " 107446/1000000: episode: 1448, duration: 5.142s, episode steps: 90, steps per second: 18, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 2.011 [0.000, 3.000], mean observation: 39.429 [0.000, 142.000], loss: 0.028092, mean_squared_error: 28.943381, mean_q: 5.925606, mean_eps: 0.100000\n",
      " 107530/1000000: episode: 1449, duration: 4.896s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.988 [0.000, 3.000], mean observation: 39.515 [0.000, 142.000], loss: 0.030680, mean_squared_error: 28.564739, mean_q: 5.907716, mean_eps: 0.100000\n",
      " 107620/1000000: episode: 1450, duration: 5.250s, episode steps: 90, steps per second: 17, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 1.800 [0.000, 3.000], mean observation: 39.427 [0.000, 142.000], loss: 0.032136, mean_squared_error: 28.430053, mean_q: 5.884377, mean_eps: 0.100000\n",
      " 107720/1000000: episode: 1451, duration: 5.799s, episode steps: 100, steps per second: 17, episode reward: 10.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.930 [0.000, 3.000], mean observation: 39.379 [0.000, 142.000], loss: 0.030101, mean_squared_error: 29.063091, mean_q: 5.946414, mean_eps: 0.100000\n",
      " 107790/1000000: episode: 1452, duration: 4.078s, episode steps: 70, steps per second: 17, episode reward: 11.000, mean reward: 0.157 [0.000, 4.000], mean action: 2.014 [0.000, 3.000], mean observation: 39.554 [0.000, 142.000], loss: 0.029090, mean_squared_error: 28.854746, mean_q: 5.932216, mean_eps: 0.100000\n",
      " 107864/1000000: episode: 1453, duration: 4.341s, episode steps: 74, steps per second: 17, episode reward: 5.000, mean reward: 0.068 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.577 [0.000, 142.000], loss: 0.033555, mean_squared_error: 29.213793, mean_q: 5.946015, mean_eps: 0.100000\n",
      " 107947/1000000: episode: 1454, duration: 4.739s, episode steps: 83, steps per second: 18, episode reward: 12.000, mean reward: 0.145 [0.000, 4.000], mean action: 2.060 [0.000, 3.000], mean observation: 39.518 [0.000, 142.000], loss: 0.028817, mean_squared_error: 29.246567, mean_q: 6.009156, mean_eps: 0.100000\n",
      " 108026/1000000: episode: 1455, duration: 4.515s, episode steps: 79, steps per second: 17, episode reward: 8.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.696 [0.000, 3.000], mean observation: 39.569 [0.000, 142.000], loss: 0.032777, mean_squared_error: 28.615943, mean_q: 5.882159, mean_eps: 0.100000\n",
      " 108129/1000000: episode: 1456, duration: 5.931s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.932 [0.000, 3.000], mean observation: 39.343 [0.000, 142.000], loss: 0.028803, mean_squared_error: 28.829645, mean_q: 5.922392, mean_eps: 0.100000\n",
      " 108217/1000000: episode: 1457, duration: 5.086s, episode steps: 88, steps per second: 17, episode reward: 9.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.909 [0.000, 3.000], mean observation: 39.508 [0.000, 142.000], loss: 0.026625, mean_squared_error: 29.302107, mean_q: 5.985398, mean_eps: 0.100000\n",
      " 108311/1000000: episode: 1458, duration: 5.439s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.904 [0.000, 3.000], mean observation: 39.406 [0.000, 142.000], loss: 0.029030, mean_squared_error: 28.984441, mean_q: 5.948000, mean_eps: 0.100000\n",
      " 108406/1000000: episode: 1459, duration: 5.470s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.779 [0.000, 3.000], mean observation: 39.427 [0.000, 142.000], loss: 0.028693, mean_squared_error: 29.059925, mean_q: 5.969208, mean_eps: 0.100000\n",
      " 108502/1000000: episode: 1460, duration: 5.561s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.719 [0.000, 3.000], mean observation: 39.433 [0.000, 142.000], loss: 0.030478, mean_squared_error: 29.129767, mean_q: 5.958349, mean_eps: 0.100000\n",
      " 108598/1000000: episode: 1461, duration: 5.627s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.604 [0.000, 3.000], mean observation: 39.438 [0.000, 142.000], loss: 0.025825, mean_squared_error: 29.443148, mean_q: 6.002128, mean_eps: 0.100000\n",
      " 108667/1000000: episode: 1462, duration: 3.898s, episode steps: 69, steps per second: 18, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 2.232 [0.000, 3.000], mean observation: 39.609 [0.000, 142.000], loss: 0.025707, mean_squared_error: 29.071481, mean_q: 5.939911, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 108758/1000000: episode: 1463, duration: 5.298s, episode steps: 91, steps per second: 17, episode reward: 13.000, mean reward: 0.143 [0.000, 4.000], mean action: 2.198 [0.000, 3.000], mean observation: 39.413 [0.000, 142.000], loss: 0.028036, mean_squared_error: 29.192451, mean_q: 5.976225, mean_eps: 0.100000\n",
      " 108854/1000000: episode: 1464, duration: 5.664s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.927 [0.000, 3.000], mean observation: 39.447 [0.000, 142.000], loss: 0.027552, mean_squared_error: 29.522635, mean_q: 6.000774, mean_eps: 0.100000\n",
      " 108949/1000000: episode: 1465, duration: 5.547s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.758 [0.000, 3.000], mean observation: 39.420 [0.000, 142.000], loss: 0.031982, mean_squared_error: 29.770968, mean_q: 6.024879, mean_eps: 0.100000\n",
      " 109084/1000000: episode: 1466, duration: 7.795s, episode steps: 135, steps per second: 17, episode reward: 17.000, mean reward: 0.126 [0.000, 4.000], mean action: 2.170 [0.000, 3.000], mean observation: 39.068 [0.000, 142.000], loss: 0.028894, mean_squared_error: 29.868097, mean_q: 6.039453, mean_eps: 0.100000\n",
      " 109221/1000000: episode: 1467, duration: 7.938s, episode steps: 137, steps per second: 17, episode reward: 18.000, mean reward: 0.131 [0.000, 4.000], mean action: 1.934 [0.000, 3.000], mean observation: 38.951 [0.000, 142.000], loss: 0.029197, mean_squared_error: 29.652041, mean_q: 6.021535, mean_eps: 0.100000\n",
      " 109338/1000000: episode: 1468, duration: 6.711s, episode steps: 117, steps per second: 17, episode reward: 16.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.162 [0.000, 3.000], mean observation: 39.190 [0.000, 142.000], loss: 0.029146, mean_squared_error: 29.726724, mean_q: 6.023756, mean_eps: 0.100000\n",
      " 109434/1000000: episode: 1469, duration: 5.455s, episode steps: 96, steps per second: 18, episode reward: 10.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.125 [0.000, 3.000], mean observation: 39.420 [0.000, 142.000], loss: 0.027208, mean_squared_error: 29.420085, mean_q: 5.979842, mean_eps: 0.100000\n",
      " 109534/1000000: episode: 1470, duration: 5.724s, episode steps: 100, steps per second: 17, episode reward: 7.000, mean reward: 0.070 [0.000, 1.000], mean action: 1.770 [0.000, 3.000], mean observation: 39.419 [0.000, 142.000], loss: 0.030696, mean_squared_error: 29.225831, mean_q: 5.978889, mean_eps: 0.100000\n",
      " 109623/1000000: episode: 1471, duration: 5.155s, episode steps: 89, steps per second: 17, episode reward: 13.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.787 [0.000, 3.000], mean observation: 39.417 [0.000, 142.000], loss: 0.032160, mean_squared_error: 30.079041, mean_q: 6.066431, mean_eps: 0.100000\n",
      " 109727/1000000: episode: 1472, duration: 6.035s, episode steps: 104, steps per second: 17, episode reward: 10.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.942 [0.000, 3.000], mean observation: 39.415 [0.000, 142.000], loss: 0.032246, mean_squared_error: 29.652667, mean_q: 6.017048, mean_eps: 0.100000\n",
      " 109846/1000000: episode: 1473, duration: 6.860s, episode steps: 119, steps per second: 17, episode reward: 9.000, mean reward: 0.076 [0.000, 1.000], mean action: 2.042 [0.000, 3.000], mean observation: 39.226 [0.000, 142.000], loss: 0.032123, mean_squared_error: 30.269804, mean_q: 6.084133, mean_eps: 0.100000\n",
      " 109935/1000000: episode: 1474, duration: 5.125s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.888 [0.000, 3.000], mean observation: 39.468 [0.000, 142.000], loss: 0.027260, mean_squared_error: 30.353684, mean_q: 6.093043, mean_eps: 0.100000\n",
      " 110017/1000000: episode: 1475, duration: 4.700s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.514 [0.000, 142.000], loss: 0.027940, mean_squared_error: 30.656817, mean_q: 6.123044, mean_eps: 0.100000\n",
      " 110114/1000000: episode: 1476, duration: 5.574s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.010 [0.000, 3.000], mean observation: 39.424 [0.000, 142.000], loss: 0.027847, mean_squared_error: 30.570075, mean_q: 6.103295, mean_eps: 0.100000\n",
      " 110217/1000000: episode: 1477, duration: 5.973s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.660 [0.000, 3.000], mean observation: 39.320 [0.000, 142.000], loss: 0.031629, mean_squared_error: 30.344727, mean_q: 6.080601, mean_eps: 0.100000\n",
      " 110312/1000000: episode: 1478, duration: 5.408s, episode steps: 95, steps per second: 18, episode reward: 7.000, mean reward: 0.074 [0.000, 1.000], mean action: 1.716 [0.000, 3.000], mean observation: 39.381 [0.000, 142.000], loss: 0.026852, mean_squared_error: 30.196105, mean_q: 6.049549, mean_eps: 0.100000\n",
      " 110385/1000000: episode: 1479, duration: 4.282s, episode steps: 73, steps per second: 17, episode reward: 8.000, mean reward: 0.110 [0.000, 4.000], mean action: 2.027 [0.000, 3.000], mean observation: 39.578 [0.000, 142.000], loss: 0.035532, mean_squared_error: 30.312620, mean_q: 6.075693, mean_eps: 0.100000\n",
      " 110484/1000000: episode: 1480, duration: 5.620s, episode steps: 99, steps per second: 18, episode reward: 10.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.414 [0.000, 142.000], loss: 0.030828, mean_squared_error: 30.724396, mean_q: 6.152931, mean_eps: 0.100000\n",
      " 110582/1000000: episode: 1481, duration: 5.678s, episode steps: 98, steps per second: 17, episode reward: 14.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.980 [0.000, 3.000], mean observation: 39.353 [0.000, 142.000], loss: 0.029564, mean_squared_error: 30.525969, mean_q: 6.116963, mean_eps: 0.100000\n",
      " 110678/1000000: episode: 1482, duration: 5.571s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.719 [0.000, 3.000], mean observation: 39.424 [0.000, 142.000], loss: 0.028023, mean_squared_error: 30.919901, mean_q: 6.148274, mean_eps: 0.100000\n",
      " 110773/1000000: episode: 1483, duration: 5.478s, episode steps: 95, steps per second: 17, episode reward: 10.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.758 [0.000, 3.000], mean observation: 39.389 [0.000, 142.000], loss: 0.026899, mean_squared_error: 30.565039, mean_q: 6.110180, mean_eps: 0.100000\n",
      " 110869/1000000: episode: 1484, duration: 5.629s, episode steps: 96, steps per second: 17, episode reward: 13.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.990 [0.000, 3.000], mean observation: 39.413 [0.000, 142.000], loss: 0.029051, mean_squared_error: 30.823323, mean_q: 6.135476, mean_eps: 0.100000\n",
      " 111007/1000000: episode: 1485, duration: 7.894s, episode steps: 138, steps per second: 17, episode reward: 17.000, mean reward: 0.123 [0.000, 4.000], mean action: 1.681 [0.000, 3.000], mean observation: 39.082 [0.000, 142.000], loss: 0.033732, mean_squared_error: 30.287688, mean_q: 6.050140, mean_eps: 0.100000\n",
      " 111101/1000000: episode: 1486, duration: 5.376s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.851 [0.000, 3.000], mean observation: 39.422 [0.000, 142.000], loss: 0.031755, mean_squared_error: 30.603444, mean_q: 6.121163, mean_eps: 0.100000\n",
      " 111196/1000000: episode: 1487, duration: 5.434s, episode steps: 95, steps per second: 17, episode reward: 10.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.800 [0.000, 3.000], mean observation: 39.425 [0.000, 142.000], loss: 0.028876, mean_squared_error: 30.663102, mean_q: 6.146386, mean_eps: 0.100000\n",
      " 111287/1000000: episode: 1488, duration: 5.272s, episode steps: 91, steps per second: 17, episode reward: 13.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.901 [0.000, 3.000], mean observation: 39.427 [0.000, 142.000], loss: 0.031311, mean_squared_error: 31.363643, mean_q: 6.223826, mean_eps: 0.100000\n",
      " 111389/1000000: episode: 1489, duration: 5.945s, episode steps: 102, steps per second: 17, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.402 [0.000, 3.000], mean observation: 39.316 [0.000, 142.000], loss: 0.029004, mean_squared_error: 30.695201, mean_q: 6.134214, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 111466/1000000: episode: 1490, duration: 4.478s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.117 [0.000, 3.000], mean observation: 39.537 [0.000, 142.000], loss: 0.022211, mean_squared_error: 31.057784, mean_q: 6.170374, mean_eps: 0.100000\n",
      " 111549/1000000: episode: 1491, duration: 4.821s, episode steps: 83, steps per second: 17, episode reward: 5.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.880 [0.000, 3.000], mean observation: 39.529 [0.000, 142.000], loss: 0.024797, mean_squared_error: 30.826218, mean_q: 6.154956, mean_eps: 0.100000\n",
      " 111643/1000000: episode: 1492, duration: 5.443s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.096 [0.000, 3.000], mean observation: 39.419 [0.000, 142.000], loss: 0.025640, mean_squared_error: 31.314927, mean_q: 6.187617, mean_eps: 0.100000\n",
      " 111737/1000000: episode: 1493, duration: 5.361s, episode steps: 94, steps per second: 18, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.766 [0.000, 3.000], mean observation: 39.425 [0.000, 142.000], loss: 0.028518, mean_squared_error: 30.852056, mean_q: 6.140682, mean_eps: 0.100000\n",
      " 111821/1000000: episode: 1494, duration: 4.835s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 2.107 [0.000, 3.000], mean observation: 39.507 [0.000, 142.000], loss: 0.028373, mean_squared_error: 31.153511, mean_q: 6.167251, mean_eps: 0.100000\n",
      " 111924/1000000: episode: 1495, duration: 6.021s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.883 [0.000, 3.000], mean observation: 39.337 [0.000, 142.000], loss: 0.025798, mean_squared_error: 31.255908, mean_q: 6.197747, mean_eps: 0.100000\n",
      " 112037/1000000: episode: 1496, duration: 6.499s, episode steps: 113, steps per second: 17, episode reward: 11.000, mean reward: 0.097 [0.000, 4.000], mean action: 2.053 [0.000, 3.000], mean observation: 39.318 [0.000, 142.000], loss: 0.026585, mean_squared_error: 31.636465, mean_q: 6.243183, mean_eps: 0.100000\n",
      " 112127/1000000: episode: 1497, duration: 5.155s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.508 [0.000, 142.000], loss: 0.030249, mean_squared_error: 31.515272, mean_q: 6.247789, mean_eps: 0.100000\n",
      " 112232/1000000: episode: 1498, duration: 5.975s, episode steps: 105, steps per second: 18, episode reward: 14.000, mean reward: 0.133 [0.000, 4.000], mean action: 1.781 [0.000, 3.000], mean observation: 39.324 [0.000, 142.000], loss: 0.029261, mean_squared_error: 31.654956, mean_q: 6.254071, mean_eps: 0.100000\n",
      " 112352/1000000: episode: 1499, duration: 6.823s, episode steps: 120, steps per second: 18, episode reward: 20.000, mean reward: 0.167 [0.000, 4.000], mean action: 2.033 [0.000, 3.000], mean observation: 39.136 [0.000, 142.000], loss: 0.027824, mean_squared_error: 31.598690, mean_q: 6.237997, mean_eps: 0.100000\n",
      " 112498/1000000: episode: 1500, duration: 8.347s, episode steps: 146, steps per second: 17, episode reward: 18.000, mean reward: 0.123 [0.000, 4.000], mean action: 1.685 [0.000, 3.000], mean observation: 38.946 [0.000, 142.000], loss: 0.028883, mean_squared_error: 31.266367, mean_q: 6.171510, mean_eps: 0.100000\n",
      " 112604/1000000: episode: 1501, duration: 6.126s, episode steps: 106, steps per second: 17, episode reward: 14.000, mean reward: 0.132 [0.000, 4.000], mean action: 1.726 [0.000, 3.000], mean observation: 39.315 [0.000, 142.000], loss: 0.030204, mean_squared_error: 31.590374, mean_q: 6.213573, mean_eps: 0.100000\n",
      " 112679/1000000: episode: 1502, duration: 4.304s, episode steps: 75, steps per second: 17, episode reward: 8.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.547 [0.000, 3.000], mean observation: 39.593 [0.000, 142.000], loss: 0.027901, mean_squared_error: 31.444302, mean_q: 6.225384, mean_eps: 0.100000\n",
      " 112810/1000000: episode: 1503, duration: 7.525s, episode steps: 131, steps per second: 17, episode reward: 11.000, mean reward: 0.084 [0.000, 1.000], mean action: 1.870 [0.000, 3.000], mean observation: 39.150 [0.000, 142.000], loss: 0.030376, mean_squared_error: 31.842404, mean_q: 6.263453, mean_eps: 0.100000\n",
      " 112894/1000000: episode: 1504, duration: 4.807s, episode steps: 84, steps per second: 17, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.511 [0.000, 142.000], loss: 0.029320, mean_squared_error: 31.461426, mean_q: 6.206019, mean_eps: 0.100000\n",
      " 112988/1000000: episode: 1505, duration: 5.502s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.064 [0.000, 3.000], mean observation: 39.424 [0.000, 142.000], loss: 0.022948, mean_squared_error: 31.065646, mean_q: 6.144989, mean_eps: 0.100000\n",
      " 113070/1000000: episode: 1506, duration: 4.834s, episode steps: 82, steps per second: 17, episode reward: 12.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.841 [0.000, 3.000], mean observation: 39.507 [0.000, 142.000], loss: 0.026893, mean_squared_error: 32.082845, mean_q: 6.278626, mean_eps: 0.100000\n",
      " 113186/1000000: episode: 1507, duration: 6.754s, episode steps: 116, steps per second: 17, episode reward: 12.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.836 [0.000, 3.000], mean observation: 39.262 [0.000, 142.000], loss: 0.027018, mean_squared_error: 31.751924, mean_q: 6.235101, mean_eps: 0.100000\n",
      " 113299/1000000: episode: 1508, duration: 6.474s, episode steps: 113, steps per second: 17, episode reward: 15.000, mean reward: 0.133 [0.000, 4.000], mean action: 1.982 [0.000, 3.000], mean observation: 39.210 [0.000, 142.000], loss: 0.030715, mean_squared_error: 31.649399, mean_q: 6.209951, mean_eps: 0.100000\n",
      " 113402/1000000: episode: 1509, duration: 5.836s, episode steps: 103, steps per second: 18, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.893 [0.000, 3.000], mean observation: 39.302 [0.000, 142.000], loss: 0.026525, mean_squared_error: 32.065316, mean_q: 6.284328, mean_eps: 0.100000\n",
      " 113505/1000000: episode: 1510, duration: 5.912s, episode steps: 103, steps per second: 17, episode reward: 10.000, mean reward: 0.097 [0.000, 4.000], mean action: 2.107 [0.000, 3.000], mean observation: 39.382 [0.000, 142.000], loss: 0.027740, mean_squared_error: 31.640706, mean_q: 6.212620, mean_eps: 0.100000\n",
      " 113629/1000000: episode: 1511, duration: 7.144s, episode steps: 124, steps per second: 17, episode reward: 16.000, mean reward: 0.129 [0.000, 4.000], mean action: 1.750 [0.000, 3.000], mean observation: 39.154 [0.000, 142.000], loss: 0.027737, mean_squared_error: 32.408790, mean_q: 6.323745, mean_eps: 0.100000\n",
      " 113710/1000000: episode: 1512, duration: 4.688s, episode steps: 81, steps per second: 17, episode reward: 12.000, mean reward: 0.148 [0.000, 4.000], mean action: 2.025 [0.000, 3.000], mean observation: 39.513 [0.000, 142.000], loss: 0.029984, mean_squared_error: 32.542516, mean_q: 6.332560, mean_eps: 0.100000\n",
      " 113793/1000000: episode: 1513, duration: 4.743s, episode steps: 83, steps per second: 18, episode reward: 9.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.928 [0.000, 3.000], mean observation: 39.504 [0.000, 142.000], loss: 0.030933, mean_squared_error: 31.804843, mean_q: 6.206732, mean_eps: 0.100000\n",
      " 113886/1000000: episode: 1514, duration: 5.288s, episode steps: 93, steps per second: 18, episode reward: 10.000, mean reward: 0.108 [0.000, 4.000], mean action: 2.054 [0.000, 3.000], mean observation: 39.398 [0.000, 142.000], loss: 0.035886, mean_squared_error: 32.087937, mean_q: 6.275768, mean_eps: 0.100000\n",
      " 113977/1000000: episode: 1515, duration: 5.204s, episode steps: 91, steps per second: 17, episode reward: 13.000, mean reward: 0.143 [0.000, 4.000], mean action: 2.055 [0.000, 3.000], mean observation: 39.424 [0.000, 142.000], loss: 0.029474, mean_squared_error: 31.874370, mean_q: 6.241048, mean_eps: 0.100000\n",
      " 114066/1000000: episode: 1516, duration: 5.157s, episode steps: 89, steps per second: 17, episode reward: 13.000, mean reward: 0.146 [0.000, 4.000], mean action: 1.978 [0.000, 3.000], mean observation: 39.417 [0.000, 142.000], loss: 0.024893, mean_squared_error: 33.159058, mean_q: 6.369214, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 114150/1000000: episode: 1517, duration: 4.870s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.917 [0.000, 3.000], mean observation: 39.535 [0.000, 142.000], loss: 0.026602, mean_squared_error: 32.612580, mean_q: 6.326289, mean_eps: 0.100000\n",
      " 114240/1000000: episode: 1518, duration: 5.203s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 2.111 [0.000, 3.000], mean observation: 39.496 [0.000, 142.000], loss: 0.031651, mean_squared_error: 32.213810, mean_q: 6.264502, mean_eps: 0.100000\n",
      " 114361/1000000: episode: 1519, duration: 6.902s, episode steps: 121, steps per second: 18, episode reward: 16.000, mean reward: 0.132 [0.000, 4.000], mean action: 1.992 [0.000, 3.000], mean observation: 39.138 [0.000, 142.000], loss: 0.029979, mean_squared_error: 32.542220, mean_q: 6.312533, mean_eps: 0.100000\n",
      " 114454/1000000: episode: 1520, duration: 5.286s, episode steps: 93, steps per second: 18, episode reward: 13.000, mean reward: 0.140 [0.000, 4.000], mean action: 1.925 [0.000, 3.000], mean observation: 39.441 [0.000, 142.000], loss: 0.024453, mean_squared_error: 31.830596, mean_q: 6.238459, mean_eps: 0.100000\n",
      " 114593/1000000: episode: 1521, duration: 8.030s, episode steps: 139, steps per second: 17, episode reward: 14.000, mean reward: 0.101 [0.000, 4.000], mean action: 2.165 [0.000, 3.000], mean observation: 39.058 [0.000, 142.000], loss: 0.031326, mean_squared_error: 32.679665, mean_q: 6.327664, mean_eps: 0.100000\n",
      " 114709/1000000: episode: 1522, duration: 6.570s, episode steps: 116, steps per second: 18, episode reward: 15.000, mean reward: 0.129 [0.000, 4.000], mean action: 2.060 [0.000, 3.000], mean observation: 39.190 [0.000, 142.000], loss: 0.032697, mean_squared_error: 32.356489, mean_q: 6.291223, mean_eps: 0.100000\n",
      " 114798/1000000: episode: 1523, duration: 5.209s, episode steps: 89, steps per second: 17, episode reward: 9.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.876 [1.000, 3.000], mean observation: 39.523 [0.000, 142.000], loss: 0.026729, mean_squared_error: 32.731774, mean_q: 6.370303, mean_eps: 0.100000\n",
      " 114931/1000000: episode: 1524, duration: 7.651s, episode steps: 133, steps per second: 17, episode reward: 14.000, mean reward: 0.105 [0.000, 4.000], mean action: 1.774 [0.000, 3.000], mean observation: 39.106 [0.000, 142.000], loss: 0.028725, mean_squared_error: 32.090097, mean_q: 6.260093, mean_eps: 0.100000\n",
      " 115033/1000000: episode: 1525, duration: 5.968s, episode steps: 102, steps per second: 17, episode reward: 8.000, mean reward: 0.078 [0.000, 1.000], mean action: 2.049 [0.000, 3.000], mean observation: 39.394 [0.000, 142.000], loss: 0.031846, mean_squared_error: 32.407979, mean_q: 6.318011, mean_eps: 0.100000\n",
      " 115130/1000000: episode: 1526, duration: 5.614s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.093 [0.000, 3.000], mean observation: 39.400 [0.000, 142.000], loss: 0.031115, mean_squared_error: 32.405884, mean_q: 6.287490, mean_eps: 0.100000\n",
      " 115237/1000000: episode: 1527, duration: 6.151s, episode steps: 107, steps per second: 17, episode reward: 11.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.075 [0.000, 3.000], mean observation: 39.252 [0.000, 142.000], loss: 0.033266, mean_squared_error: 32.787292, mean_q: 6.367073, mean_eps: 0.100000\n",
      " 115301/1000000: episode: 1528, duration: 3.698s, episode steps: 64, steps per second: 17, episode reward: 7.000, mean reward: 0.109 [0.000, 4.000], mean action: 1.969 [0.000, 3.000], mean observation: 39.664 [0.000, 142.000], loss: 0.042914, mean_squared_error: 32.385614, mean_q: 6.306972, mean_eps: 0.100000\n",
      " 115395/1000000: episode: 1529, duration: 5.431s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.830 [0.000, 3.000], mean observation: 39.438 [0.000, 142.000], loss: 0.030599, mean_squared_error: 32.849344, mean_q: 6.353596, mean_eps: 0.100000\n",
      " 115502/1000000: episode: 1530, duration: 6.093s, episode steps: 107, steps per second: 18, episode reward: 15.000, mean reward: 0.140 [0.000, 4.000], mean action: 2.056 [0.000, 3.000], mean observation: 39.207 [0.000, 142.000], loss: 0.034341, mean_squared_error: 32.489927, mean_q: 6.310441, mean_eps: 0.100000\n",
      " 115586/1000000: episode: 1531, duration: 4.862s, episode steps: 84, steps per second: 17, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.491 [0.000, 142.000], loss: 0.030159, mean_squared_error: 32.914777, mean_q: 6.318193, mean_eps: 0.100000\n",
      " 115680/1000000: episode: 1532, duration: 5.403s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.840 [0.000, 3.000], mean observation: 39.414 [0.000, 142.000], loss: 0.028505, mean_squared_error: 32.601670, mean_q: 6.346308, mean_eps: 0.100000\n",
      " 115767/1000000: episode: 1533, duration: 5.034s, episode steps: 87, steps per second: 17, episode reward: 9.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.920 [0.000, 3.000], mean observation: 39.521 [0.000, 142.000], loss: 0.025917, mean_squared_error: 32.485253, mean_q: 6.292911, mean_eps: 0.100000\n",
      " 115860/1000000: episode: 1534, duration: 5.392s, episode steps: 93, steps per second: 17, episode reward: 13.000, mean reward: 0.140 [0.000, 4.000], mean action: 1.989 [0.000, 3.000], mean observation: 39.430 [0.000, 142.000], loss: 0.027746, mean_squared_error: 32.917067, mean_q: 6.369661, mean_eps: 0.100000\n",
      " 115937/1000000: episode: 1535, duration: 4.426s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.818 [0.000, 3.000], mean observation: 39.623 [0.000, 142.000], loss: 0.031537, mean_squared_error: 33.340174, mean_q: 6.389503, mean_eps: 0.100000\n",
      " 116016/1000000: episode: 1536, duration: 4.580s, episode steps: 79, steps per second: 17, episode reward: 5.000, mean reward: 0.063 [0.000, 1.000], mean action: 2.152 [0.000, 3.000], mean observation: 39.559 [0.000, 142.000], loss: 0.027573, mean_squared_error: 32.755736, mean_q: 6.328310, mean_eps: 0.100000\n",
      " 116106/1000000: episode: 1537, duration: 5.169s, episode steps: 90, steps per second: 17, episode reward: 13.000, mean reward: 0.144 [0.000, 4.000], mean action: 1.956 [0.000, 3.000], mean observation: 39.422 [0.000, 142.000], loss: 0.025875, mean_squared_error: 32.641513, mean_q: 6.287807, mean_eps: 0.100000\n",
      " 116214/1000000: episode: 1538, duration: 6.209s, episode steps: 108, steps per second: 17, episode reward: 11.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.298 [0.000, 142.000], loss: 0.027329, mean_squared_error: 33.503674, mean_q: 6.418344, mean_eps: 0.100000\n",
      " 116341/1000000: episode: 1539, duration: 7.240s, episode steps: 127, steps per second: 18, episode reward: 17.000, mean reward: 0.134 [0.000, 4.000], mean action: 1.906 [0.000, 3.000], mean observation: 39.100 [0.000, 142.000], loss: 0.028706, mean_squared_error: 32.874818, mean_q: 6.335450, mean_eps: 0.100000\n",
      " 116436/1000000: episode: 1540, duration: 5.464s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.863 [0.000, 3.000], mean observation: 39.440 [0.000, 142.000], loss: 0.025896, mean_squared_error: 32.817247, mean_q: 6.340435, mean_eps: 0.100000\n",
      " 116539/1000000: episode: 1541, duration: 5.945s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.311 [0.000, 142.000], loss: 0.027484, mean_squared_error: 32.401320, mean_q: 6.301680, mean_eps: 0.100000\n",
      " 116629/1000000: episode: 1542, duration: 5.057s, episode steps: 90, steps per second: 18, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.978 [0.000, 3.000], mean observation: 39.522 [0.000, 142.000], loss: 0.025839, mean_squared_error: 32.231609, mean_q: 6.263739, mean_eps: 0.100000\n",
      " 116731/1000000: episode: 1543, duration: 5.859s, episode steps: 102, steps per second: 17, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.039 [0.000, 3.000], mean observation: 39.306 [0.000, 142.000], loss: 0.028427, mean_squared_error: 32.317542, mean_q: 6.266746, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 116842/1000000: episode: 1544, duration: 6.485s, episode steps: 111, steps per second: 17, episode reward: 12.000, mean reward: 0.108 [0.000, 4.000], mean action: 2.117 [0.000, 3.000], mean observation: 39.226 [0.000, 142.000], loss: 0.030786, mean_squared_error: 33.077794, mean_q: 6.371768, mean_eps: 0.100000\n",
      " 116952/1000000: episode: 1545, duration: 6.272s, episode steps: 110, steps per second: 18, episode reward: 12.000, mean reward: 0.109 [0.000, 4.000], mean action: 1.945 [0.000, 3.000], mean observation: 39.250 [0.000, 142.000], loss: 0.029142, mean_squared_error: 32.883564, mean_q: 6.362380, mean_eps: 0.100000\n",
      " 117045/1000000: episode: 1546, duration: 5.360s, episode steps: 93, steps per second: 17, episode reward: 13.000, mean reward: 0.140 [0.000, 4.000], mean action: 2.054 [0.000, 3.000], mean observation: 39.430 [0.000, 142.000], loss: 0.027723, mean_squared_error: 32.482819, mean_q: 6.295470, mean_eps: 0.100000\n",
      " 117174/1000000: episode: 1547, duration: 7.483s, episode steps: 129, steps per second: 17, episode reward: 10.000, mean reward: 0.078 [0.000, 1.000], mean action: 1.597 [0.000, 3.000], mean observation: 39.198 [0.000, 142.000], loss: 0.027014, mean_squared_error: 33.528050, mean_q: 6.413281, mean_eps: 0.100000\n",
      " 117256/1000000: episode: 1548, duration: 4.699s, episode steps: 82, steps per second: 17, episode reward: 5.000, mean reward: 0.061 [0.000, 1.000], mean action: 1.878 [0.000, 3.000], mean observation: 39.571 [0.000, 142.000], loss: 0.026162, mean_squared_error: 33.082162, mean_q: 6.357228, mean_eps: 0.100000\n",
      " 117346/1000000: episode: 1549, duration: 5.156s, episode steps: 90, steps per second: 17, episode reward: 9.000, mean reward: 0.100 [0.000, 4.000], mean action: 2.200 [0.000, 3.000], mean observation: 39.487 [0.000, 142.000], loss: 0.031947, mean_squared_error: 32.207156, mean_q: 6.263768, mean_eps: 0.100000\n",
      " 117450/1000000: episode: 1550, duration: 5.963s, episode steps: 104, steps per second: 17, episode reward: 8.000, mean reward: 0.077 [0.000, 1.000], mean action: 1.731 [0.000, 3.000], mean observation: 39.369 [0.000, 142.000], loss: 0.028779, mean_squared_error: 32.605381, mean_q: 6.285170, mean_eps: 0.100000\n",
      " 117552/1000000: episode: 1551, duration: 5.803s, episode steps: 102, steps per second: 18, episode reward: 11.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.755 [0.000, 3.000], mean observation: 39.324 [0.000, 142.000], loss: 0.026896, mean_squared_error: 33.036818, mean_q: 6.363608, mean_eps: 0.100000\n",
      " 117654/1000000: episode: 1552, duration: 5.882s, episode steps: 102, steps per second: 17, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.098 [0.000, 3.000], mean observation: 39.316 [0.000, 142.000], loss: 0.030697, mean_squared_error: 33.035836, mean_q: 6.373450, mean_eps: 0.100000\n",
      " 117741/1000000: episode: 1553, duration: 5.023s, episode steps: 87, steps per second: 17, episode reward: 9.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.989 [0.000, 3.000], mean observation: 39.524 [0.000, 142.000], loss: 0.028444, mean_squared_error: 32.696215, mean_q: 6.345122, mean_eps: 0.100000\n",
      " 117843/1000000: episode: 1554, duration: 5.792s, episode steps: 102, steps per second: 18, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.069 [0.000, 3.000], mean observation: 39.326 [0.000, 142.000], loss: 0.027906, mean_squared_error: 32.940821, mean_q: 6.350747, mean_eps: 0.100000\n",
      " 117957/1000000: episode: 1555, duration: 6.554s, episode steps: 114, steps per second: 17, episode reward: 15.000, mean reward: 0.132 [0.000, 4.000], mean action: 2.219 [0.000, 3.000], mean observation: 39.165 [0.000, 142.000], loss: 0.027622, mean_squared_error: 33.000443, mean_q: 6.343918, mean_eps: 0.100000\n",
      " 118086/1000000: episode: 1556, duration: 7.532s, episode steps: 129, steps per second: 17, episode reward: 17.000, mean reward: 0.132 [0.000, 4.000], mean action: 2.062 [0.000, 3.000], mean observation: 39.043 [0.000, 142.000], loss: 0.027775, mean_squared_error: 33.094536, mean_q: 6.369981, mean_eps: 0.100000\n",
      " 118207/1000000: episode: 1557, duration: 6.822s, episode steps: 121, steps per second: 18, episode reward: 9.000, mean reward: 0.074 [0.000, 1.000], mean action: 2.008 [0.000, 3.000], mean observation: 39.254 [0.000, 142.000], loss: 0.028394, mean_squared_error: 33.248747, mean_q: 6.403455, mean_eps: 0.100000\n",
      " 118354/1000000: episode: 1558, duration: 8.390s, episode steps: 147, steps per second: 18, episode reward: 11.000, mean reward: 0.075 [0.000, 1.000], mean action: 1.810 [0.000, 3.000], mean observation: 39.059 [0.000, 142.000], loss: 0.027699, mean_squared_error: 33.075031, mean_q: 6.370647, mean_eps: 0.100000\n",
      " 118475/1000000: episode: 1559, duration: 6.937s, episode steps: 121, steps per second: 17, episode reward: 17.000, mean reward: 0.140 [0.000, 4.000], mean action: 1.934 [0.000, 3.000], mean observation: 39.077 [0.000, 142.000], loss: 0.028825, mean_squared_error: 33.118686, mean_q: 6.369130, mean_eps: 0.100000\n",
      " 118584/1000000: episode: 1560, duration: 6.178s, episode steps: 109, steps per second: 18, episode reward: 15.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.936 [0.000, 3.000], mean observation: 39.202 [0.000, 142.000], loss: 0.024686, mean_squared_error: 32.227427, mean_q: 6.248776, mean_eps: 0.100000\n",
      " 118687/1000000: episode: 1561, duration: 5.890s, episode steps: 103, steps per second: 17, episode reward: 11.000, mean reward: 0.107 [0.000, 4.000], mean action: 2.019 [0.000, 3.000], mean observation: 39.287 [0.000, 142.000], loss: 0.029203, mean_squared_error: 33.264102, mean_q: 6.403883, mean_eps: 0.100000\n",
      " 118810/1000000: episode: 1562, duration: 7.067s, episode steps: 123, steps per second: 17, episode reward: 12.000, mean reward: 0.098 [0.000, 4.000], mean action: 1.976 [0.000, 3.000], mean observation: 39.259 [0.000, 142.000], loss: 0.030622, mean_squared_error: 33.490884, mean_q: 6.419312, mean_eps: 0.100000\n",
      " 118926/1000000: episode: 1563, duration: 6.638s, episode steps: 116, steps per second: 17, episode reward: 15.000, mean reward: 0.129 [0.000, 4.000], mean action: 2.069 [0.000, 3.000], mean observation: 39.181 [0.000, 142.000], loss: 0.031103, mean_squared_error: 33.318566, mean_q: 6.371631, mean_eps: 0.100000\n",
      " 119028/1000000: episode: 1564, duration: 5.868s, episode steps: 102, steps per second: 17, episode reward: 15.000, mean reward: 0.147 [0.000, 4.000], mean action: 2.078 [0.000, 3.000], mean observation: 39.185 [0.000, 142.000], loss: 0.030968, mean_squared_error: 33.415780, mean_q: 6.395669, mean_eps: 0.100000\n",
      " 119113/1000000: episode: 1565, duration: 4.911s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 2.353 [0.000, 3.000], mean observation: 39.497 [0.000, 142.000], loss: 0.030157, mean_squared_error: 33.227676, mean_q: 6.385410, mean_eps: 0.100000\n",
      " 119239/1000000: episode: 1566, duration: 7.340s, episode steps: 126, steps per second: 17, episode reward: 13.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.071 [0.000, 3.000], mean observation: 39.143 [0.000, 142.000], loss: 0.031164, mean_squared_error: 33.450694, mean_q: 6.419857, mean_eps: 0.100000\n",
      " 119343/1000000: episode: 1567, duration: 6.023s, episode steps: 104, steps per second: 17, episode reward: 14.000, mean reward: 0.135 [0.000, 4.000], mean action: 2.212 [0.000, 3.000], mean observation: 39.321 [0.000, 142.000], loss: 0.026704, mean_squared_error: 33.708199, mean_q: 6.444648, mean_eps: 0.100000\n",
      " 119438/1000000: episode: 1568, duration: 5.563s, episode steps: 95, steps per second: 17, episode reward: 10.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.063 [0.000, 3.000], mean observation: 39.395 [0.000, 142.000], loss: 0.025755, mean_squared_error: 33.725555, mean_q: 6.449100, mean_eps: 0.100000\n",
      " 119541/1000000: episode: 1569, duration: 5.974s, episode steps: 103, steps per second: 17, episode reward: 8.000, mean reward: 0.078 [0.000, 1.000], mean action: 1.835 [0.000, 3.000], mean observation: 39.397 [0.000, 142.000], loss: 0.030548, mean_squared_error: 33.920742, mean_q: 6.468597, mean_eps: 0.100000\n",
      " 119644/1000000: episode: 1570, duration: 5.978s, episode steps: 103, steps per second: 17, episode reward: 14.000, mean reward: 0.136 [0.000, 4.000], mean action: 2.010 [0.000, 3.000], mean observation: 39.301 [0.000, 142.000], loss: 0.029759, mean_squared_error: 32.966269, mean_q: 6.327714, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 119750/1000000: episode: 1571, duration: 6.164s, episode steps: 106, steps per second: 17, episode reward: 14.000, mean reward: 0.132 [0.000, 4.000], mean action: 2.028 [0.000, 3.000], mean observation: 39.321 [0.000, 142.000], loss: 0.027910, mean_squared_error: 33.928171, mean_q: 6.462600, mean_eps: 0.100000\n",
      " 119860/1000000: episode: 1572, duration: 6.332s, episode steps: 110, steps per second: 17, episode reward: 15.000, mean reward: 0.136 [0.000, 4.000], mean action: 2.055 [0.000, 3.000], mean observation: 39.287 [0.000, 142.000], loss: 0.028976, mean_squared_error: 33.844296, mean_q: 6.457121, mean_eps: 0.100000\n",
      " 119944/1000000: episode: 1573, duration: 4.809s, episode steps: 84, steps per second: 17, episode reward: 9.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.929 [0.000, 3.000], mean observation: 39.498 [0.000, 142.000], loss: 0.029179, mean_squared_error: 33.896387, mean_q: 6.434999, mean_eps: 0.100000\n",
      " 120054/1000000: episode: 1574, duration: 6.355s, episode steps: 110, steps per second: 17, episode reward: 15.000, mean reward: 0.136 [0.000, 4.000], mean action: 1.918 [0.000, 3.000], mean observation: 39.204 [0.000, 142.000], loss: 0.029771, mean_squared_error: 33.988066, mean_q: 6.454579, mean_eps: 0.100000\n",
      " 120154/1000000: episode: 1575, duration: 5.714s, episode steps: 100, steps per second: 18, episode reward: 14.000, mean reward: 0.140 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.321 [0.000, 142.000], loss: 0.027538, mean_squared_error: 33.353296, mean_q: 6.381863, mean_eps: 0.100000\n",
      " 120253/1000000: episode: 1576, duration: 5.745s, episode steps: 99, steps per second: 17, episode reward: 14.000, mean reward: 0.141 [0.000, 4.000], mean action: 1.919 [0.000, 3.000], mean observation: 39.329 [0.000, 142.000], loss: 0.033402, mean_squared_error: 33.348787, mean_q: 6.367839, mean_eps: 0.100000\n",
      " 120364/1000000: episode: 1577, duration: 6.373s, episode steps: 111, steps per second: 17, episode reward: 15.000, mean reward: 0.135 [0.000, 4.000], mean action: 1.874 [0.000, 3.000], mean observation: 39.216 [0.000, 142.000], loss: 0.027233, mean_squared_error: 33.619511, mean_q: 6.426163, mean_eps: 0.100000\n",
      " 120442/1000000: episode: 1578, duration: 4.492s, episode steps: 78, steps per second: 17, episode reward: 12.000, mean reward: 0.154 [0.000, 4.000], mean action: 1.936 [0.000, 3.000], mean observation: 39.530 [0.000, 142.000], loss: 0.025158, mean_squared_error: 34.310254, mean_q: 6.499764, mean_eps: 0.100000\n",
      " 120536/1000000: episode: 1579, duration: 5.461s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.043 [0.000, 3.000], mean observation: 39.437 [0.000, 142.000], loss: 0.031090, mean_squared_error: 33.828374, mean_q: 6.454434, mean_eps: 0.100000\n",
      " 120634/1000000: episode: 1580, duration: 5.651s, episode steps: 98, steps per second: 17, episode reward: 10.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.796 [0.000, 3.000], mean observation: 39.358 [0.000, 142.000], loss: 0.031578, mean_squared_error: 34.291466, mean_q: 6.492824, mean_eps: 0.100000\n",
      " 120727/1000000: episode: 1581, duration: 5.313s, episode steps: 93, steps per second: 18, episode reward: 13.000, mean reward: 0.140 [0.000, 4.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.433 [0.000, 142.000], loss: 0.037307, mean_squared_error: 33.963199, mean_q: 6.470834, mean_eps: 0.100000\n",
      " 120812/1000000: episode: 1582, duration: 4.920s, episode steps: 85, steps per second: 17, episode reward: 9.000, mean reward: 0.106 [0.000, 4.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.524 [0.000, 142.000], loss: 0.030461, mean_squared_error: 32.393069, mean_q: 6.306326, mean_eps: 0.100000\n",
      " 120907/1000000: episode: 1583, duration: 5.485s, episode steps: 95, steps per second: 17, episode reward: 10.000, mean reward: 0.105 [0.000, 4.000], mean action: 2.084 [0.000, 3.000], mean observation: 39.374 [0.000, 142.000], loss: 0.033740, mean_squared_error: 33.643515, mean_q: 6.443085, mean_eps: 0.100000\n",
      " 121006/1000000: episode: 1584, duration: 5.639s, episode steps: 99, steps per second: 18, episode reward: 10.000, mean reward: 0.101 [0.000, 4.000], mean action: 1.848 [0.000, 3.000], mean observation: 39.452 [0.000, 142.000], loss: 0.031616, mean_squared_error: 33.736809, mean_q: 6.437878, mean_eps: 0.100000\n",
      " 121077/1000000: episode: 1585, duration: 4.028s, episode steps: 71, steps per second: 18, episode reward: 11.000, mean reward: 0.155 [0.000, 4.000], mean action: 1.746 [0.000, 3.000], mean observation: 39.537 [0.000, 142.000], loss: 0.029800, mean_squared_error: 34.628629, mean_q: 6.534436, mean_eps: 0.100000\n",
      " 121169/1000000: episode: 1586, duration: 5.362s, episode steps: 92, steps per second: 17, episode reward: 10.000, mean reward: 0.109 [0.000, 4.000], mean action: 2.065 [0.000, 3.000], mean observation: 39.421 [0.000, 142.000], loss: 0.029699, mean_squared_error: 33.810168, mean_q: 6.428135, mean_eps: 0.100000\n",
      " 121282/1000000: episode: 1587, duration: 6.454s, episode steps: 113, steps per second: 18, episode reward: 15.000, mean reward: 0.133 [0.000, 4.000], mean action: 2.212 [0.000, 3.000], mean observation: 39.189 [0.000, 142.000], loss: 0.033391, mean_squared_error: 33.728103, mean_q: 6.435225, mean_eps: 0.100000\n",
      " 121396/1000000: episode: 1588, duration: 6.474s, episode steps: 114, steps per second: 18, episode reward: 11.000, mean reward: 0.096 [0.000, 4.000], mean action: 2.035 [0.000, 3.000], mean observation: 39.274 [0.000, 142.000], loss: 0.028305, mean_squared_error: 34.243117, mean_q: 6.488971, mean_eps: 0.100000\n",
      " 121493/1000000: episode: 1589, duration: 5.557s, episode steps: 97, steps per second: 17, episode reward: 10.000, mean reward: 0.103 [0.000, 4.000], mean action: 2.072 [0.000, 3.000], mean observation: 39.399 [0.000, 142.000], loss: 0.029783, mean_squared_error: 33.847483, mean_q: 6.444534, mean_eps: 0.100000\n",
      " 121706/1000000: episode: 1590, duration: 12.207s, episode steps: 213, steps per second: 17, episode reward: 17.000, mean reward: 0.080 [0.000, 4.000], mean action: 1.700 [0.000, 3.000], mean observation: 38.767 [0.000, 142.000], loss: 0.025943, mean_squared_error: 34.442035, mean_q: 6.500838, mean_eps: 0.100000\n",
      " 121838/1000000: episode: 1591, duration: 7.498s, episode steps: 132, steps per second: 18, episode reward: 16.000, mean reward: 0.121 [0.000, 4.000], mean action: 1.530 [0.000, 3.000], mean observation: 39.119 [0.000, 142.000], loss: 0.028502, mean_squared_error: 34.189184, mean_q: 6.477772, mean_eps: 0.100000\n",
      " 121931/1000000: episode: 1592, duration: 5.322s, episode steps: 93, steps per second: 17, episode reward: 17.000, mean reward: 0.183 [0.000, 4.000], mean action: 1.892 [0.000, 3.000], mean observation: 39.302 [0.000, 142.000], loss: 0.028405, mean_squared_error: 33.612403, mean_q: 6.401841, mean_eps: 0.100000\n",
      " 122028/1000000: episode: 1593, duration: 5.580s, episode steps: 97, steps per second: 17, episode reward: 14.000, mean reward: 0.144 [0.000, 4.000], mean action: 2.010 [0.000, 3.000], mean observation: 39.383 [0.000, 142.000], loss: 0.029367, mean_squared_error: 33.984207, mean_q: 6.450200, mean_eps: 0.100000\n",
      " 122130/1000000: episode: 1594, duration: 5.816s, episode steps: 102, steps per second: 18, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.853 [0.000, 3.000], mean observation: 39.319 [0.000, 142.000], loss: 0.027334, mean_squared_error: 34.167772, mean_q: 6.474286, mean_eps: 0.100000\n",
      " 122224/1000000: episode: 1595, duration: 5.388s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.830 [0.000, 3.000], mean observation: 39.417 [0.000, 142.000], loss: 0.028890, mean_squared_error: 35.279159, mean_q: 6.603579, mean_eps: 0.100000\n",
      " 122347/1000000: episode: 1596, duration: 7.014s, episode steps: 123, steps per second: 18, episode reward: 13.000, mean reward: 0.106 [0.000, 4.000], mean action: 2.211 [0.000, 3.000], mean observation: 39.097 [0.000, 142.000], loss: 0.031128, mean_squared_error: 34.093599, mean_q: 6.475482, mean_eps: 0.100000\n",
      " 122441/1000000: episode: 1597, duration: 5.394s, episode steps: 94, steps per second: 17, episode reward: 17.000, mean reward: 0.181 [0.000, 4.000], mean action: 1.691 [0.000, 3.000], mean observation: 39.291 [0.000, 142.000], loss: 0.029437, mean_squared_error: 33.907501, mean_q: 6.435748, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 122524/1000000: episode: 1598, duration: 4.704s, episode steps: 83, steps per second: 18, episode reward: 9.000, mean reward: 0.108 [0.000, 4.000], mean action: 1.952 [0.000, 3.000], mean observation: 39.454 [0.000, 142.000], loss: 0.029187, mean_squared_error: 33.950316, mean_q: 6.437582, mean_eps: 0.100000\n",
      " 122673/1000000: episode: 1599, duration: 8.570s, episode steps: 149, steps per second: 17, episode reward: 18.000, mean reward: 0.121 [0.000, 4.000], mean action: 2.101 [0.000, 3.000], mean observation: 39.022 [0.000, 142.000], loss: 0.029300, mean_squared_error: 34.829890, mean_q: 6.564733, mean_eps: 0.100000\n",
      " 122769/1000000: episode: 1600, duration: 5.504s, episode steps: 96, steps per second: 17, episode reward: 10.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.927 [0.000, 3.000], mean observation: 39.403 [0.000, 142.000], loss: 0.023375, mean_squared_error: 34.577370, mean_q: 6.515110, mean_eps: 0.100000\n",
      " 122868/1000000: episode: 1601, duration: 5.640s, episode steps: 99, steps per second: 18, episode reward: 14.000, mean reward: 0.141 [0.000, 4.000], mean action: 2.141 [0.000, 3.000], mean observation: 39.319 [0.000, 142.000], loss: 0.027660, mean_squared_error: 33.892111, mean_q: 6.447727, mean_eps: 0.100000\n",
      " 122981/1000000: episode: 1602, duration: 6.452s, episode steps: 113, steps per second: 18, episode reward: 9.000, mean reward: 0.080 [0.000, 1.000], mean action: 1.867 [0.000, 3.000], mean observation: 39.224 [0.000, 142.000], loss: 0.024148, mean_squared_error: 34.594389, mean_q: 6.519510, mean_eps: 0.100000\n",
      " 123048/1000000: episode: 1603, duration: 3.892s, episode steps: 67, steps per second: 17, episode reward: 4.000, mean reward: 0.060 [0.000, 1.000], mean action: 1.806 [0.000, 3.000], mean observation: 39.745 [0.000, 142.000], loss: 0.029663, mean_squared_error: 35.183538, mean_q: 6.595161, mean_eps: 0.100000\n",
      " 123142/1000000: episode: 1604, duration: 5.421s, episode steps: 94, steps per second: 17, episode reward: 7.000, mean reward: 0.074 [0.000, 1.000], mean action: 1.989 [0.000, 3.000], mean observation: 39.434 [0.000, 142.000], loss: 0.032301, mean_squared_error: 34.806308, mean_q: 6.553363, mean_eps: 0.100000\n",
      " 123255/1000000: episode: 1605, duration: 6.430s, episode steps: 113, steps per second: 18, episode reward: 12.000, mean reward: 0.106 [0.000, 4.000], mean action: 2.239 [0.000, 3.000], mean observation: 39.251 [0.000, 142.000], loss: 0.029863, mean_squared_error: 34.583438, mean_q: 6.503164, mean_eps: 0.100000\n",
      " 123332/1000000: episode: 1606, duration: 4.442s, episode steps: 77, steps per second: 17, episode reward: 8.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.714 [0.000, 3.000], mean observation: 39.541 [0.000, 142.000], loss: 0.026630, mean_squared_error: 34.227744, mean_q: 6.506087, mean_eps: 0.100000\n",
      " 123440/1000000: episode: 1607, duration: 6.133s, episode steps: 108, steps per second: 18, episode reward: 11.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.815 [0.000, 3.000], mean observation: 39.263 [0.000, 142.000], loss: 0.025272, mean_squared_error: 34.761604, mean_q: 6.557353, mean_eps: 0.100000\n",
      " 123549/1000000: episode: 1608, duration: 6.288s, episode steps: 109, steps per second: 17, episode reward: 15.000, mean reward: 0.138 [0.000, 4.000], mean action: 2.018 [0.000, 3.000], mean observation: 39.168 [0.000, 142.000], loss: 0.025774, mean_squared_error: 34.455280, mean_q: 6.522798, mean_eps: 0.100000\n",
      " 123658/1000000: episode: 1609, duration: 6.225s, episode steps: 109, steps per second: 18, episode reward: 15.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.908 [0.000, 3.000], mean observation: 39.230 [0.000, 142.000], loss: 0.025210, mean_squared_error: 33.949428, mean_q: 6.442275, mean_eps: 0.100000\n",
      " 123785/1000000: episode: 1610, duration: 7.313s, episode steps: 127, steps per second: 17, episode reward: 13.000, mean reward: 0.102 [0.000, 4.000], mean action: 1.827 [0.000, 3.000], mean observation: 39.066 [0.000, 142.000], loss: 0.027091, mean_squared_error: 34.496229, mean_q: 6.515026, mean_eps: 0.100000\n",
      " 123854/1000000: episode: 1611, duration: 3.984s, episode steps: 69, steps per second: 17, episode reward: 4.000, mean reward: 0.058 [0.000, 1.000], mean action: 1.710 [0.000, 3.000], mean observation: 39.609 [0.000, 142.000], loss: 0.027206, mean_squared_error: 35.002048, mean_q: 6.591402, mean_eps: 0.100000\n",
      " 123979/1000000: episode: 1612, duration: 7.222s, episode steps: 125, steps per second: 17, episode reward: 13.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.056 [0.000, 3.000], mean observation: 39.178 [0.000, 142.000], loss: 0.028659, mean_squared_error: 34.585512, mean_q: 6.515774, mean_eps: 0.100000\n",
      " 124077/1000000: episode: 1613, duration: 5.691s, episode steps: 98, steps per second: 17, episode reward: 10.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.020 [0.000, 3.000], mean observation: 39.387 [0.000, 142.000], loss: 0.031195, mean_squared_error: 34.555052, mean_q: 6.532432, mean_eps: 0.100000\n",
      " 124179/1000000: episode: 1614, duration: 5.906s, episode steps: 102, steps per second: 17, episode reward: 14.000, mean reward: 0.137 [0.000, 4.000], mean action: 1.990 [0.000, 3.000], mean observation: 39.326 [0.000, 142.000], loss: 0.030704, mean_squared_error: 35.245436, mean_q: 6.596884, mean_eps: 0.100000\n",
      " 124344/1000000: episode: 1615, duration: 9.495s, episode steps: 165, steps per second: 17, episode reward: 16.000, mean reward: 0.097 [0.000, 4.000], mean action: 2.030 [0.000, 3.000], mean observation: 39.177 [0.000, 142.000], loss: 0.027157, mean_squared_error: 34.364464, mean_q: 6.492535, mean_eps: 0.100000\n",
      " 124438/1000000: episode: 1616, duration: 5.408s, episode steps: 94, steps per second: 17, episode reward: 13.000, mean reward: 0.138 [0.000, 4.000], mean action: 1.819 [0.000, 3.000], mean observation: 39.423 [0.000, 142.000], loss: 0.025784, mean_squared_error: 34.713261, mean_q: 6.550551, mean_eps: 0.100000\n",
      " 124522/1000000: episode: 1617, duration: 4.950s, episode steps: 84, steps per second: 17, episode reward: 12.000, mean reward: 0.143 [0.000, 4.000], mean action: 2.024 [0.000, 3.000], mean observation: 39.508 [0.000, 142.000], loss: 0.030449, mean_squared_error: 34.756006, mean_q: 6.541363, mean_eps: 0.100000\n",
      " 124680/1000000: episode: 1618, duration: 9.003s, episode steps: 158, steps per second: 18, episode reward: 18.000, mean reward: 0.114 [0.000, 4.000], mean action: 2.297 [0.000, 3.000], mean observation: 38.964 [0.000, 142.000], loss: 0.030052, mean_squared_error: 34.670824, mean_q: 6.536917, mean_eps: 0.100000\n",
      " 124787/1000000: episode: 1619, duration: 6.130s, episode steps: 107, steps per second: 17, episode reward: 14.000, mean reward: 0.131 [0.000, 4.000], mean action: 1.944 [0.000, 3.000], mean observation: 39.319 [0.000, 142.000], loss: 0.028721, mean_squared_error: 34.744599, mean_q: 6.519667, mean_eps: 0.100000\n",
      " 124898/1000000: episode: 1620, duration: 6.368s, episode steps: 111, steps per second: 17, episode reward: 12.000, mean reward: 0.108 [0.000, 4.000], mean action: 2.045 [0.000, 3.000], mean observation: 39.230 [0.000, 142.000], loss: 0.031200, mean_squared_error: 34.055167, mean_q: 6.461544, mean_eps: 0.100000\n",
      " 125022/1000000: episode: 1621, duration: 7.119s, episode steps: 124, steps per second: 17, episode reward: 12.000, mean reward: 0.097 [0.000, 4.000], mean action: 2.073 [0.000, 3.000], mean observation: 39.284 [0.000, 142.000], loss: 0.027454, mean_squared_error: 34.125102, mean_q: 6.471056, mean_eps: 0.100000\n",
      " 125130/1000000: episode: 1622, duration: 6.112s, episode steps: 108, steps per second: 18, episode reward: 11.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.139 [0.000, 3.000], mean observation: 39.280 [0.000, 142.000], loss: 0.029993, mean_squared_error: 34.882711, mean_q: 6.556250, mean_eps: 0.100000\n",
      " 125225/1000000: episode: 1623, duration: 5.487s, episode steps: 95, steps per second: 17, episode reward: 13.000, mean reward: 0.137 [0.000, 4.000], mean action: 2.105 [0.000, 3.000], mean observation: 39.428 [0.000, 142.000], loss: 0.026039, mean_squared_error: 35.126849, mean_q: 6.586273, mean_eps: 0.100000\n",
      " 125366/1000000: episode: 1624, duration: 8.125s, episode steps: 141, steps per second: 17, episode reward: 18.000, mean reward: 0.128 [0.000, 4.000], mean action: 2.184 [0.000, 3.000], mean observation: 39.037 [0.000, 142.000], loss: 0.028617, mean_squared_error: 34.301184, mean_q: 6.489966, mean_eps: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 125473/1000000: episode: 1625, duration: 6.136s, episode steps: 107, steps per second: 17, episode reward: 14.000, mean reward: 0.131 [0.000, 4.000], mean action: 1.907 [0.000, 3.000], mean observation: 39.319 [0.000, 142.000], loss: 0.033734, mean_squared_error: 34.477247, mean_q: 6.524874, mean_eps: 0.100000\n",
      " 125585/1000000: episode: 1626, duration: 6.313s, episode steps: 112, steps per second: 18, episode reward: 12.000, mean reward: 0.107 [0.000, 4.000], mean action: 2.089 [0.000, 3.000], mean observation: 39.241 [0.000, 142.000], loss: 0.027148, mean_squared_error: 34.194235, mean_q: 6.465611, mean_eps: 0.100000\n",
      " 125703/1000000: episode: 1627, duration: 6.762s, episode steps: 118, steps per second: 17, episode reward: 15.000, mean reward: 0.127 [0.000, 4.000], mean action: 1.881 [0.000, 3.000], mean observation: 39.184 [0.000, 142.000], loss: 0.026710, mean_squared_error: 34.851350, mean_q: 6.562823, mean_eps: 0.100000\n",
      " 125856/1000000: episode: 1628, duration: 8.763s, episode steps: 153, steps per second: 17, episode reward: 12.000, mean reward: 0.078 [0.000, 1.000], mean action: 2.059 [0.000, 3.000], mean observation: 38.947 [0.000, 142.000], loss: 0.027870, mean_squared_error: 35.277814, mean_q: 6.633986, mean_eps: 0.100000\n",
      " 125983/1000000: episode: 1629, duration: 7.245s, episode steps: 127, steps per second: 18, episode reward: 16.000, mean reward: 0.126 [0.000, 4.000], mean action: 1.984 [0.000, 3.000], mean observation: 39.092 [0.000, 142.000], loss: 0.024779, mean_squared_error: 34.945435, mean_q: 6.559844, mean_eps: 0.100000\n",
      " 126084/1000000: episode: 1630, duration: 5.776s, episode steps: 101, steps per second: 17, episode reward: 7.000, mean reward: 0.069 [0.000, 1.000], mean action: 2.000 [0.000, 3.000], mean observation: 39.408 [0.000, 142.000], loss: 0.024061, mean_squared_error: 35.377998, mean_q: 6.623753, mean_eps: 0.100000\n",
      " 126218/1000000: episode: 1631, duration: 7.635s, episode steps: 134, steps per second: 18, episode reward: 14.000, mean reward: 0.104 [0.000, 4.000], mean action: 2.090 [0.000, 3.000], mean observation: 39.085 [0.000, 142.000], loss: 0.025911, mean_squared_error: 35.376809, mean_q: 6.618000, mean_eps: 0.100000\n",
      " 126291/1000000: episode: 1632, duration: 4.207s, episode steps: 73, steps per second: 17, episode reward: 8.000, mean reward: 0.110 [0.000, 4.000], mean action: 1.712 [0.000, 3.000], mean observation: 39.584 [0.000, 142.000], loss: 0.026536, mean_squared_error: 34.965236, mean_q: 6.563764, mean_eps: 0.100000\n",
      " 126406/1000000: episode: 1633, duration: 6.531s, episode steps: 115, steps per second: 18, episode reward: 15.000, mean reward: 0.130 [0.000, 4.000], mean action: 1.930 [0.000, 3.000], mean observation: 39.193 [0.000, 142.000], loss: 0.024093, mean_squared_error: 34.859701, mean_q: 6.549939, mean_eps: 0.100000\n",
      " 126518/1000000: episode: 1634, duration: 6.443s, episode steps: 112, steps per second: 17, episode reward: 15.000, mean reward: 0.134 [0.000, 4.000], mean action: 1.902 [0.000, 3.000], mean observation: 39.273 [0.000, 142.000], loss: 0.023788, mean_squared_error: 35.545251, mean_q: 6.632163, mean_eps: 0.100000\n",
      " 126625/1000000: episode: 1635, duration: 6.220s, episode steps: 107, steps per second: 17, episode reward: 14.000, mean reward: 0.131 [0.000, 4.000], mean action: 1.944 [0.000, 3.000], mean observation: 39.318 [0.000, 142.000], loss: 0.029063, mean_squared_error: 35.499727, mean_q: 6.633657, mean_eps: 0.100000\n",
      " 126717/1000000: episode: 1636, duration: 5.215s, episode steps: 92, steps per second: 18, episode reward: 10.000, mean reward: 0.109 [0.000, 4.000], mean action: 2.152 [0.000, 3.000], mean observation: 39.414 [0.000, 142.000], loss: 0.032257, mean_squared_error: 34.505263, mean_q: 6.515224, mean_eps: 0.100000\n",
      " 126824/1000000: episode: 1637, duration: 6.140s, episode steps: 107, steps per second: 17, episode reward: 14.000, mean reward: 0.131 [0.000, 4.000], mean action: 1.673 [0.000, 3.000], mean observation: 39.333 [0.000, 142.000], loss: 0.029456, mean_squared_error: 34.824940, mean_q: 6.548472, mean_eps: 0.100000\n",
      " 126965/1000000: episode: 1638, duration: 8.111s, episode steps: 141, steps per second: 17, episode reward: 15.000, mean reward: 0.106 [0.000, 4.000], mean action: 1.887 [0.000, 3.000], mean observation: 38.949 [0.000, 142.000], loss: 0.032472, mean_squared_error: 35.039967, mean_q: 6.555053, mean_eps: 0.100000\n",
      " 127100/1000000: episode: 1639, duration: 7.743s, episode steps: 135, steps per second: 17, episode reward: 13.000, mean reward: 0.096 [0.000, 4.000], mean action: 1.807 [0.000, 3.000], mean observation: 39.161 [0.000, 142.000], loss: 0.026584, mean_squared_error: 35.238045, mean_q: 6.579071, mean_eps: 0.100000\n",
      " 127216/1000000: episode: 1640, duration: 6.616s, episode steps: 116, steps per second: 18, episode reward: 12.000, mean reward: 0.103 [0.000, 4.000], mean action: 1.983 [0.000, 3.000], mean observation: 39.242 [0.000, 142.000], loss: 0.030352, mean_squared_error: 35.163807, mean_q: 6.587827, mean_eps: 0.100000\n",
      " 127336/1000000: episode: 1641, duration: 6.870s, episode steps: 120, steps per second: 17, episode reward: 12.000, mean reward: 0.100 [0.000, 4.000], mean action: 1.733 [0.000, 3.000], mean observation: 39.229 [0.000, 142.000], loss: 0.032741, mean_squared_error: 35.301835, mean_q: 6.599871, mean_eps: 0.100000\n",
      " 127458/1000000: episode: 1642, duration: 6.920s, episode steps: 122, steps per second: 18, episode reward: 13.000, mean reward: 0.107 [0.000, 4.000], mean action: 1.926 [0.000, 3.000], mean observation: 39.166 [0.000, 142.000], loss: 0.027078, mean_squared_error: 35.230361, mean_q: 6.585606, mean_eps: 0.100000\n",
      " 127587/1000000: episode: 1643, duration: 7.283s, episode steps: 129, steps per second: 18, episode reward: 17.000, mean reward: 0.132 [0.000, 4.000], mean action: 2.233 [0.000, 3.000], mean observation: 39.092 [0.000, 142.000], loss: 0.024402, mean_squared_error: 34.923768, mean_q: 6.571255, mean_eps: 0.100000\n",
      " 127701/1000000: episode: 1644, duration: 6.484s, episode steps: 114, steps per second: 18, episode reward: 15.000, mean reward: 0.132 [0.000, 4.000], mean action: 2.088 [0.000, 3.000], mean observation: 39.201 [0.000, 142.000], loss: 0.027289, mean_squared_error: 35.595645, mean_q: 6.627860, mean_eps: 0.100000\n",
      " 127797/1000000: episode: 1645, duration: 5.482s, episode steps: 96, steps per second: 18, episode reward: 10.000, mean reward: 0.104 [0.000, 4.000], mean action: 1.812 [0.000, 3.000], mean observation: 39.405 [0.000, 142.000], loss: 0.026183, mean_squared_error: 35.967294, mean_q: 6.673583, mean_eps: 0.100000\n",
      " 127921/1000000: episode: 1646, duration: 7.160s, episode steps: 124, steps per second: 17, episode reward: 15.000, mean reward: 0.121 [0.000, 4.000], mean action: 2.048 [0.000, 3.000], mean observation: 39.172 [0.000, 142.000], loss: 0.024981, mean_squared_error: 35.850995, mean_q: 6.668517, mean_eps: 0.100000\n",
      " 128026/1000000: episode: 1647, duration: 6.100s, episode steps: 105, steps per second: 17, episode reward: 15.000, mean reward: 0.143 [0.000, 4.000], mean action: 1.876 [0.000, 3.000], mean observation: 39.264 [0.000, 142.000], loss: 0.029866, mean_squared_error: 36.118812, mean_q: 6.714618, mean_eps: 0.100000\n",
      " 128154/1000000: episode: 1648, duration: 7.336s, episode steps: 128, steps per second: 17, episode reward: 13.000, mean reward: 0.102 [0.000, 4.000], mean action: 2.062 [0.000, 3.000], mean observation: 39.123 [0.000, 142.000], loss: 0.026428, mean_squared_error: 35.899710, mean_q: 6.663455, mean_eps: 0.100000\n",
      " 128292/1000000: episode: 1649, duration: 7.784s, episode steps: 138, steps per second: 18, episode reward: 14.000, mean reward: 0.101 [0.000, 4.000], mean action: 2.239 [0.000, 3.000], mean observation: 39.055 [0.000, 142.000], loss: 0.026599, mean_squared_error: 35.567249, mean_q: 6.641792, mean_eps: 0.100000\n",
      " 128423/1000000: episode: 1650, duration: 7.590s, episode steps: 131, steps per second: 17, episode reward: 17.000, mean reward: 0.130 [0.000, 4.000], mean action: 2.176 [0.000, 3.000], mean observation: 39.060 [0.000, 142.000], loss: 0.028150, mean_squared_error: 36.204678, mean_q: 6.715438, mean_eps: 0.100000\n",
      " 128524/1000000: episode: 1651, duration: 5.662s, episode steps: 101, steps per second: 18, episode reward: 7.000, mean reward: 0.069 [0.000, 1.000], mean action: 2.099 [0.000, 3.000], mean observation: 39.439 [0.000, 142.000], loss: 0.025906, mean_squared_error: 36.179022, mean_q: 6.720816, mean_eps: 0.100000\n"
     ]
    }
   ],
   "source": [
    "# Setup Callbacks\n",
    "session_num = len(os.listdir('sessions')) + 1\n",
    "train_name = 'dqn_v' + str(session_num)\n",
    "session_path = \"sessions/\" + train_name + '/'\n",
    "model_path = session_path + \"weights/weights_{step}.hdf5\"\n",
    "log_path = session_path + \"log.json\"\n",
    "\n",
    "if not os.path.exists(session_path + 'weights'):\n",
    "    os.makedirs(session_path + 'weights')\n",
    "\n",
    "with open(session_path + 'model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "    \n",
    "model.save(session_path + 'model.h5')\n",
    "\n",
    "callback_list = []\n",
    "callback_list.append(TensorBoard(log_dir=session_path))\n",
    "callback_list.append(ModelIntervalCheckpoint(model_path, 500))\n",
    "callback_list.append(FileLogger(log_path, 500))\n",
    "#callback_list.append(Visualizer())\n",
    "\n",
    "# train the DQN\n",
    "hist = dqn.fit(env, nb_steps=1000000, visualize=False, \n",
    "               action_repetition=4, callbacks=callback_list, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights\n",
    "dqn.save_weights(session_path + \"weights.h5f\", overwrite=True)\n",
    "model.save(session_path + 'model.h5')\n",
    "\n",
    "# and save the history to a csv\n",
    "results = pd.DataFrame(hist.history)\n",
    "results.to_csv(session_path +\"hist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Here, we run the actual DQN in a test environment. There are a couple of things to note:\n",
    "\n",
    "The `test` method doesn't necessarily use the same policy as the `fit` method.  It defaults to `GreedyQPolicy` unless `test_policy` in the `DQNAgent` instantiation is set.  If the model is properly trained, it's action might not vary at all given a greedy policy (e.g., it chooses `LEFT` for every action).  This isn't an issue (although it doesn't make for a very interesting training session), however, it can appear as the the session starts for a couple frames, then freezes.  This is actually because there is a `FIRE` action that the model must first take before the game starts.  If it's only going left, then the game never starts.  I added the 'frame' and 'action' labels to the visualization to check for this.\n",
    "\n",
    "The `Visualization` callback needs to be added just like during training if you want to view it, and, similar to before, `visualize` needs to be set to `False` unless the system is properly configured to handle it.\n",
    "\n",
    "Also similar to training, `action_repetition` is set to 4.  This is appropriate since this is how it was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b4bd5ecf2528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m test_hist = dqn.test(env, nb_episodes=1, action_repetition=4,\n\u001b[0;32m----> 5\u001b[0;31m                      callbacks=callbacks, visualize=False)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rl/core.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                     \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/rl/callbacks.py\u001b[0m in \u001b[0;36mon_action_end\u001b[0;34m(self, action, logs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'on_action_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fcb944301d1b>\u001b[0m in \u001b[0;36mon_action_end\u001b[0;34m(self, action, logs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2201\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1144\u001b[0;31m                 renderer, self, dsu, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2424\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1138\u001b[0m                                                                 renderer)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mtick_tups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_bounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0;31m# handle inverted limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mtick_tups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_bounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0;31m# handle inverted limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36miter_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \"\"\"\n\u001b[1;32m    912\u001b[0m         \u001b[0mmajorLocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mmajorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajorLocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajorLocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         majorLabels = [self.major.formatter(val, i)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;31m# update the new tick label properties from the old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumticks\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m                 \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mXTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tickdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick1line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick1line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick1line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m                           \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tickmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                           \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                           markeredgewidth=self._width, zorder=self._zorder)\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tick1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarkerStyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_marker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_markevery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mset_marker\u001b[0;34m(self, marker)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \"\"\"\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_marker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/markers.py\u001b[0m in \u001b[0;36mset_marker\u001b[0;34m(self, marker)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/markers.py\u001b[0m in \u001b[0;36m_recache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'butt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marker_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/markers.py\u001b[0m in \u001b[0;36m_set_tickdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_tickdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_snap_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, matrix, **kwargs)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0midentity\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \"\"\"\n\u001b[0;32m-> 1818\u001b[0;31m         \u001b[0mAffine2DBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m             \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1663\u001b[0;31m         \u001b[0mTransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1664\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6634897b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f66345800f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks = []\n",
    "callbacks = [Visualizer()]\n",
    "\n",
    "test_hist = dqn.test(env, nb_episodes=1, action_repetition=4,\n",
    "                     callbacks=callbacks, visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "After we have trained everything, we can look at the training history. We then plot the `episode_reward` to see how well it performed over each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6601667278>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_pickle(\"sessions/\" + train_name +\"/hist.pickle\")\n",
    "plt.plot(results['episode_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
